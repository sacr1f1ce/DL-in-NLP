{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b09d7a19-5848-43f4-9d91-f35d4e8614b0",
      "metadata": {
        "id": "b09d7a19-5848-43f4-9d91-f35d4e8614b0"
      },
      "source": [
        "# 1. Information about the submission"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e37cb5bb-f3d0-4c11-a1dc-2490a208fcd3",
      "metadata": {
        "id": "e37cb5bb-f3d0-4c11-a1dc-2490a208fcd3"
      },
      "source": [
        "## 1.1 Name and number of the assignment "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4e9d00b8-f3e5-4a44-bcc6-35cdd60767a9",
      "metadata": {
        "id": "4e9d00b8-f3e5-4a44-bcc6-35cdd60767a9"
      },
      "source": [
        "## Text categorization and argument mining task. HW2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ba7f63-66ec-4691-a5d2-17f4679e298d",
      "metadata": {
        "id": "64ba7f63-66ec-4691-a5d2-17f4679e298d"
      },
      "source": [
        "## 1.2 Student name"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cc8a4e09-62cc-43fd-a7a7-3e9d55ec13b2",
      "metadata": {
        "id": "cc8a4e09-62cc-43fd-a7a7-3e9d55ec13b2"
      },
      "source": [
        "## Nuzhnov Mark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a46ab45-d215-41af-b910-63ff4a215a07",
      "metadata": {
        "id": "8a46ab45-d215-41af-b910-63ff4a215a07"
      },
      "source": [
        "## 1.3 Codalab user ID"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b15cd6b5-8e20-4287-b6ea-a7b0904b355a",
      "metadata": {
        "id": "b15cd6b5-8e20-4287-b6ea-a7b0904b355a"
      },
      "source": [
        "## Nuzhnov_Mark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70456c74-8e1f-4da0-bebe-fbceee169115",
      "metadata": {
        "id": "70456c74-8e1f-4da0-bebe-fbceee169115"
      },
      "source": [
        "## 1.4 Additional comments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b810ac6-7739-4f7f-8bea-dbf1198570ea",
      "metadata": {
        "id": "6b810ac6-7739-4f7f-8bea-dbf1198570ea"
      },
      "source": [
        "***Enter here** any additional comments which you would like to communicate to a TA who is going to grade this work not related to the content of your submission.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1af498ab-3c00-4d36-a962-c947862fede8",
      "metadata": {
        "id": "1af498ab-3c00-4d36-a962-c947862fede8"
      },
      "source": [
        "# 2. Technical Report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3c18a6-868b-4357-a308-7f6dff05c3d0",
      "metadata": {
        "id": "9b3c18a6-868b-4357-a308-7f6dff05c3d0"
      },
      "source": [
        "*Use Section 2 to describe results of your experiments as you would do writing a paper about your results. DO NOT insert code in this part. Only insert plots and tables summarizing results as needed. Use formulas if needed do described your methodology. The code is provided in Section 3.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061f71b9-114a-4cb0-b531-5711970317bf",
      "metadata": {
        "id": "061f71b9-114a-4cb0-b531-5711970317bf"
      },
      "source": [
        "## 2.1 Methodology "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c327f43e-ed30-4279-bba2-a97b2f8ef9e3",
      "metadata": {
        "id": "c327f43e-ed30-4279-bba2-a97b2f8ef9e3"
      },
      "source": [
        "***Enter here** a detailed description of the method used in your submission(s) to Codalab. The description should be at least 2-4 paragraphs featuring the following: type of the model, meta-parameters, how did you select meta-parameters, any further modifications of the out-of-the-box solutions, etc. The text is markdown and you can use math environment to write formulas:* \n",
        "\n",
        "$\\hat{y}=\\beta_0 + \\sum^p_{j=1} x_j \\beta_j$\n",
        "\n",
        "Also you can insert images as needed:\n",
        "\n",
        "![image](https://upload.wikimedia.org/wikipedia/commons/6/6d/Exam_pass_logistic_curve.jpeg)\n",
        "\n",
        "*This part of the should contain description of all methods that you tried and, most importantly, that worked the best for you. Here you can include some tricks of your preprocessing, description of the models and motivation of their usage, the description of the training process details (train-test split, cross-validation, etc.). So, everything valuable that will help us to understand the scope of your work and reproduce your pipeline*\n",
        "\n",
        "*The 'innovativeness' scores will be assigned based on the content of this part. In case you just use a 'drop-in' baseline model these scores will be low. In case you made some clever modification of the model which improves the result this score will be low. However, it does not make sense do describe some modifications which are creative but does not work at all. Try different approaches, models, play with preprocessing, hyperparameters, etc. It is OK to reimplement some already existing approach. It is OK that some of your experiments did not work as you expected. Show us that you used your creativity and ran several experiments.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe27e49-10c7-4c12-adea-48b0a05a5681",
      "metadata": {
        "id": "afe27e49-10c7-4c12-adea-48b0a05a5681"
      },
      "source": [
        "## 2.2 Discussion of results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b1c84c-c261-46b5-a009-0f2bc4002752",
      "metadata": {
        "id": "b5b1c84c-c261-46b5-a009-0f2bc4002752"
      },
      "source": [
        "***Enter here** a discussion of results and a summary of the experiment. Here we want to see the final table with comparison of the baseline and all tried approaches you decided to report. Even if some method did not bring you to the top of the leaderboard, you should nevertheless indicate this result and a discussion, why, in your opinion, some approach worked and another failed. Interesting findings in the discussion will be a plus.*\n",
        "\n",
        "Method | Precision | Recall\n",
        "--- | --- | ---\n",
        "Baseline | 0.88 | 0.77\n",
        "My great method 1 | 0.99 | 0.11\n",
        "My great method 2 | 0.90 | 0.90\n",
        "\n",
        "*If relevant insert plots and historgams in this section e.g. testing variation of the score with respect to some parameters e.g. learning rate or size of the input dataset, etc. Please do not use code to generate plots, instead just insert images as shown below. Plots could be generated from code in Section 3. *\n",
        "\n",
        "![image](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Sine_and_Cosine.svg/640px-Sine_and_Cosine.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194fecf1-e044-4210-a54b-aefbf4b4eebe",
      "metadata": {
        "id": "194fecf1-e044-4210-a54b-aefbf4b4eebe"
      },
      "source": [
        "# 3. Code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a33ff9bd-62c6-4a63-8600-b1651420fee1",
      "metadata": {
        "id": "a33ff9bd-62c6-4a63-8600-b1651420fee1"
      },
      "source": [
        "*Enter here all code used to produce your results submitted to Codalab. Add some comments and subsections to navigate though your solution.*\n",
        "\n",
        "*In this part you are expected to develop yourself a solution of the task and provide a reproducible code:*\n",
        "- *Using Python 3;*\n",
        "- *Contains code for installation of all dependencies;*\n",
        "- *Contains code for downloading of all the datasets used*;\n",
        "- *Contains the code for reproducing your results (in other words, if a tester downloads your notebook she should be able to run cell-by-cell the code and obtain your experimental results as described in the methodology section)*.\n",
        "\n",
        "\n",
        "*As a result, you code will be graded according to these criteria:*\n",
        "- ***Readability**: your code should be well-structured preferably with indicated parts of your approach (Preprocessing, Model training, Evaluation, etc.).*\n",
        "- ***Reproducibility**: your code should be reproduced without any mistakes with “Run all” mode (obtaining experimental part).*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dff93e37-3a24-40ab-87db-16b537aad3f6",
      "metadata": {
        "id": "dff93e37-3a24-40ab-87db-16b537aad3f6"
      },
      "source": [
        "## 3.1 Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "paNHf6yRz5jK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T19:06:01.561451Z",
          "iopub.status.busy": "2023-04-19T19:06:01.560708Z",
          "iopub.status.idle": "2023-04-19T19:06:40.051141Z",
          "shell.execute_reply": "2023-04-19T19:06:40.049811Z",
          "shell.execute_reply.started": "2023-04-19T19:06:01.561404Z"
        },
        "id": "paNHf6yRz5jK",
        "outputId": "a5d5f4d1-0efd-4bbd-f645-dab00243ed2b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "Successfully installed gdown-4.7.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.14.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.9.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.28.2)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.30)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from wandb) (4.4.0)\n",
            "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.8.0)\n",
            "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.18.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.11.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.11.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install gdown\n",
        "! pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73daa932-114b-4e28-9141-13b57c729435",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-19T19:06:40.054971Z",
          "iopub.status.busy": "2023-04-19T19:06:40.054564Z",
          "iopub.status.idle": "2023-04-19T19:06:51.737567Z",
          "shell.execute_reply": "2023-04-19T19:06:51.736079Z",
          "shell.execute_reply.started": "2023-04-19T19:06:40.054922Z"
        },
        "id": "73daa932-114b-4e28-9141-13b57c729435",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import MultiHeadAttention, Flatten, TimeDistributed\n",
        "from tensorflow.keras.optimizers.experimental import AdamW\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "seed_value = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ifqn-NB_9GHI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "6cd77a7ebbfe446389ea3461318d5a3f",
            "d035931093f248369dbb26f17eb590bf",
            "fd8d238024cb43019ad5552237000223",
            "a55bc959b5464902be6584288ce7b8d1",
            "235bd2cda15142dfa7a99f8fd8cd0a9b",
            "8d9e9d90c9bd4548bff981b9c63a4259",
            "e0e368e7fa9e4c45b7babb003d17a99f",
            "1859ea04a21349d8a4b7b657c896bf75",
            "44950988de7144ba9c075a5901fe6d58",
            "de5a58be128a4e23a3adcecacef41e2f",
            "d2c7cac0850d4c76ae22dccdf1a594d8",
            "d5aea24b949c430195ad3e4b6835deb4",
            "1f74d62057f64197a68ef807fae1f0cf",
            "e02e39a6969c42ba9c9096f4eb7aead1",
            "7facfea53845464981c9cb07b31137c9",
            "94da8c2174b6465a8b09099ca1c698c0",
            "aae01d39da4a4d39b95ba98f138e9920",
            "2909ae3e202545ca97f2d177a50ceaa9",
            "7264c4efd2d142cb9da4997994d13090",
            "c43d9796980542518e7fc98a22aa96af",
            "f66f51ecc2204b21928b34740b028474",
            "39b3a03232074940a32d832ed72b9bf4",
            "dadd760b9d8142ae987b8868409353c4",
            "a604b16f25c34d568e59294280330bd8",
            "168b4a4a02e74707a85c4a57f6f65deb",
            "42287c1ea97f4d959d4cb1d86c65ee3f",
            "9fedcf90bd234b92b2a9ca884c16e082",
            "dafedb9a4229445384d73bca5be86700",
            "64ae863966f849789ea5e1b93a18e47d",
            "f05103783e324ef5be9b6be4625934f8",
            "6744639e9adb4beda7d1eaa91cd48e20",
            "4fb2681bef4f4a7dbf203bfb812910ce",
            "c6951df00866437380f997604f2d0e88",
            "58365ddd22454f7e8148e5e417ae0a63",
            "1d6cfcf43f62450b8432462e839f776a",
            "65bec8e640c04dd3bfd525e9d85a228c",
            "0128ba3037d54f689efe4fc9abe25bb5",
            "c2c994d8d37d42aa9c707b3cd95fc315",
            "3b7e428fa9554798b652e307c9a0d789",
            "b214014bdc094792b33a1e6ac1bb283f",
            "1e81219c44ff4cf19bdb083c4a372e1f",
            "7a2938dd5138476ebd05358c4855ef0f",
            "52458245c5984599bdfbbcb3563a38ee",
            "b86ea15b73a747a69ba379bdd890dc1b",
            "95248307486c46b59e794349a399d238",
            "f6851b1763c64aaaa53bed69b05f56be",
            "f940b7a547524f728476c9f00db7898f",
            "2fe76d7b205a4c37b6a3d60e27bc0f12",
            "6042b5798fd444f6bc658ee9669211bf",
            "c51a2be116e740a19a4aaac982c89717",
            "7ee59eb8a0954366a92cfc8aec52d5a9",
            "19373f266a3b45c29f5cf8b164e68809",
            "1288e4dbb6fa42abb8786a14d6a58fcc",
            "5842bd0413754232a206c565d66df1d0",
            "c56ed62af4d943ec829f02f69cfb1a18",
            "2ba20cf48e69464fbf638960b9516429",
            "0ff4fb2118f74589a8b2cefe87cbecb0",
            "49ebe7eee1844081be79361452bb7995",
            "107781f3d3934cbbad94b3a74c2ee564",
            "b327302946c14991bf527ffb51751d68"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T19:06:51.740298Z",
          "iopub.status.busy": "2023-04-19T19:06:51.739876Z",
          "iopub.status.idle": "2023-04-19T19:07:05.323545Z",
          "shell.execute_reply": "2023-04-19T19:07:05.322525Z",
          "shell.execute_reply.started": "2023-04-19T19:06:51.740248Z"
        },
        "id": "Ifqn-NB_9GHI",
        "outputId": "681d1dec-fcb0-4981-fb07-f3da2240caa6",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ba20cf48e69464fbf638960b9516429",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ff4fb2118f74589a8b2cefe87cbecb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49ebe7eee1844081be79361452bb7995",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "107781f3d3934cbbad94b3a74c2ee564",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b327302946c14991bf527ffb51751d68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# Name of the BERT model to use\n",
        "model_name = 'DeepPavlov/rubert-base-cased-sentence'\n",
        "\n",
        "# Load transformers config and set output_hidden_states to False\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "config.output_hidden_states = False\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config=config)\n",
        "\n",
        "# Load the Transformers BERT model\n",
        "transformer_model = TFBertModel.from_pretrained(model_name, config=config, from_pt=True)\n",
        "\n",
        "# Load the MainLayer\n",
        "bert = transformer_model.layers[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b3c19fa-f883-4675-9506-85c4f02f0af9",
      "metadata": {
        "id": "1b3c19fa-f883-4675-9506-85c4f02f0af9"
      },
      "source": [
        "## 3.2 Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f366b0f-7d0b-44e0-bb82-0d82c3ea1bb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T19:07:05.326507Z",
          "iopub.status.busy": "2023-04-19T19:07:05.326076Z",
          "iopub.status.idle": "2023-04-19T19:07:08.453455Z",
          "shell.execute_reply": "2023-04-19T19:07:08.452091Z",
          "shell.execute_reply.started": "2023-04-19T19:07:05.326465Z"
        },
        "id": "8f366b0f-7d0b-44e0-bb82-0d82c3ea1bb1",
        "outputId": "cfd9f867-64e3-4032-c0ef-135025330da8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19LzgUlM3417TlG6bmo-eSY5vRAKw2ukR\n",
            "To: /kaggle/working/train_all.tsv\n",
            "100%|███████████████████████████████████████| 1.54M/1.54M [00:00<00:00, 103MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 19LzgUlM3417TlG6bmo-eSY5vRAKw2ukR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t9RX0IdD9GHI",
      "metadata": {
        "id": "t9RX0IdD9GHI"
      },
      "source": [
        "## 3.3 Quarantine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cKrIw_Ve9GHI",
      "metadata": {
        "id": "cKrIw_Ve9GHI"
      },
      "source": [
        "### 3.3.1 Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4aa2274-477a-46e6-95ff-ec98e633ab35",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-18T18:27:46.109481Z",
          "iopub.status.busy": "2023-04-18T18:27:46.109014Z",
          "iopub.status.idle": "2023-04-18T18:27:46.234967Z",
          "shell.execute_reply": "2023-04-18T18:27:46.233851Z",
          "shell.execute_reply.started": "2023-04-18T18:27:46.109440Z"
        },
        "id": "f4aa2274-477a-46e6-95ff-ec98e633ab35",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "CLASS_NAME = \"quarantine\"\n",
        "# Import data from csv\n",
        "whole_data = pd.read_csv('/content/train_all.tsv', sep='\\t')\n",
        "\n",
        "# Train_test_split\n",
        "test_size = 0.3\n",
        "data, data_test = train_test_split(whole_data, test_size=test_size, random_state = seed_value)\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------------#\n",
        "## Train\n",
        "# Select required columns\n",
        "data = data[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "\n",
        "# Set your model output as categorical and save in new label col\n",
        "data['stance_label'] = pd.Categorical(data[f'{CLASS_NAME}_stance'])\n",
        "data['argument_label'] = pd.Categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Transform your output to numeric\n",
        "data[f'{CLASS_NAME}_stance'] = data['stance_label'].cat.codes\n",
        "data[f'{CLASS_NAME}_argument'] = data['argument_label'].cat.codes\n",
        "\n",
        "#------------------------------------------------------------------------------------#\n",
        "## Test\n",
        "# Select required columns\n",
        "data_test = data_test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "\n",
        "# Set your model output as categorical and save in new label col\n",
        "data_test['stance_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_stance'])\n",
        "data_test['argument_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Transform your output to numeric\n",
        "data_test[f'{CLASS_NAME}_stance'] = data_test['stance_label'].cat.codes\n",
        "data_test[f'{CLASS_NAME}_argument'] = data_test['argument_label'].cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hm3BY632zyn1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-18T18:27:51.434843Z",
          "iopub.status.busy": "2023-04-18T18:27:51.434015Z",
          "iopub.status.idle": "2023-04-18T18:27:51.742806Z",
          "shell.execute_reply": "2023-04-18T18:27:51.741543Z",
          "shell.execute_reply.started": "2023-04-18T18:27:51.434801Z"
        },
        "id": "hm3BY632zyn1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#wandb.init(project=\"Text_categorization\", name = \"baseline_run\", tags = [\"Ruberta\", \"RB\"])\n",
        "# Ready output data for the model\n",
        "test_y_stance = to_categorical(data_test[f'{CLASS_NAME}_stance'])\n",
        "test_y_argument = to_categorical(data_test[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "test_x = tokenizer(\n",
        "    text=data_test['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6mfHDU3GWdy6",
      "metadata": {
        "id": "6mfHDU3GWdy6"
      },
      "source": [
        "### 3.3.2 Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8DuMYSSnzyrU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T18:27:56.180203Z",
          "iopub.status.busy": "2023-04-18T18:27:56.179785Z",
          "iopub.status.idle": "2023-04-18T18:28:01.686653Z",
          "shell.execute_reply": "2023-04-18T18:28:01.685782Z",
          "shell.execute_reply.started": "2023-04-18T18:27:56.180168Z"
        },
        "id": "8DuMYSSnzyrU",
        "outputId": "489231c6-6e29-4d0d-c330-2ee6d27c153d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"BERT_MultiLabel_MultiClass\"\n",
            "\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "\n",
            "==================================================================================================\n",
            "\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['input_ids[0][0]']              \n",
            "\n",
            "                                thPoolingAndCrossAt                                               \n",
            "\n",
            "                                tentions(last_hidde                                               \n",
            "\n",
            "                                n_state=(None, 256,                                               \n",
            "\n",
            "                                 768),                                                            \n",
            "\n",
            "                                 pooler_output=(Non                                               \n",
            "\n",
            "                                e, 768),                                                          \n",
            "\n",
            "                                 past_key_values=No                                               \n",
            "\n",
            "                                ne, hidden_states=N                                               \n",
            "\n",
            "                                one, attentions=Non                                               \n",
            "\n",
            "                                e, cross_attentions                                               \n",
            "\n",
            "                                =None)                                                            \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " pooled_output (Dropout)        (None, 768)          0           ['bert[1][1]']                   \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " argument (Dense)               (None, 4)            3076        ['pooled_output[0][0]']          \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " stance (Dense)                 (None, 4)            3076        ['pooled_output[0][0]']          \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            "==================================================================================================\n",
            "\n",
            "Total params: 177,859,592\n",
            "\n",
            "Trainable params: 177,859,592\n",
            "\n",
            "Non-trainable params: 0\n",
            "\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build your model input\n",
        "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[1]\n",
        "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "pooled_output = dropout(bert_model, training=False)\n",
        "\n",
        "# Then build your model output\n",
        "stance = Dense(units=len(data.stance_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
        "argument = Dense(units=len(data.argument_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
        "outputs = {'stance': stance, 'argument': argument}\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KLOaX_HE9GHJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T18:28:20.212474Z",
          "iopub.status.busy": "2023-04-18T18:28:20.212054Z",
          "iopub.status.idle": "2023-04-18T18:31:58.735610Z",
          "shell.execute_reply": "2023-04-18T18:31:58.732299Z",
          "shell.execute_reply.started": "2023-04-18T18:28:20.212440Z"
        },
        "id": "KLOaX_HE9GHJ",
        "outputId": "02d03914-a17f-4fa8-d774-78dcad833cac",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230418_200519-egdadxhc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/egdadxhc' target=\"_blank\">baseline_run_quarantine</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/egdadxhc' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/egdadxhc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "672/672 [==============================] - ETA: 0s - loss: 1.7180 - argument_loss: 0.8148 - stance_loss: 0.9032 - argument_accuracy: 0.6868 - stance_accuracy: 0.6875"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230418_200519-egdadxhc/files/model-best)... Done. 13.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 558s 674ms/step - loss: 1.7180 - argument_loss: 0.8148 - stance_loss: 0.9032 - argument_accuracy: 0.6868 - stance_accuracy: 0.6875 - val_loss: 1.5449 - val_argument_loss: 0.7069 - val_stance_loss: 0.8380 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 2/20\n",
            "\n",
            "672/672 [==============================] - ETA: 0s - loss: 1.4550 - argument_loss: 0.6857 - stance_loss: 0.7692 - argument_accuracy: 0.7499 - stance_accuracy: 0.7340"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230418_200519-egdadxhc/files/model-best)... Done. 12.4s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 426s 633ms/step - loss: 1.4550 - argument_loss: 0.6857 - stance_loss: 0.7692 - argument_accuracy: 0.7499 - stance_accuracy: 0.7340 - val_loss: 0.3162 - val_argument_loss: 0.0847 - val_stance_loss: 0.2316 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 3/20\n",
            "\n",
            "672/672 [==============================] - 358s 533ms/step - loss: 1.2980 - argument_loss: 0.6068 - stance_loss: 0.6912 - argument_accuracy: 0.7828 - stance_accuracy: 0.7621 - val_loss: 1.5579 - val_argument_loss: 0.7391 - val_stance_loss: 0.8189 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 4/20\n",
            "\n",
            "672/672 [==============================] - 354s 527ms/step - loss: 1.7145 - argument_loss: 0.8130 - stance_loss: 0.9014 - argument_accuracy: 0.6868 - stance_accuracy: 0.6873 - val_loss: 1.5648 - val_argument_loss: 0.7260 - val_stance_loss: 0.8388 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 5/20\n",
            "\n",
            "672/672 [==============================] - 354s 527ms/step - loss: 1.7060 - argument_loss: 0.8098 - stance_loss: 0.8962 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5385 - val_argument_loss: 0.7278 - val_stance_loss: 0.8107 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 6/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.7019 - argument_loss: 0.8063 - stance_loss: 0.8955 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.6548 - val_argument_loss: 0.7624 - val_stance_loss: 0.8924 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 7/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.7025 - argument_loss: 0.8068 - stance_loss: 0.8957 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5914 - val_argument_loss: 0.7330 - val_stance_loss: 0.8583 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 8/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.6990 - argument_loss: 0.8054 - stance_loss: 0.8935 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5595 - val_argument_loss: 0.7375 - val_stance_loss: 0.8220 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 9/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.7003 - argument_loss: 0.8052 - stance_loss: 0.8951 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5721 - val_argument_loss: 0.7408 - val_stance_loss: 0.8313 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 10/20\n",
            "\n",
            "672/672 [==============================] - 352s 524ms/step - loss: 1.7001 - argument_loss: 0.8053 - stance_loss: 0.8948 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5324 - val_argument_loss: 0.7128 - val_stance_loss: 0.8196 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 11/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.6962 - argument_loss: 0.8033 - stance_loss: 0.8928 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5026 - val_argument_loss: 0.6976 - val_stance_loss: 0.8050 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 12/20\n",
            "\n",
            "672/672 [==============================] - 352s 524ms/step - loss: 1.6963 - argument_loss: 0.8041 - stance_loss: 0.8922 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5513 - val_argument_loss: 0.7291 - val_stance_loss: 0.8222 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 13/20\n",
            "\n",
            "672/672 [==============================] - 352s 525ms/step - loss: 1.6952 - argument_loss: 0.8044 - stance_loss: 0.8909 - argument_accuracy: 0.6875 - stance_accuracy: 0.6875 - val_loss: 1.5729 - val_argument_loss: 0.7364 - val_stance_loss: 0.8365 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 14/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.6946 - argument_loss: 0.8028 - stance_loss: 0.8918 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5836 - val_argument_loss: 0.7360 - val_stance_loss: 0.8476 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 15/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.6950 - argument_loss: 0.8029 - stance_loss: 0.8921 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5834 - val_argument_loss: 0.7289 - val_stance_loss: 0.8545 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 16/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.6960 - argument_loss: 0.8029 - stance_loss: 0.8931 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5522 - val_argument_loss: 0.7266 - val_stance_loss: 0.8257 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 17/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.6929 - argument_loss: 0.8021 - stance_loss: 0.8908 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5787 - val_argument_loss: 0.7435 - val_stance_loss: 0.8352 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 18/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.6929 - argument_loss: 0.8020 - stance_loss: 0.8909 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5994 - val_argument_loss: 0.7499 - val_stance_loss: 0.8495 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 19/20\n",
            "\n",
            "672/672 [==============================] - 353s 526ms/step - loss: 1.6935 - argument_loss: 0.8020 - stance_loss: 0.8916 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5741 - val_argument_loss: 0.7464 - val_stance_loss: 0.8277 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 20/20\n",
            "\n",
            "672/672 [==============================] - 353s 525ms/step - loss: 1.6906 - argument_loss: 0.8010 - stance_loss: 0.8895 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5661 - val_argument_loss: 0.7293 - val_stance_loss: 0.8368 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n"
          ]
        }
      ],
      "source": [
        "! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = Adam(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "wandb.init(project=\"Text_categorization\", name = \"baseline_run_quarantine\", tags = [\"Ruberta\", \"RB\"])\n",
        "epochs = 20\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8]}, {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs, callbacks=[WandbCallback()])\n",
        "for epoch in range(epochs): \n",
        "    wandb.log({'loss': history.history['loss'][epoch],\n",
        "               'argument_loss': history.history['argument_loss'][epoch],\n",
        "               'stance_loss': history.history['stance_loss'][epoch],\n",
        "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
        "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
        "               'val_loss': history.history['stance_accuracy'][epoch],\n",
        "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
        "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
        "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
        "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lmwgUAW24-ST",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "664a0142c8734e0b8cfb07fd42e57aa5",
            "57fb930a50d546be9ad485886f58a54f",
            "289ff43ec3604aa1a2430f53c39d9bfb",
            "27fc82e66c7747ef966440dcbfcbade8",
            "71e436214e95485da4d300218b6339f9",
            "076fab6237eb4abfadd1f25330041b9b",
            "f1f3e3315e4349da8459d980058b9cf5",
            "dbeeb5a93bca48ebb320a13e0e9937d1"
          ]
        },
        "id": "lmwgUAW24-ST",
        "outputId": "8073386a-63d3-4c1d-f570-b8513f607b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:z1wiapq3) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "664a0142c8734e0b8cfb07fd42e57aa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='2042.839 MB of 2042.839 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>argument_accuracy</td><td>▁█▁█</td></tr><tr><td>argument_loss</td><td>█▁█▁</td></tr><tr><td>epoch</td><td>▁█</td></tr><tr><td>loss</td><td>█▁█▁</td></tr><tr><td>stance_accuracy</td><td>▁█▁█</td></tr><tr><td>stance_loss</td><td>█▁█▁</td></tr><tr><td>val_argument_accuracy</td><td>▁▁▁▁</td></tr><tr><td>val_argument_loss</td><td>█▁█▁</td></tr><tr><td>val_loss</td><td>▁▁██</td></tr><tr><td>val_stance_accuracy</td><td>▁▁▁▁</td></tr><tr><td>val_stance_loss</td><td>▁█▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>argument_accuracy</td><td>0.93337</td></tr><tr><td>argument_loss</td><td>0.21651</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.22185</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>0.50582</td></tr><tr><td>stance_accuracy</td><td>0.87735</td></tr><tr><td>stance_loss</td><td>0.28931</td></tr><tr><td>val_argument_accuracy</td><td>1.0</td></tr><tr><td>val_argument_loss</td><td>0.03277</td></tr><tr><td>val_loss</td><td>0.87735</td></tr><tr><td>val_stance_accuracy</td><td>0.875</td></tr><tr><td>val_stance_loss</td><td>0.2157</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">baseline_run_vaccines_2_epochs</strong> at: <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/z1wiapq3' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/z1wiapq3</a><br/>Synced 5 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230419_092630-z1wiapq3/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:z1wiapq3). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230419_094224-lfshzxpe</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/lfshzxpe' target=\"_blank\">baseline_run_quarantine_2_epochs</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/lfshzxpe' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/lfshzxpe</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\n",
            "672/672 [==============================] - ETA: 0s - loss: 0.6714 - argument_loss: 0.2939 - stance_loss: 0.3776 - argument_accuracy: 0.9211 - stance_accuracy: 0.8686"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_094224-lfshzxpe/files/model-best)... Done. 12.9s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 474s 621ms/step - loss: 0.6714 - argument_loss: 0.2939 - stance_loss: 0.3776 - argument_accuracy: 0.9211 - stance_accuracy: 0.8686 - val_loss: 0.2600 - val_argument_loss: 0.0316 - val_stance_loss: 0.2284 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 2/2\n",
            "\n",
            "672/672 [==============================] - 341s 507ms/step - loss: 0.5334 - argument_loss: 0.2257 - stance_loss: 0.3077 - argument_accuracy: 0.9403 - stance_accuracy: 0.8872 - val_loss: 0.2630 - val_argument_loss: 0.0324 - val_stance_loss: 0.2306 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n"
          ]
        }
      ],
      "source": [
        "! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = Adam(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "wandb.init(project=\"Text_categorization\", name = \"baseline_run_quarantine_2_epochs\", tags = [\"Ruberta\", \"RB\"])\n",
        "epochs = 2\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8]}, {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs, callbacks=[WandbCallback()])\n",
        "for epoch in range(epochs): \n",
        "    wandb.log({'loss': history.history['loss'][epoch],\n",
        "               'argument_loss': history.history['argument_loss'][epoch],\n",
        "               'stance_loss': history.history['stance_loss'][epoch],\n",
        "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
        "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
        "               'val_loss': history.history['stance_accuracy'][epoch],\n",
        "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
        "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
        "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
        "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VZa3_IxI9GHJ",
      "metadata": {
        "id": "VZa3_IxI9GHJ"
      },
      "source": [
        "### 3.3.3 Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TnSf8ppm5NLO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:10:45.961256Z",
          "iopub.status.busy": "2023-04-18T19:10:45.960545Z",
          "iopub.status.idle": "2023-04-18T19:11:12.697586Z",
          "shell.execute_reply": "2023-04-18T19:11:12.695780Z",
          "shell.execute_reply.started": "2023-04-18T19:10:45.961200Z"
        },
        "id": "TnSf8ppm5NLO",
        "outputId": "cddb5707-2869-4d20-ef63-17424f097f52",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 23s 526ms/step\n"
          ]
        }
      ],
      "source": [
        "val_results = model.predict(x={'input_ids': test_x['input_ids']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ygAMFDn99GHK",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-18T19:11:12.701147Z",
          "iopub.status.busy": "2023-04-18T19:11:12.700194Z",
          "iopub.status.idle": "2023-04-18T19:11:12.712696Z",
          "shell.execute_reply": "2023-04-18T19:11:12.710990Z",
          "shell.execute_reply.started": "2023-04-18T19:11:12.701107Z"
        },
        "id": "ygAMFDn99GHK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
        "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aMBWw0LD5NRD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:11:12.719848Z",
          "iopub.status.busy": "2023-04-18T19:11:12.715071Z",
          "iopub.status.idle": "2023-04-18T19:11:12.742831Z",
          "shell.execute_reply": "2023-04-18T19:11:12.741041Z",
          "shell.execute_reply.started": "2023-04-18T19:11:12.719804Z"
        },
        "id": "aMBWw0LD5NRD",
        "outputId": "242f4ecb-31f1-45cd-c9f3-7ef1bc6464dd",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.99      1.00      0.99       910\n",
            "\n",
            "           1       0.00      0.00      0.00        33\n",
            "\n",
            "           2       0.62      0.98      0.76       267\n",
            "\n",
            "           3       0.00      0.00      0.00       134\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.87      1344\n",
            "\n",
            "   macro avg       0.40      0.49      0.44      1344\n",
            "\n",
            "weighted avg       0.79      0.87      0.82      1344\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PPWoe9y15NUC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:11:12.752486Z",
          "iopub.status.busy": "2023-04-18T19:11:12.749716Z",
          "iopub.status.idle": "2023-04-18T19:11:12.775830Z",
          "shell.execute_reply": "2023-04-18T19:11:12.774884Z",
          "shell.execute_reply.started": "2023-04-18T19:11:12.752438Z"
        },
        "id": "PPWoe9y15NUC",
        "outputId": "1436092d-8735-4c0a-c85e-9a3b3983fb2e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.99      1.00      0.99       910\n",
            "\n",
            "           1       0.00      0.00      0.00        18\n",
            "\n",
            "           2       0.85      0.97      0.91       375\n",
            "\n",
            "           3       0.00      0.00      0.00        41\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.94      1344\n",
            "\n",
            "   macro avg       0.46      0.49      0.47      1344\n",
            "\n",
            "weighted avg       0.91      0.94      0.92      1344\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ro1qIXGaUT1W",
      "metadata": {
        "id": "ro1qIXGaUT1W"
      },
      "source": [
        "### 3.3.4 Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hN97GUdu9GHK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:30:58.676596Z",
          "iopub.status.busy": "2023-04-18T19:30:58.676186Z",
          "iopub.status.idle": "2023-04-18T19:30:58.710106Z",
          "shell.execute_reply": "2023-04-18T19:30:58.708762Z",
          "shell.execute_reply.started": "2023-04-18T19:30:58.676557Z"
        },
        "id": "hN97GUdu9GHK",
        "outputId": "2466028a-ff96-4434-ff30-39ce4006f7c1",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b5785579-5813-4a52-b355-ea0e76fd8582\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>text</th>\n",
              "      <th>masks_stance</th>\n",
              "      <th>masks_argument</th>\n",
              "      <th>quarantine_stance</th>\n",
              "      <th>quarantine_argument</th>\n",
              "      <th>vaccines_stance</th>\n",
              "      <th>vaccines_argument</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17041</td>\n",
              "      <td>&gt; 26 марта его поместили на принудительный кар...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17057</td>\n",
              "      <td>И шевкунов вещает из телевизора про необходимо...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17058</td>\n",
              "      <td>Это результат его  же лобировал до последнего ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17071</td>\n",
              "      <td>При этом нормально обеспечены (к слову о якобы...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17079</td>\n",
              "      <td>для опасного врага нужен официальный карантин ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5785579-5813-4a52-b355-ea0e76fd8582')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5785579-5813-4a52-b355-ea0e76fd8582 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5785579-5813-4a52-b355-ea0e76fd8582');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   text_id                                               text  masks_stance  \\\n",
              "0    17041  > 26 марта его поместили на принудительный кар...           NaN   \n",
              "1    17057  И шевкунов вещает из телевизора про необходимо...           NaN   \n",
              "2    17058  Это результат его  же лобировал до последнего ...           NaN   \n",
              "3    17071  При этом нормально обеспечены (к слову о якобы...           NaN   \n",
              "4    17079  для опасного врага нужен официальный карантин ...           NaN   \n",
              "\n",
              "   masks_argument  quarantine_stance  quarantine_argument  vaccines_stance  \\\n",
              "0             NaN                NaN                  NaN              NaN   \n",
              "1             NaN                NaN                  NaN              NaN   \n",
              "2             NaN                NaN                  NaN              NaN   \n",
              "3             NaN                NaN                  NaN              NaN   \n",
              "4             NaN                NaN                  NaN              NaN   \n",
              "\n",
              "   vaccines_argument  \n",
              "0                NaN  \n",
              "1                NaN  \n",
              "2                NaN  \n",
              "3                NaN  \n",
              "4                NaN  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv(\"/content/drive/MyDrive/HW_2/val_empty.tsv\", sep='\\t')\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3wo6ErB29GHK",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-18T19:30:58.712407Z",
          "iopub.status.busy": "2023-04-18T19:30:58.711416Z",
          "iopub.status.idle": "2023-04-18T19:30:58.719558Z",
          "shell.execute_reply": "2023-04-18T19:30:58.718134Z",
          "shell.execute_reply.started": "2023-04-18T19:30:58.712369Z"
        },
        "id": "3wo6ErB29GHK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7-f6bLrd9GHK",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-18T19:25:38.520306Z",
          "iopub.status.busy": "2023-04-18T19:25:38.519915Z",
          "iopub.status.idle": "2023-04-18T19:25:38.706951Z",
          "shell.execute_reply": "2023-04-18T19:25:38.705661Z",
          "shell.execute_reply.started": "2023-04-18T19:25:38.520260Z"
        },
        "id": "7-f6bLrd9GHK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for_pred = tokenizer(\n",
        "    text=test_d['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "luOpNbda9GHK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:28:01.274416Z",
          "iopub.status.busy": "2023-04-18T19:28:01.274022Z",
          "iopub.status.idle": "2023-04-18T19:28:33.862666Z",
          "shell.execute_reply": "2023-04-18T19:28:33.859414Z",
          "shell.execute_reply.started": "2023-04-18T19:28:01.274380Z"
        },
        "id": "luOpNbda9GHK",
        "outputId": "a67aa777-77a3-4193-cd13-52828b38f32e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 29s 553ms/step\n"
          ]
        }
      ],
      "source": [
        "test_results = model.predict(x={'input_ids': for_pred['input_ids']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MEvGRgeU9GHK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:31:04.832531Z",
          "iopub.status.busy": "2023-04-18T19:31:04.831958Z",
          "iopub.status.idle": "2023-04-18T19:31:04.845182Z",
          "shell.execute_reply": "2023-04-18T19:31:04.843039Z",
          "shell.execute_reply.started": "2023-04-18T19:31:04.832493Z"
        },
        "id": "MEvGRgeU9GHK",
        "outputId": "7c811b4d-c05f-42a7-c2cc-5360b9eae75e",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'stance': array([[-4.089829  , -0.33473855,  2.5395935 ,  1.3415891 ],\n",
              "        [-4.0897512 , -0.3347472 ,  2.5395615 ,  1.3415637 ],\n",
              "        [-4.0894866 , -0.33475885,  2.5394356 ,  1.3414531 ],\n",
              "        ...,\n",
              "        [ 5.198219  , -1.4057834 , -1.263636  , -1.1913619 ],\n",
              "        [ 5.200686  , -1.4059892 , -1.2654437 , -1.1920764 ],\n",
              "        [ 5.1925864 , -1.4060783 , -1.2590035 , -1.1900823 ]],\n",
              "       dtype=float32),\n",
              " 'argument': array([[-4.1424227 , -0.21485949,  2.9515023 ,  0.39686468],\n",
              "        [-4.1423306 , -0.21488512,  2.9514856 ,  0.3968405 ],\n",
              "        [-4.1420374 , -0.21497214,  2.9513922 ,  0.39675808],\n",
              "        ...,\n",
              "        [ 5.410088  , -1.8092142 , -0.41383114, -1.7783811 ],\n",
              "        [ 5.4125404 , -1.8092424 , -0.41525313, -1.7785566 ],\n",
              "        [ 5.40485   , -1.8096377 , -0.41075704, -1.7784284 ]],\n",
              "       dtype=float32)}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xlku2NIG9GHL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:31:08.248136Z",
          "iopub.status.busy": "2023-04-18T19:31:08.247555Z",
          "iopub.status.idle": "2023-04-18T19:31:08.259731Z",
          "shell.execute_reply": "2023-04-18T19:31:08.258014Z",
          "shell.execute_reply.started": "2023-04-18T19:31:08.248098Z"
        },
        "id": "xlku2NIG9GHL",
        "outputId": "4a065ab6-1254-4fbb-8597-47a6a9f8091b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-1f1aa18992cb>:1: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
            "\n",
            "<ipython-input-27-1f1aa18992cb>:2: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n"
          ]
        }
      ],
      "source": [
        "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QnGgkiy55NXe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:31:18.790659Z",
          "iopub.status.busy": "2023-04-18T19:31:18.790269Z",
          "iopub.status.idle": "2023-04-18T19:31:18.803007Z",
          "shell.execute_reply": "2023-04-18T19:31:18.801536Z",
          "shell.execute_reply.started": "2023-04-18T19:31:18.790619Z"
        },
        "id": "QnGgkiy55NXe",
        "outputId": "6d9e8c98-c776-4147-c433-d76201c12596",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-28-c079fcfdc6d7>:1: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_stance'] -= 1\n",
            "\n",
            "<ipython-input-28-c079fcfdc6d7>:2: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_argument'] -= 1\n"
          ]
        }
      ],
      "source": [
        "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
        "test_d[f'{CLASS_NAME}_argument'] -= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SzVczctF9GHL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:31:24.908800Z",
          "iopub.status.busy": "2023-04-18T19:31:24.908174Z",
          "iopub.status.idle": "2023-04-18T19:31:24.925512Z",
          "shell.execute_reply": "2023-04-18T19:31:24.923776Z",
          "shell.execute_reply.started": "2023-04-18T19:31:24.908750Z"
        },
        "id": "SzVczctF9GHL",
        "outputId": "258ecc55-8589-4489-f7ff-80d251092b63",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7a04ae44-216c-4c44-a5fe-7391971319c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>quarantine_stance</th>\n",
              "      <th>quarantine_argument</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&gt; 26 марта его поместили на принудительный кар...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>И шевкунов вещает из телевизора про необходимо...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Это результат его  же лобировал до последнего ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>При этом нормально обеспечены (к слову о якобы...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>для опасного врага нужен официальный карантин ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a04ae44-216c-4c44-a5fe-7391971319c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a04ae44-216c-4c44-a5fe-7391971319c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a04ae44-216c-4c44-a5fe-7391971319c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  quarantine_stance  \\\n",
              "0  > 26 марта его поместили на принудительный кар...                  1   \n",
              "1  И шевкунов вещает из телевизора про необходимо...                  1   \n",
              "2  Это результат его  же лобировал до последнего ...                  1   \n",
              "3  При этом нормально обеспечены (к слову о якобы...                  1   \n",
              "4  для опасного врага нужен официальный карантин ...                  1   \n",
              "\n",
              "   quarantine_argument  \n",
              "0                    1  \n",
              "1                    1  \n",
              "2                    1  \n",
              "3                    1  \n",
              "4                    1  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_d.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RyzvpKmz4nJu",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-18T19:32:12.595149Z",
          "iopub.status.busy": "2023-04-18T19:32:12.594698Z",
          "iopub.status.idle": "2023-04-18T19:32:12.619944Z",
          "shell.execute_reply": "2023-04-18T19:32:12.618922Z",
          "shell.execute_reply.started": "2023-04-18T19:32:12.595109Z"
        },
        "id": "RyzvpKmz4nJu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Giwutp1z5nLB",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-18T19:32:22.662965Z",
          "iopub.status.busy": "2023-04-18T19:32:22.662395Z",
          "iopub.status.idle": "2023-04-18T19:32:22.680932Z",
          "shell.execute_reply": "2023-04-18T19:32:22.679788Z",
          "shell.execute_reply.started": "2023-04-18T19:32:22.662929Z"
        },
        "id": "Giwutp1z5nLB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "CLASS_NAME = \"quarantine\"\n",
        "df1 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q9TvyZMBWrjy",
      "metadata": {
        "id": "Q9TvyZMBWrjy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "i_6Zh1PNUX4C",
      "metadata": {
        "id": "i_6Zh1PNUX4C"
      },
      "source": [
        "### 3.3.5 new acrhitecture MHA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jWweocUlVxdN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWweocUlVxdN",
        "outputId": "aacf9fbe-e0df-4d87-c33f-afa99ad24389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"BERT_MultiLabel_MultiClass\"\n",
            "\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "\n",
            "==================================================================================================\n",
            "\n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['attention_mask[0][0]',         \n",
            "\n",
            "                                thPoolingAndCrossAt               'input_ids[0][0]']              \n",
            "\n",
            "                                tentions(last_hidde                                               \n",
            "\n",
            "                                n_state=(None, 256,                                               \n",
            "\n",
            "                                 768),                                                            \n",
            "\n",
            "                                 pooler_output=(Non                                               \n",
            "\n",
            "                                e, 768),                                                          \n",
            "\n",
            "                                 past_key_values=No                                               \n",
            "\n",
            "                                ne, hidden_states=N                                               \n",
            "\n",
            "                                one, attentions=Non                                               \n",
            "\n",
            "                                e, cross_attentions                                               \n",
            "\n",
            "                                =None)                                                            \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " multi_head_attention_3 (MultiH  (None, 256, 768)    591168      ['bert[3][0]',                   \n",
            "\n",
            " eadAttention)                                                    'bert[3][0]']                   \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " flatten_3 (Flatten)            (None, 196608)       0           ['multi_head_attention_3[0][0]'] \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " pooled_output (Dropout)        (None, 196608)       0           ['flatten_3[0][0]']              \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " argument (Dense)               (None, 4)            786436      ['pooled_output[0][0]']          \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            " stance (Dense)                 (None, 4)            786436      ['pooled_output[0][0]']          \n",
            "\n",
            "                                                                                                  \n",
            "\n",
            "==================================================================================================\n",
            "\n",
            "Total params: 180,017,480\n",
            "\n",
            "Trainable params: 180,017,480\n",
            "\n",
            "Non-trainable params: 0\n",
            "\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build your model\n",
        "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
        "attention_mask = Input(shape=(256,), name='attention_mask', dtype='int32')\n",
        "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[0]\n",
        "\n",
        "# Add multi-head attention layer\n",
        "attention_output = MultiHeadAttention(num_heads=3, key_dim=64)(bert_model, bert_model)\n",
        "\n",
        "# Flatten the output from multi-head attention layer\n",
        "flatten = Flatten()(attention_output)\n",
        "\n",
        "# Apply dropout layer\n",
        "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "pooled_output = dropout(flatten, training=False)\n",
        "\n",
        "# Then build your model output\n",
        "stance = Dense(units=len(data.stance_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
        "argument = Dense(units=len(data.argument_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
        "outputs = {'stance': stance, 'argument': argument}\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_b9BwoFqghah",
      "metadata": {
        "id": "_b9BwoFqghah"
      },
      "source": [
        "#### 3.3.5.0 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1w1dRryIUavy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "1w1dRryIUavy",
        "outputId": "2080dddd-6a8e-4d7f-d466-91c3b60ad076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230419_122916-t4jmozy8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/t4jmozy8' target=\"_blank\">Bert_attention_quarantine</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/t4jmozy8' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/t4jmozy8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "756/756 [==============================] - ETA: 0s - loss: 0.7156 - argument_loss: 0.2951 - stance_loss: 0.4205 - argument_accuracy: 0.9310 - stance_accuracy: 0.8718"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_122916-t4jmozy8/files/model-best)... Done. 16.8s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "756/756 [==============================] - 611s 655ms/step - loss: 0.7156 - argument_loss: 0.2951 - stance_loss: 0.4205 - argument_accuracy: 0.9310 - stance_accuracy: 0.8718 - val_loss: 0.1541 - val_argument_loss: 0.0322 - val_stance_loss: 0.1219 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 2/10\n",
            "\n",
            "756/756 [==============================] - ETA: 0s - loss: 0.5780 - argument_loss: 0.2401 - stance_loss: 0.3379 - argument_accuracy: 0.9381 - stance_accuracy: 0.8822"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_122916-t4jmozy8/files/model-best)... Done. 14.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "756/756 [==============================] - 463s 611ms/step - loss: 0.5780 - argument_loss: 0.2401 - stance_loss: 0.3379 - argument_accuracy: 0.9381 - stance_accuracy: 0.8822 - val_loss: 0.0552 - val_argument_loss: 0.0073 - val_stance_loss: 0.0479 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 3/10\n",
            "\n",
            "756/756 [==============================] - 390s 515ms/step - loss: 0.4876 - argument_loss: 0.2079 - stance_loss: 0.2797 - argument_accuracy: 0.9355 - stance_accuracy: 0.9072 - val_loss: 0.3484 - val_argument_loss: 0.1232 - val_stance_loss: 0.2252 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 4/10\n",
            "\n",
            "756/756 [==============================] - 384s 508ms/step - loss: 0.4297 - argument_loss: 0.1912 - stance_loss: 0.2385 - argument_accuracy: 0.9418 - stance_accuracy: 0.9251 - val_loss: 0.0581 - val_argument_loss: 0.0043 - val_stance_loss: 0.0538 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 5/10\n",
            "\n",
            "756/756 [==============================] - 384s 508ms/step - loss: 0.4764 - argument_loss: 0.2212 - stance_loss: 0.2552 - argument_accuracy: 0.9289 - stance_accuracy: 0.9310 - val_loss: 0.4316 - val_argument_loss: 0.0566 - val_stance_loss: 0.3750 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 6/10\n",
            "\n",
            "756/756 [==============================] - 384s 508ms/step - loss: 0.4334 - argument_loss: 0.1974 - stance_loss: 0.2361 - argument_accuracy: 0.9317 - stance_accuracy: 0.9370 - val_loss: 0.2671 - val_argument_loss: 0.0141 - val_stance_loss: 0.2530 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 7/10\n",
            "\n",
            "756/756 [==============================] - 384s 507ms/step - loss: 0.4359 - argument_loss: 0.1944 - stance_loss: 0.2414 - argument_accuracy: 0.9400 - stance_accuracy: 0.9297 - val_loss: 0.3842 - val_argument_loss: 0.0650 - val_stance_loss: 0.3192 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 8/10\n",
            "\n",
            "756/756 [==============================] - 383s 507ms/step - loss: 0.5386 - argument_loss: 0.2492 - stance_loss: 0.2893 - argument_accuracy: 0.9234 - stance_accuracy: 0.9173 - val_loss: 2.2941 - val_argument_loss: 1.1387 - val_stance_loss: 1.1554 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 9/10\n",
            "\n",
            "756/756 [==============================] - 383s 506ms/step - loss: 0.5332 - argument_loss: 0.2369 - stance_loss: 0.2963 - argument_accuracy: 0.9416 - stance_accuracy: 0.9175 - val_loss: 3.4789 - val_argument_loss: 1.7735 - val_stance_loss: 1.7053 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 10/10\n",
            "\n",
            "756/756 [==============================] - ETA: 0s - loss: 0.8836 - argument_loss: 0.4174 - stance_loss: 0.4662 - argument_accuracy: 0.8940 - stance_accuracy: 0.8794"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_122916-t4jmozy8/files/model-best)... Done. 13.2s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "756/756 [==============================] - 458s 606ms/step - loss: 0.8836 - argument_loss: 0.4174 - stance_loss: 0.4662 - argument_accuracy: 0.8940 - stance_accuracy: 0.8794 - val_loss: 0.0122 - val_argument_loss: 0.0073 - val_stance_loss: 0.0048 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = AdamW(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "wandb.init(project=\"Text_categorization\", name = \"Bert_attention_quarantine\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
        "epochs = 10\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8], 'attention_mask': test_x['attention_mask'][:8]}, \n",
        "                     {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs, callbacks=[WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p8I3z8PswbYn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "p8I3z8PswbYn",
        "outputId": "c3aa5bb7-6ab9-453c-9fd7-9eb109436fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230419_141842-iofgjh2d</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/iofgjh2d' target=\"_blank\">Bert_attention_quarantine_4epochs</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/iofgjh2d' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/iofgjh2d</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "756/756 [==============================] - ETA: 0s - loss: 0.8425 - argument_loss: 0.3830 - stance_loss: 0.4595 - argument_accuracy: 0.8397 - stance_accuracy: 0.8046"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_141842-iofgjh2d/files/model-best)... Done. 13.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "756/756 [==============================] - 540s 627ms/step - loss: 0.8425 - argument_loss: 0.3830 - stance_loss: 0.4595 - argument_accuracy: 0.8397 - stance_accuracy: 0.8046 - val_loss: 0.0935 - val_argument_loss: 0.0260 - val_stance_loss: 0.0676 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 2/4\n",
            "\n",
            "756/756 [==============================] - ETA: 0s - loss: 0.7088 - argument_loss: 0.2972 - stance_loss: 0.4115 - argument_accuracy: 0.9355 - stance_accuracy: 0.8799"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_141842-iofgjh2d/files/model-best)... Done. 13.1s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "756/756 [==============================] - 458s 606ms/step - loss: 0.7088 - argument_loss: 0.2972 - stance_loss: 0.4115 - argument_accuracy: 0.9355 - stance_accuracy: 0.8799 - val_loss: 0.0803 - val_argument_loss: 0.0221 - val_stance_loss: 0.0582 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 3/4\n",
            "\n",
            "756/756 [==============================] - 392s 519ms/step - loss: 0.6473 - argument_loss: 0.2833 - stance_loss: 0.3639 - argument_accuracy: 0.9390 - stance_accuracy: 0.8778 - val_loss: 0.1477 - val_argument_loss: 0.0455 - val_stance_loss: 0.1021 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 4/4\n",
            "\n",
            "756/756 [==============================] - 384s 509ms/step - loss: 0.5705 - argument_loss: 0.2425 - stance_loss: 0.3280 - argument_accuracy: 0.9434 - stance_accuracy: 0.8811 - val_loss: 0.1055 - val_argument_loss: 0.0314 - val_stance_loss: 0.0741 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = AdamW(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "wandb.init(project=\"Text_categorization\", name = \"Bert_attention_quarantine_4epochs\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
        "epochs = 4\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8], 'attention_mask': test_x['attention_mask'][:8]}, \n",
        "                     {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs, callbacks=[WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pa9Fn9Blwbh3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pa9Fn9Blwbh3",
        "outputId": "462a22d6-c217-4242-def5-b813e0ac58da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230419_161952-v54egoga</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/v54egoga' target=\"_blank\">Bert_attention_quarantine_4epochs</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/v54egoga' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/v54egoga</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - ETA: 0s - loss: 0.8158 - argument_loss: 0.3679 - stance_loss: 0.4480 - argument_accuracy: 0.8887 - stance_accuracy: 0.8790"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_161952-v54egoga/files/model-best)... Done. 13.5s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 463s 676ms/step - loss: 0.8158 - argument_loss: 0.3679 - stance_loss: 0.4480 - argument_accuracy: 0.8887 - stance_accuracy: 0.8790 - val_loss: 0.0692 - val_argument_loss: 0.0217 - val_stance_loss: 0.0475 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 2/4\n",
            "\n",
            "588/588 [==============================] - 304s 516ms/step - loss: 0.6858 - argument_loss: 0.2849 - stance_loss: 0.4009 - argument_accuracy: 0.9383 - stance_accuracy: 0.8847 - val_loss: 0.1559 - val_argument_loss: 0.0662 - val_stance_loss: 0.0897 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 3/4\n",
            "\n",
            "588/588 [==============================] - 299s 509ms/step - loss: 0.6372 - argument_loss: 0.2601 - stance_loss: 0.3771 - argument_accuracy: 0.9392 - stance_accuracy: 0.8853 - val_loss: 0.1381 - val_argument_loss: 0.0360 - val_stance_loss: 0.1021 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 4/4\n",
            "\n",
            "588/588 [==============================] - 298s 507ms/step - loss: 0.6059 - argument_loss: 0.2428 - stance_loss: 0.3631 - argument_accuracy: 0.9394 - stance_accuracy: 0.8828 - val_loss: 0.0824 - val_argument_loss: 0.0235 - val_stance_loss: 0.0589 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = AdamW(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "wandb.init(project=\"Text_categorization\", name = \"Bert_attention_quarantine_4epochs\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
        "epochs = 4\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8], 'attention_mask': test_x['attention_mask'][:8]}, \n",
        "                     {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs, callbacks=[WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZCfuF8AIwblE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZCfuF8AIwblE",
        "outputId": "075098be-7d46-4d39-c58e-3c5753363044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:v54egoga) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>argument_accuracy</td><td>▁███</td></tr><tr><td>argument_loss</td><td>█▃▂▁</td></tr><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>loss</td><td>█▄▂▁</td></tr><tr><td>stance_accuracy</td><td>▁▇█▅</td></tr><tr><td>stance_loss</td><td>█▄▂▁</td></tr><tr><td>val_argument_accuracy</td><td>▁▁▁▁</td></tr><tr><td>val_argument_loss</td><td>▁█▃▁</td></tr><tr><td>val_loss</td><td>▁█▇▂</td></tr><tr><td>val_stance_accuracy</td><td>▁▁▁▁</td></tr><tr><td>val_stance_loss</td><td>▁▆█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>argument_accuracy</td><td>0.93937</td></tr><tr><td>argument_loss</td><td>0.24283</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.06916</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>loss</td><td>0.60591</td></tr><tr><td>stance_accuracy</td><td>0.88279</td></tr><tr><td>stance_loss</td><td>0.36308</td></tr><tr><td>val_argument_accuracy</td><td>1.0</td></tr><tr><td>val_argument_loss</td><td>0.0235</td></tr><tr><td>val_loss</td><td>0.08239</td></tr><tr><td>val_stance_accuracy</td><td>1.0</td></tr><tr><td>val_stance_loss</td><td>0.05889</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Bert_attention_quarantine_4epochs</strong> at: <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/v54egoga' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/v54egoga</a><br/>Synced 5 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230419_161952-v54egoga/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:v54egoga). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230419_170632-pwhy5nnf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/pwhy5nnf' target=\"_blank\">Bert_attention_quarantine_20_epochs</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/pwhy5nnf' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/pwhy5nnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - ETA: 0s - loss: 0.5585 - argument_loss: 0.2076 - stance_loss: 0.3509 - argument_accuracy: 0.9404 - stance_accuracy: 0.8524"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_170632-pwhy5nnf/files/model-best)... Done. 14.9s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 439s 647ms/step - loss: 0.5585 - argument_loss: 0.2076 - stance_loss: 0.3509 - argument_accuracy: 0.9404 - stance_accuracy: 0.8524 - val_loss: 0.3952 - val_argument_loss: 0.0856 - val_stance_loss: 0.3096 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 2/20\n",
            "\n",
            "588/588 [==============================] - ETA: 0s - loss: 0.3559 - argument_loss: 0.1402 - stance_loss: 0.2157 - argument_accuracy: 0.9479 - stance_accuracy: 0.9253"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_170632-pwhy5nnf/files/model-best)... Done. 18.8s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 377s 642ms/step - loss: 0.3559 - argument_loss: 0.1402 - stance_loss: 0.2157 - argument_accuracy: 0.9479 - stance_accuracy: 0.9253 - val_loss: 0.2837 - val_argument_loss: 0.0568 - val_stance_loss: 0.2269 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 3/20\n",
            "\n",
            "588/588 [==============================] - 303s 515ms/step - loss: 0.3343 - argument_loss: 0.1342 - stance_loss: 0.2002 - argument_accuracy: 0.9532 - stance_accuracy: 0.9302 - val_loss: 0.4415 - val_argument_loss: 0.0743 - val_stance_loss: 0.3672 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 4/20\n",
            "\n",
            "588/588 [==============================] - ETA: 0s - loss: 0.3151 - argument_loss: 0.1266 - stance_loss: 0.1885 - argument_accuracy: 0.9566 - stance_accuracy: 0.9360"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_170632-pwhy5nnf/files/model-best)... Done. 13.5s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 369s 628ms/step - loss: 0.3151 - argument_loss: 0.1266 - stance_loss: 0.1885 - argument_accuracy: 0.9566 - stance_accuracy: 0.9360 - val_loss: 0.2486 - val_argument_loss: 0.0480 - val_stance_loss: 0.2006 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 5/20\n",
            "\n",
            "588/588 [==============================] - 305s 518ms/step - loss: 0.2970 - argument_loss: 0.1242 - stance_loss: 0.1728 - argument_accuracy: 0.9609 - stance_accuracy: 0.9436 - val_loss: 0.2786 - val_argument_loss: 0.0252 - val_stance_loss: 0.2534 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 6/20\n",
            "\n",
            "588/588 [==============================] - 298s 506ms/step - loss: 0.2803 - argument_loss: 0.1168 - stance_loss: 0.1634 - argument_accuracy: 0.9623 - stance_accuracy: 0.9464 - val_loss: 0.4763 - val_argument_loss: 0.0551 - val_stance_loss: 0.4212 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 7/20\n",
            "\n",
            "588/588 [==============================] - 298s 507ms/step - loss: 0.2641 - argument_loss: 0.1092 - stance_loss: 0.1549 - argument_accuracy: 0.9685 - stance_accuracy: 0.9526 - val_loss: 0.5735 - val_argument_loss: 0.0248 - val_stance_loss: 0.5487 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 8/20\n",
            "\n",
            "588/588 [==============================] - ETA: 0s - loss: 0.2622 - argument_loss: 0.1084 - stance_loss: 0.1539 - argument_accuracy: 0.9692 - stance_accuracy: 0.9502"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_170632-pwhy5nnf/files/model-best)... Done. 18.5s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 379s 644ms/step - loss: 0.2622 - argument_loss: 0.1084 - stance_loss: 0.1539 - argument_accuracy: 0.9692 - stance_accuracy: 0.9502 - val_loss: 0.1639 - val_argument_loss: 0.0133 - val_stance_loss: 0.1506 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 9/20\n",
            "\n",
            "588/588 [==============================] - ETA: 0s - loss: 0.2503 - argument_loss: 0.0986 - stance_loss: 0.1517 - argument_accuracy: 0.9721 - stance_accuracy: 0.9528"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_170632-pwhy5nnf/files/model-best)... Done. 13.7s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 373s 634ms/step - loss: 0.2503 - argument_loss: 0.0986 - stance_loss: 0.1517 - argument_accuracy: 0.9721 - stance_accuracy: 0.9528 - val_loss: 0.1324 - val_argument_loss: 0.0101 - val_stance_loss: 0.1223 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 10/20\n",
            "\n",
            "588/588 [==============================] - 303s 514ms/step - loss: 0.2443 - argument_loss: 0.0957 - stance_loss: 0.1485 - argument_accuracy: 0.9730 - stance_accuracy: 0.9545 - val_loss: 0.5944 - val_argument_loss: 0.0415 - val_stance_loss: 0.5530 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 11/20\n",
            "\n",
            "588/588 [==============================] - 298s 506ms/step - loss: 0.2259 - argument_loss: 0.0892 - stance_loss: 0.1367 - argument_accuracy: 0.9749 - stance_accuracy: 0.9560 - val_loss: 0.5289 - val_argument_loss: 0.0167 - val_stance_loss: 0.5122 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 12/20\n",
            "\n",
            "588/588 [==============================] - 298s 507ms/step - loss: 0.2256 - argument_loss: 0.0804 - stance_loss: 0.1452 - argument_accuracy: 0.9770 - stance_accuracy: 0.9545 - val_loss: 0.4335 - val_argument_loss: 0.0073 - val_stance_loss: 0.4262 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 13/20\n",
            "\n",
            "588/588 [==============================] - 297s 505ms/step - loss: 0.2151 - argument_loss: 0.0739 - stance_loss: 0.1413 - argument_accuracy: 0.9770 - stance_accuracy: 0.9538 - val_loss: 0.6617 - val_argument_loss: 0.0026 - val_stance_loss: 0.6591 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 14/20\n",
            "\n",
            "588/588 [==============================] - 297s 506ms/step - loss: 0.2170 - argument_loss: 0.0716 - stance_loss: 0.1454 - argument_accuracy: 0.9760 - stance_accuracy: 0.9538 - val_loss: 0.4156 - val_argument_loss: 0.0017 - val_stance_loss: 0.4139 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 15/20\n",
            "\n",
            "588/588 [==============================] - 298s 507ms/step - loss: 0.2033 - argument_loss: 0.0683 - stance_loss: 0.1350 - argument_accuracy: 0.9768 - stance_accuracy: 0.9534 - val_loss: 0.3560 - val_argument_loss: 0.0012 - val_stance_loss: 0.3548 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 16/20\n",
            "\n",
            "588/588 [==============================] - 298s 506ms/step - loss: 0.1819 - argument_loss: 0.0596 - stance_loss: 0.1223 - argument_accuracy: 0.9779 - stance_accuracy: 0.9530 - val_loss: 0.5189 - val_argument_loss: 0.0020 - val_stance_loss: 0.5168 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 17/20\n",
            "\n",
            "588/588 [==============================] - 299s 509ms/step - loss: 0.1889 - argument_loss: 0.0636 - stance_loss: 0.1252 - argument_accuracy: 0.9738 - stance_accuracy: 0.9504 - val_loss: 0.8250 - val_argument_loss: 0.0011 - val_stance_loss: 0.8239 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 18/20\n",
            "\n",
            "588/588 [==============================] - 297s 505ms/step - loss: 0.1689 - argument_loss: 0.0550 - stance_loss: 0.1139 - argument_accuracy: 0.9751 - stance_accuracy: 0.9492 - val_loss: 0.9895 - val_argument_loss: 0.0014 - val_stance_loss: 0.9881 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 19/20\n",
            "\n",
            "588/588 [==============================] - 297s 505ms/step - loss: 0.1594 - argument_loss: 0.0515 - stance_loss: 0.1078 - argument_accuracy: 0.9734 - stance_accuracy: 0.9524 - val_loss: 0.9930 - val_argument_loss: 7.9469e-04 - val_stance_loss: 0.9922 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "\n",
            "Epoch 20/20\n",
            "\n",
            "588/588 [==============================] - 297s 505ms/step - loss: 0.1588 - argument_loss: 0.0549 - stance_loss: 0.1039 - argument_accuracy: 0.9738 - stance_accuracy: 0.9536 - val_loss: 0.5286 - val_argument_loss: 5.1544e-04 - val_stance_loss: 0.5281 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n"
          ]
        }
      ],
      "source": [
        "! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = AdamW(\n",
        "    learning_rate=5e-06,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "wandb.init(project=\"Text_categorization\", name = \"Bert_attention_quarantine_20_epochs\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
        "epochs = 20\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8], 'attention_mask': test_x['attention_mask'][:8]}, \n",
        "                     {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs, callbacks=[WandbCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4BgYHG6mfdwF",
      "metadata": {
        "id": "4BgYHG6mfdwF"
      },
      "source": [
        "### 3.3.5.1 Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SSYugGwgUa1Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSYugGwgUa1Q",
        "outputId": "691ddbce-eecb-427f-ff2f-9e4a8cbe492b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 14s 552ms/step\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       1.00      0.98      0.99       468\n",
            "\n",
            "           1       0.00      0.00      0.00        19\n",
            "\n",
            "           2       0.59      0.99      0.74       126\n",
            "\n",
            "           3       0.00      0.00      0.00        59\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.87       672\n",
            "\n",
            "   macro avg       0.40      0.49      0.43       672\n",
            "\n",
            "weighted avg       0.80      0.87      0.83       672\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       1.00      0.98      0.99       468\n",
            "\n",
            "           1       0.00      0.00      0.00        15\n",
            "\n",
            "           2       0.79      0.99      0.88       170\n",
            "\n",
            "           3       0.00      0.00      0.00        19\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.93       672\n",
            "\n",
            "   macro avg       0.45      0.49      0.47       672\n",
            "\n",
            "weighted avg       0.90      0.93      0.91       672\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "val_results = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
        "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
        "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
        "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0), classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OvcFdsIO33A2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvcFdsIO33A2",
        "outputId": "f79d9e98-e9c7-49f8-cd68-cf1a2b2c51ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 38s 571ms/step\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.97      0.99      0.98      1359\n",
            "\n",
            "           1       0.00      0.00      0.00        47\n",
            "\n",
            "           2       0.70      0.74      0.72       408\n",
            "\n",
            "           3       0.41      0.41      0.41       202\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.86      2016\n",
            "\n",
            "   macro avg       0.52      0.53      0.53      2016\n",
            "\n",
            "weighted avg       0.84      0.86      0.85      2016\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.98      0.98      0.98      1359\n",
            "\n",
            "           1       0.00      0.00      0.00        43\n",
            "\n",
            "           2       0.82      0.95      0.88       543\n",
            "\n",
            "           3       0.59      0.14      0.23        71\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.93      2016\n",
            "\n",
            "   macro avg       0.60      0.52      0.52      2016\n",
            "\n",
            "weighted avg       0.90      0.93      0.91      2016\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "val_results = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
        "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
        "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
        "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0), classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6ILpu24fyCV",
      "metadata": {
        "id": "a6ILpu24fyCV"
      },
      "source": [
        "#### 3.3.5.2 Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ofKoV8ZiUa6s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofKoV8ZiUa6s",
        "outputId": "ff1dc61b-ee54-4b97-f8ab-8e53c303f96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 29s 574ms/step\n"
          ]
        }
      ],
      "source": [
        "test = pd.read_csv(\"/content/drive/MyDrive/HW_2/val_empty.tsv\", sep='\\t')\n",
        "test.head()\n",
        "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "for_pred = tokenizer(\n",
        "    text=test_d['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "test_results = model.predict(x={'input_ids': for_pred['input_ids'], 'attention_mask': for_pred['attention_mask']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4hU-oMDsUa9D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hU-oMDsUa9D",
        "outputId": "32258c78-ebcd-4eea-badc-3727b037ca6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-8c8124cf8f8b>:1: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
            "\n",
            "<ipython-input-33-8c8124cf8f8b>:2: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
            "\n",
            "<ipython-input-33-8c8124cf8f8b>:3: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_stance'] -= 1\n",
            "\n",
            "<ipython-input-33-8c8124cf8f8b>:4: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_argument'] -= 1\n"
          ]
        }
      ],
      "source": [
        "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
        "test_d[f'{CLASS_NAME}_argument'] -= 1\n",
        "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_AdamW_lr_5e6_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dL1YyFDHUa_g",
      "metadata": {
        "id": "dL1YyFDHUa_g"
      },
      "outputs": [],
      "source": [
        "CLASS_NAME = \"quarantine\"\n",
        "df1 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_AdamW_lr_5e6_{CLASS_NAME}.tsv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Dl1vax0e9GHL",
      "metadata": {
        "id": "Dl1vax0e9GHL"
      },
      "source": [
        "## 3.4 Masks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1TjrWgJs9GHL",
      "metadata": {
        "id": "1TjrWgJs9GHL"
      },
      "source": [
        "### 3.4.1 Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M0pPhzWh9GHL",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-19T20:43:56.603519Z",
          "iopub.status.busy": "2023-04-19T20:43:56.603108Z",
          "iopub.status.idle": "2023-04-19T20:43:56.653685Z",
          "shell.execute_reply": "2023-04-19T20:43:56.652632Z",
          "shell.execute_reply.started": "2023-04-19T20:43:56.603482Z"
        },
        "id": "M0pPhzWh9GHL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "CLASS_NAME = \"masks\"\n",
        "# Import data from csv\n",
        "whole_data = pd.read_csv('/kaggle/working/train_all.tsv', sep='\\t')\n",
        "\n",
        "# Train_test_split\n",
        "test_size = 0.2\n",
        "data, data_test = train_test_split(whole_data, test_size=test_size, random_state = seed_value)\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------------#\n",
        "## Train\n",
        "# Select required columns\n",
        "data = data[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "\n",
        "# Set your model output as categorical and save in new label col\n",
        "data['stance_label'] = pd.Categorical(data[f'{CLASS_NAME}_stance'])\n",
        "data['argument_label'] = pd.Categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Transform your output to numeric\n",
        "data[f'{CLASS_NAME}_stance'] = data['stance_label'].cat.codes\n",
        "data[f'{CLASS_NAME}_argument'] = data['argument_label'].cat.codes\n",
        "\n",
        "#------------------------------------------------------------------------------------#\n",
        "## Test\n",
        "# Select required columns\n",
        "data_test = data_test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "\n",
        "# Set your model output as categorical and save in new label col\n",
        "data_test['stance_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_stance'])\n",
        "data_test['argument_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Transform your output to numeric\n",
        "data_test[f'{CLASS_NAME}_stance'] = data_test['stance_label'].cat.codes\n",
        "data_test[f'{CLASS_NAME}_argument'] = data_test['argument_label'].cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jFHr7V939GHL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T20:44:14.553005Z",
          "iopub.status.busy": "2023-04-19T20:44:14.552239Z",
          "iopub.status.idle": "2023-04-19T20:44:16.630681Z",
          "shell.execute_reply": "2023-04-19T20:44:16.629780Z",
          "shell.execute_reply.started": "2023-04-19T20:44:14.552965Z"
        },
        "id": "jFHr7V939GHL",
        "outputId": "c72dca70-17c1-4e10-b3b0-9941a2018503",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"BERT_MultiLabel_MultiClass\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['input_ids[0][0]']              \n",
            "                                thPoolingAndCrossAt                                               \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " pooled_output (Dropout)        (None, 768)          0           ['bert[3][1]']                   \n",
            "                                                                                                  \n",
            " argument (Dense)               (None, 4)            3076        ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            " stance (Dense)                 (None, 4)            3076        ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 177,859,592\n",
            "Trainable params: 177,859,592\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#wandb.init(project=\"Text_categorization\", name = \"baseline_run\", tags = [\"Ruberta\", \"RB\"])\n",
        "# Ready output data for the model\n",
        "test_y_stance = to_categorical(data_test[f'{CLASS_NAME}_stance'])\n",
        "test_y_argument = to_categorical(data_test[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "test_x = tokenizer(\n",
        "    text=data_test['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "# Build your model input\n",
        "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[1]\n",
        "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "pooled_output = dropout(bert_model, training=False)\n",
        "\n",
        "# Then build your model output\n",
        "stance = Dense(units=len(data.stance_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
        "argument = Dense(units=len(data.argument_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
        "outputs = {'stance': stance, 'argument': argument}\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "osmGpcNL9GHL",
      "metadata": {
        "id": "osmGpcNL9GHL"
      },
      "source": [
        "### 3.4.2 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0L-HQOGs9GHM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:35:54.986398Z",
          "iopub.status.busy": "2023-04-18T19:35:54.985999Z",
          "iopub.status.idle": "2023-04-18T19:42:53.392049Z",
          "shell.execute_reply": "2023-04-18T19:42:53.387855Z",
          "shell.execute_reply.started": "2023-04-18T19:35:54.986364Z"
        },
        "id": "0L-HQOGs9GHM",
        "outputId": "fbfc7401-af1a-44b6-ed7b-9d26b49ee3e8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:wandb.sdk.internal.internal_api:500 response executing GraphQL.\n",
            "\n",
            "ERROR:wandb.sdk.internal.internal_api:{\"error\":\"driver: bad connection\"}\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230419_070439-ofpqwwmf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/ofpqwwmf' target=\"_blank\">baseline_run_masks</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/ofpqwwmf' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/ofpqwwmf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "672/672 [==============================] - ETA: 0s - loss: 1.7642 - argument_loss: 0.8188 - stance_loss: 0.9454 - argument_accuracy: 0.6588 - stance_accuracy: 0.6213"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_070439-ofpqwwmf/files/model-best)... Done. 12.2s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 483s 633ms/step - loss: 1.7642 - argument_loss: 0.8188 - stance_loss: 0.9454 - argument_accuracy: 0.6588 - stance_accuracy: 0.6213 - val_loss: 1.7240 - val_argument_loss: 0.7653 - val_stance_loss: 0.9586 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 2/20\n",
            "\n",
            "672/672 [==============================] - 346s 514ms/step - loss: 1.1378 - argument_loss: 0.5051 - stance_loss: 0.6327 - argument_accuracy: 0.8558 - stance_accuracy: 0.7713 - val_loss: 1.9198 - val_argument_loss: 0.8926 - val_stance_loss: 1.0272 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 3/20\n",
            "\n",
            "672/672 [==============================] - ETA: 0s - loss: 1.1441 - argument_loss: 0.5083 - stance_loss: 0.6358 - argument_accuracy: 0.8558 - stance_accuracy: 0.7713"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_070439-ofpqwwmf/files/model-best)... Done. 12.1s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 409s 609ms/step - loss: 1.1441 - argument_loss: 0.5083 - stance_loss: 0.6358 - argument_accuracy: 0.8558 - stance_accuracy: 0.7713 - val_loss: 1.6039 - val_argument_loss: 0.7321 - val_stance_loss: 0.8718 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 4/20\n",
            "\n",
            "672/672 [==============================] - 342s 509ms/step - loss: 1.1474 - argument_loss: 0.5106 - stance_loss: 0.6369 - argument_accuracy: 0.8559 - stance_accuracy: 0.7714 - val_loss: 1.6246 - val_argument_loss: 0.7632 - val_stance_loss: 0.8614 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 5/20\n",
            "\n",
            "672/672 [==============================] - 339s 505ms/step - loss: 1.1438 - argument_loss: 0.5080 - stance_loss: 0.6357 - argument_accuracy: 0.8554 - stance_accuracy: 0.7711 - val_loss: 1.7899 - val_argument_loss: 0.8472 - val_stance_loss: 0.9426 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.6250\n",
            "\n",
            "Epoch 6/20\n",
            "\n",
            "252/672 [==========>...................] - ETA: 3:31 - loss: 1.1472 - argument_loss: 0.5117 - stance_loss: 0.6355 - argument_accuracy: 0.8552 - stance_accuracy: 0.7728"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4eb7758fc33b>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m# x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = Adam(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "wandb.init(project=\"Text_categorization\", name = \"baseline_run_masks\", tags = [\"Ruberta\", \"RB\"])\n",
        "epochs = 20\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8]}, {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs, callbacks=[WandbCallback()])\n",
        "for epoch in range(epochs): \n",
        "    wandb.log({'loss': history.history['loss'][epoch],\n",
        "               'argument_loss': history.history['argument_loss'][epoch],\n",
        "               'stance_loss': history.history['stance_loss'][epoch],\n",
        "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
        "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
        "               'val_loss': history.history['stance_accuracy'][epoch],\n",
        "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
        "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
        "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
        "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tnKqEMph9Spi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnKqEMph9Spi",
        "outputId": "97c2f5e5-6953-48f5-da58-d2e480ed2ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230419_104514-qz2ewsir</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/qz2ewsir' target=\"_blank\">baseline_run_masks_2_epochs</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/qz2ewsir' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/qz2ewsir</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\n",
            "714/714 [==============================] - ETA: 0s - loss: 1.1913 - argument_loss: 0.5295 - stance_loss: 0.6618 - argument_accuracy: 0.8376 - stance_accuracy: 0.7544"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_104514-qz2ewsir/files/model-best)... Done. 13.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "714/714 [==============================] - 522s 640ms/step - loss: 1.1913 - argument_loss: 0.5295 - stance_loss: 0.6618 - argument_accuracy: 0.8376 - stance_accuracy: 0.7544 - val_loss: 2.0221 - val_argument_loss: 1.0588 - val_stance_loss: 0.9633 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.5000\n",
            "\n",
            "Epoch 2/2\n",
            "\n",
            "714/714 [==============================] - ETA: 0s - loss: 0.9614 - argument_loss: 0.4150 - stance_loss: 0.5463 - argument_accuracy: 0.8816 - stance_accuracy: 0.7917"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_104514-qz2ewsir/files/model-best)... Done. 12.3s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "714/714 [==============================] - 433s 607ms/step - loss: 0.9614 - argument_loss: 0.4150 - stance_loss: 0.5463 - argument_accuracy: 0.8816 - stance_accuracy: 0.7917 - val_loss: 1.8573 - val_argument_loss: 1.0845 - val_stance_loss: 0.7728 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = Adam(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "wandb.init(project=\"Text_categorization\", name = \"baseline_run_masks_2_epochs\", tags = [\"Ruberta\", \"RB\"])\n",
        "epochs = 2\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8]}, {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs, callbacks=[WandbCallback()])\n",
        "for epoch in range(epochs): \n",
        "    wandb.log({'loss': history.history['loss'][epoch],\n",
        "               'argument_loss': history.history['argument_loss'][epoch],\n",
        "               'stance_loss': history.history['stance_loss'][epoch],\n",
        "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
        "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
        "               'val_loss': history.history['stance_accuracy'][epoch],\n",
        "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
        "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
        "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
        "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T5v7lBS49GHM",
      "metadata": {
        "id": "T5v7lBS49GHM"
      },
      "source": [
        "### 3.4.3 Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22N4D3Tb9GHM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:42:59.713265Z",
          "iopub.status.busy": "2023-04-18T19:42:59.712870Z",
          "iopub.status.idle": "2023-04-18T19:43:42.467165Z",
          "shell.execute_reply": "2023-04-18T19:43:42.465888Z",
          "shell.execute_reply.started": "2023-04-18T19:42:59.713213Z"
        },
        "id": "22N4D3Tb9GHM",
        "outputId": "566ea559-a2ca-4ce0-c0c3-39c35b9c04bf",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 20s 531ms/step\n"
          ]
        }
      ],
      "source": [
        "val_results = model.predict(x={'input_ids': test_x['input_ids']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A2Gn5EDk9GHM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:43:42.470776Z",
          "iopub.status.busy": "2023-04-18T19:43:42.469211Z",
          "iopub.status.idle": "2023-04-18T19:43:42.498225Z",
          "shell.execute_reply": "2023-04-18T19:43:42.496748Z",
          "shell.execute_reply.started": "2023-04-18T19:43:42.470733Z"
        },
        "id": "A2Gn5EDk9GHM",
        "outputId": "1092a943-6da0-47d4-a208-4a1235ae64e3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.99      0.99      0.99       534\n",
            "\n",
            "           1       0.00      0.00      0.00        89\n",
            "\n",
            "           2       0.60      1.00      0.75       287\n",
            "\n",
            "           3       0.00      0.00      0.00        98\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.81      1008\n",
            "\n",
            "   macro avg       0.40      0.50      0.43      1008\n",
            "\n",
            "weighted avg       0.70      0.81      0.74      1008\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
        "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
        "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_eQGxfiO9GHM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:43:42.499924Z",
          "iopub.status.busy": "2023-04-18T19:43:42.499561Z",
          "iopub.status.idle": "2023-04-18T19:43:42.523366Z",
          "shell.execute_reply": "2023-04-18T19:43:42.521942Z",
          "shell.execute_reply.started": "2023-04-18T19:43:42.499885Z"
        },
        "id": "_eQGxfiO9GHM",
        "outputId": "0ff5907b-a647-4123-b72d-32ad40a7b74f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.99      0.99      0.99       534\n",
            "\n",
            "           1       0.00      0.00      0.00        56\n",
            "\n",
            "           2       0.78      0.99      0.87       373\n",
            "\n",
            "           3       0.00      0.00      0.00        45\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.89      1008\n",
            "\n",
            "   macro avg       0.44      0.49      0.47      1008\n",
            "\n",
            "weighted avg       0.81      0.89      0.85      1008\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9F8-w-Hv9GHM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:43:56.268140Z",
          "iopub.status.busy": "2023-04-18T19:43:56.267325Z",
          "iopub.status.idle": "2023-04-18T19:43:56.322440Z",
          "shell.execute_reply": "2023-04-18T19:43:56.321400Z",
          "shell.execute_reply.started": "2023-04-18T19:43:56.268091Z"
        },
        "id": "9F8-w-Hv9GHM",
        "outputId": "8243955e-4723-4c55-cabc-413798b68429",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-02857577-469a-4372-bedb-c3e4a85abd6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>text</th>\n",
              "      <th>masks_stance</th>\n",
              "      <th>masks_argument</th>\n",
              "      <th>quarantine_stance</th>\n",
              "      <th>quarantine_argument</th>\n",
              "      <th>vaccines_stance</th>\n",
              "      <th>vaccines_argument</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17041</td>\n",
              "      <td>&gt; 26 марта его поместили на принудительный кар...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17057</td>\n",
              "      <td>И шевкунов вещает из телевизора про необходимо...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17058</td>\n",
              "      <td>Это результат его  же лобировал до последнего ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17071</td>\n",
              "      <td>При этом нормально обеспечены (к слову о якобы...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17079</td>\n",
              "      <td>для опасного врага нужен официальный карантин ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02857577-469a-4372-bedb-c3e4a85abd6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02857577-469a-4372-bedb-c3e4a85abd6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02857577-469a-4372-bedb-c3e4a85abd6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   text_id                                               text  masks_stance  \\\n",
              "0    17041  > 26 марта его поместили на принудительный кар...           NaN   \n",
              "1    17057  И шевкунов вещает из телевизора про необходимо...           NaN   \n",
              "2    17058  Это результат его  же лобировал до последнего ...           NaN   \n",
              "3    17071  При этом нормально обеспечены (к слову о якобы...           NaN   \n",
              "4    17079  для опасного врага нужен официальный карантин ...           NaN   \n",
              "\n",
              "   masks_argument  quarantine_stance  quarantine_argument  vaccines_stance  \\\n",
              "0             NaN                NaN                  NaN              NaN   \n",
              "1             NaN                NaN                  NaN              NaN   \n",
              "2             NaN                NaN                  NaN              NaN   \n",
              "3             NaN                NaN                  NaN              NaN   \n",
              "4             NaN                NaN                  NaN              NaN   \n",
              "\n",
              "   vaccines_argument  \n",
              "0                NaN  \n",
              "1                NaN  \n",
              "2                NaN  \n",
              "3                NaN  \n",
              "4                NaN  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv(\"/content/drive/MyDrive/HW_2/val_empty.tsv\", sep='\\t')\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Nx6W9cz-9GHM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:44:00.180907Z",
          "iopub.status.busy": "2023-04-18T19:44:00.180531Z",
          "iopub.status.idle": "2023-04-18T19:44:31.587662Z",
          "shell.execute_reply": "2023-04-18T19:44:31.584483Z",
          "shell.execute_reply.started": "2023-04-18T19:44:00.180873Z"
        },
        "id": "Nx6W9cz-9GHM",
        "outputId": "746a63d8-056e-4256-b18e-05195a2aac4b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 25s 549ms/step\n"
          ]
        }
      ],
      "source": [
        "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "for_pred = tokenizer(\n",
        "    text=test_d['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "test_results = model.predict(x={'input_ids': for_pred['input_ids']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bb-f3vmN9GHM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:44:31.590565Z",
          "iopub.status.busy": "2023-04-18T19:44:31.589905Z",
          "iopub.status.idle": "2023-04-18T19:44:31.601988Z",
          "shell.execute_reply": "2023-04-18T19:44:31.600881Z",
          "shell.execute_reply.started": "2023-04-18T19:44:31.590524Z"
        },
        "id": "Bb-f3vmN9GHM",
        "outputId": "dbbc52cc-7acf-4346-cd3b-3c563fcd7f9c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-d467d76760e1>:1: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
            "\n",
            "<ipython-input-13-d467d76760e1>:2: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
            "\n",
            "<ipython-input-13-d467d76760e1>:3: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_stance'] -= 1\n",
            "\n",
            "<ipython-input-13-d467d76760e1>:4: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_argument'] -= 1\n"
          ]
        }
      ],
      "source": [
        "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
        "test_d[f'{CLASS_NAME}_argument'] -= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DjrQC-6G9GHM",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-18T19:45:35.172502Z",
          "iopub.status.busy": "2023-04-18T19:45:35.171920Z",
          "iopub.status.idle": "2023-04-18T19:45:35.211525Z",
          "shell.execute_reply": "2023-04-18T19:45:35.208768Z",
          "shell.execute_reply.started": "2023-04-18T19:45:35.172456Z"
        },
        "id": "DjrQC-6G9GHM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t', index=None)\n",
        "df2 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r3FkHFVFAqh6",
      "metadata": {
        "id": "r3FkHFVFAqh6"
      },
      "source": [
        "### 3.4.4 New Arch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vyau-xOdAyv6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T20:44:51.470488Z",
          "iopub.status.busy": "2023-04-19T20:44:51.470078Z",
          "iopub.status.idle": "2023-04-19T20:44:53.474937Z",
          "shell.execute_reply": "2023-04-19T20:44:53.474086Z",
          "shell.execute_reply.started": "2023-04-19T20:44:51.470452Z"
        },
        "id": "vyau-xOdAyv6",
        "outputId": "55fbd5a5-0063-4ee1-93bc-93ee37d479ae",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"BERT_MultiLabel_MultiClass\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['attention_mask[0][0]',         \n",
            "                                thPoolingAndCrossAt               'input_ids[0][0]']              \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 256, 768)    591168      ['bert[4][0]',                   \n",
            " eadAttention)                                                    'bert[4][0]']                   \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 196608)       0           ['multi_head_attention_2[0][0]'] \n",
            "                                                                                                  \n",
            " pooled_output (Dropout)        (None, 196608)       0           ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " argument (Dense)               (None, 4)            786436      ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            " stance (Dense)                 (None, 4)            786436      ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 180,017,480\n",
            "Trainable params: 180,017,480\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build your model\n",
        "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
        "attention_mask = Input(shape=(256,), name='attention_mask', dtype='int32')\n",
        "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[0]\n",
        "\n",
        "# Add multi-head attention layer\n",
        "attention_output = MultiHeadAttention(num_heads=3, key_dim=64)(bert_model, bert_model)\n",
        "\n",
        "# Flatten the output from multi-head attention layer\n",
        "flatten = Flatten()(attention_output)\n",
        "\n",
        "# Apply dropout layer\n",
        "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "pooled_output = dropout(flatten, training=False)\n",
        "\n",
        "# Then build your model output\n",
        "stance = Dense(units=len(data.stance_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
        "argument = Dense(units=len(data.argument_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
        "outputs = {'stance': stance, 'argument': argument}\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CbTC672ZA76b",
      "metadata": {
        "id": "CbTC672ZA76b"
      },
      "source": [
        "### 3.4.5 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s7vDnlPEAyy5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T20:44:59.583887Z",
          "iopub.status.busy": "2023-04-19T20:44:59.583495Z",
          "iopub.status.idle": "2023-04-19T21:54:57.791767Z",
          "shell.execute_reply": "2023-04-19T21:54:57.790767Z",
          "shell.execute_reply.started": "2023-04-19T20:44:59.583852Z"
        },
        "id": "s7vDnlPEAyy5",
        "outputId": "2a2646c3-432c-4ad5-dab7-15bcb867c290",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "672/672 [==============================] - 269s 322ms/step - loss: 0.9638 - argument_loss: 0.2996 - stance_loss: 0.6642 - argument_accuracy: 0.8857 - stance_accuracy: 0.5455 - val_loss: 1.3897 - val_argument_loss: 0.6952 - val_stance_loss: 0.6945 - val_argument_accuracy: 0.5000 - val_stance_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "672/672 [==============================] - 208s 310ms/step - loss: 0.8831 - argument_loss: 0.2402 - stance_loss: 0.6429 - argument_accuracy: 0.8891 - stance_accuracy: 0.5632 - val_loss: 1.0589 - val_argument_loss: 0.6932 - val_stance_loss: 0.3657 - val_argument_accuracy: 0.5000 - val_stance_accuracy: 0.8750\n",
            "Epoch 3/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.7341 - argument_loss: 0.2030 - stance_loss: 0.5311 - argument_accuracy: 0.8911 - stance_accuracy: 0.7031 - val_loss: 1.0667 - val_argument_loss: 0.6932 - val_stance_loss: 0.3735 - val_argument_accuracy: 0.5000 - val_stance_accuracy: 0.8750\n",
            "Epoch 4/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.5530 - argument_loss: 0.1938 - stance_loss: 0.3592 - argument_accuracy: 0.8917 - stance_accuracy: 0.8606 - val_loss: 1.1477 - val_argument_loss: 0.8086 - val_stance_loss: 0.3391 - val_argument_accuracy: 0.5000 - val_stance_accuracy: 0.8750\n",
            "Epoch 5/20\n",
            "672/672 [==============================] - 207s 309ms/step - loss: 0.4467 - argument_loss: 0.1619 - stance_loss: 0.2849 - argument_accuracy: 0.9205 - stance_accuracy: 0.8917 - val_loss: 1.4496 - val_argument_loss: 0.8978 - val_stance_loss: 0.5518 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 6/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.3535 - argument_loss: 0.1396 - stance_loss: 0.2139 - argument_accuracy: 0.9349 - stance_accuracy: 0.9244 - val_loss: 1.4768 - val_argument_loss: 1.0954 - val_stance_loss: 0.3814 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 7/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.2722 - argument_loss: 0.1221 - stance_loss: 0.1501 - argument_accuracy: 0.9363 - stance_accuracy: 0.9475 - val_loss: 1.5675 - val_argument_loss: 1.2034 - val_stance_loss: 0.3641 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 8/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.2173 - argument_loss: 0.1145 - stance_loss: 0.1028 - argument_accuracy: 0.9393 - stance_accuracy: 0.9641 - val_loss: 1.6869 - val_argument_loss: 1.1876 - val_stance_loss: 0.4992 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 9/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.1937 - argument_loss: 0.1106 - stance_loss: 0.0831 - argument_accuracy: 0.9378 - stance_accuracy: 0.9741 - val_loss: 1.6629 - val_argument_loss: 1.3649 - val_stance_loss: 0.2980 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 10/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1645 - argument_loss: 0.1062 - stance_loss: 0.0582 - argument_accuracy: 0.9401 - stance_accuracy: 0.9827 - val_loss: 2.3441 - val_argument_loss: 1.5388 - val_stance_loss: 0.8052 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 11/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1364 - argument_loss: 0.0951 - stance_loss: 0.0413 - argument_accuracy: 0.9421 - stance_accuracy: 0.9866 - val_loss: 4.0032 - val_argument_loss: 2.5953 - val_stance_loss: 1.4079 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 12/20\n",
            "672/672 [==============================] - 207s 307ms/step - loss: 0.1178 - argument_loss: 0.0906 - stance_loss: 0.0272 - argument_accuracy: 0.9444 - stance_accuracy: 0.9918 - val_loss: 1.3476 - val_argument_loss: 1.2340 - val_stance_loss: 0.1136 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 13/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.1313 - argument_loss: 0.0948 - stance_loss: 0.0365 - argument_accuracy: 0.9451 - stance_accuracy: 0.9892 - val_loss: 2.7190 - val_argument_loss: 1.8900 - val_stance_loss: 0.8290 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 14/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1148 - argument_loss: 0.0885 - stance_loss: 0.0263 - argument_accuracy: 0.9453 - stance_accuracy: 0.9922 - val_loss: 1.8399 - val_argument_loss: 1.5720 - val_stance_loss: 0.2679 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 15/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1171 - argument_loss: 0.0834 - stance_loss: 0.0337 - argument_accuracy: 0.9462 - stance_accuracy: 0.9913 - val_loss: 2.0737 - val_argument_loss: 1.9079 - val_stance_loss: 0.1658 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 16/20\n",
            "672/672 [==============================] - 207s 307ms/step - loss: 0.1068 - argument_loss: 0.0883 - stance_loss: 0.0185 - argument_accuracy: 0.9453 - stance_accuracy: 0.9948 - val_loss: 3.3938 - val_argument_loss: 1.9901 - val_stance_loss: 1.4038 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 17/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.1047 - argument_loss: 0.0818 - stance_loss: 0.0228 - argument_accuracy: 0.9468 - stance_accuracy: 0.9933 - val_loss: 3.2504 - val_argument_loss: 2.3521 - val_stance_loss: 0.8983 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 18/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1062 - argument_loss: 0.0851 - stance_loss: 0.0211 - argument_accuracy: 0.9460 - stance_accuracy: 0.9950 - val_loss: 1.8683 - val_argument_loss: 1.7852 - val_stance_loss: 0.0831 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "672/672 [==============================] - 207s 307ms/step - loss: 0.1100 - argument_loss: 0.0863 - stance_loss: 0.0237 - argument_accuracy: 0.9458 - stance_accuracy: 0.9937 - val_loss: 3.7337 - val_argument_loss: 2.6744 - val_stance_loss: 1.0594 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n",
            "Epoch 20/20\n",
            "672/672 [==============================] - 207s 307ms/step - loss: 0.0991 - argument_loss: 0.0806 - stance_loss: 0.0185 - argument_accuracy: 0.9471 - stance_accuracy: 0.9944 - val_loss: 3.3171 - val_argument_loss: 2.5946 - val_stance_loss: 0.7225 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.8750\n"
          ]
        }
      ],
      "source": [
        "#! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = AdamW(\n",
        "    learning_rate=5e-06,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "#wandb.init(project=\"Text_categorization\", name = \"Bert_attention_masks_20epochs_AdamW_lr_5e6_masks\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
        "epochs = 20\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8], 'attention_mask': test_x['attention_mask'][:8]}, \n",
        "                     {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs) #, callbacks=[WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SzErtB3fiL7F",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-19T21:54:57.794812Z",
          "iopub.status.busy": "2023-04-19T21:54:57.794385Z",
          "iopub.status.idle": "2023-04-19T21:55:31.119646Z",
          "shell.execute_reply": "2023-04-19T21:55:31.118543Z",
          "shell.execute_reply.started": "2023-04-19T21:54:57.794767Z"
        },
        "id": "SzErtB3fiL7F",
        "outputId": "9f413e13-d79d-4312-e5c6-c5767b067427",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Usage: wandb login [OPTIONS] [KEY]...\n",
            "Try 'wandb login --help' for help.\n",
            "\n",
            "Error: No such option: --login Did you mean --relogin?\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.14.2 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/kaggle/working/wandb/run-20230419_215500-et21hbla</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/et21hbla' target=\"_blank\">Bert_attention_masks_20epochs_AdamW_lr_5e6_masks-6</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/et21hbla' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/et21hbla</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "! wandb login --login Nikita4epuh\n",
        "wandb.init(project=\"Text_categorization\", name = \"Bert_attention_masks_20epochs_AdamW_lr_5e6_masks-6\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
        "\n",
        "for epoch in range(epochs): \n",
        "    wandb.log({'loss': history.history['loss'][epoch],\n",
        "               'argument_loss': history.history['argument_loss'][epoch],\n",
        "               'stance_loss': history.history['stance_loss'][epoch],\n",
        "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
        "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
        "               'val_loss': history.history['stance_accuracy'][epoch],\n",
        "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
        "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
        "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
        "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FBwH1L09A_FM",
      "metadata": {
        "id": "FBwH1L09A_FM"
      },
      "source": [
        "#### 3.4.5.1 Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cOI_mXfHAy4J",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOI_mXfHAy4J",
        "outputId": "c6d79fc6-56f5-4ee4-b1be-4c0b7b3fa154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 25s 653ms/step\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       1.00      1.00      1.00       534\n",
            "\n",
            "           1       0.41      0.21      0.28        89\n",
            "\n",
            "           2       0.75      0.75      0.75       287\n",
            "\n",
            "           3       0.28      0.41      0.33        98\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.80      1008\n",
            "\n",
            "   macro avg       0.61      0.59      0.59      1008\n",
            "\n",
            "weighted avg       0.81      0.80      0.80      1008\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       1.00      1.00      1.00       534\n",
            "\n",
            "           1       0.33      0.54      0.41        56\n",
            "\n",
            "           2       0.90      0.92      0.91       373\n",
            "\n",
            "           3       0.00      0.00      0.00        45\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.90      1008\n",
            "\n",
            "   macro avg       0.55      0.61      0.58      1008\n",
            "\n",
            "weighted avg       0.88      0.90      0.89      1008\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "val_results = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
        "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
        "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
        "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0), classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rTMsoe3aBBD4",
      "metadata": {
        "id": "rTMsoe3aBBD4"
      },
      "source": [
        "#### 3.4.5.2 Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d8KdNpUAy9A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T21:55:31.127507Z",
          "iopub.status.busy": "2023-04-19T21:55:31.125013Z",
          "iopub.status.idle": "2023-04-19T21:55:51.309063Z",
          "shell.execute_reply": "2023-04-19T21:55:51.307973Z",
          "shell.execute_reply.started": "2023-04-19T21:55:31.127459Z"
        },
        "id": "7d8KdNpUAy9A",
        "outputId": "267886c5-1ed7-4b74-f720-9736a1257140",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 20s 322ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "CLASS_NAME = \"masks\"\n",
        "test = pd.read_csv(\"/kaggle/working/val_empty.tsv\", sep='\\t')\n",
        "test.head()\n",
        "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "for_pred = tokenizer(\n",
        "    text=test_d['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "test_results = model.predict(x={'input_ids': for_pred['input_ids'], 'attention_mask': for_pred['attention_mask']})\n",
        "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
        "test_d[f'{CLASS_NAME}_argument'] -= 1\n",
        "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/kaggle/working/val_predict_MHA_AdamW_lr_5e6_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YVR6SY-yAy_7",
      "metadata": {
        "id": "YVR6SY-yAy_7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "iciqRheS9GHN",
      "metadata": {
        "id": "iciqRheS9GHN"
      },
      "source": [
        "## 3.5 vaccines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "peIWpSF59GHN",
      "metadata": {
        "id": "peIWpSF59GHN"
      },
      "source": [
        "### 3.5.1 Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LZGYLGXF9GHN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T19:07:50.471846Z",
          "iopub.status.busy": "2023-04-19T19:07:50.470588Z",
          "iopub.status.idle": "2023-04-19T19:07:56.590530Z",
          "shell.execute_reply": "2023-04-19T19:07:56.589288Z",
          "shell.execute_reply.started": "2023-04-19T19:07:50.471792Z"
        },
        "id": "LZGYLGXF9GHN",
        "outputId": "4395a95a-6ced-4243-c5ed-df0d3ea69b2c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"BERT_MultiLabel_MultiClass\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['input_ids[0][0]']              \n",
            "                                thPoolingAndCrossAt                                               \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " pooled_output (Dropout)        (None, 768)          0           ['bert[0][1]']                   \n",
            "                                                                                                  \n",
            " argument (Dense)               (None, 4)            3076        ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            " stance (Dense)                 (None, 4)            3076        ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 177,859,592\n",
            "Trainable params: 177,859,592\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "CLASS_NAME = \"vaccines\"\n",
        "# Import data from csv\n",
        "whole_data = pd.read_csv('/kaggle/working/train_all.tsv', sep='\\t')\n",
        "\n",
        "# Train_test_split\n",
        "test_size = 0.2\n",
        "data, data_test = train_test_split(whole_data, test_size=test_size)\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------------#\n",
        "## Train\n",
        "# Select required columns\n",
        "data = data[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "\n",
        "# Set your model output as categorical and save in new label col\n",
        "data['stance_label'] = pd.Categorical(data[f'{CLASS_NAME}_stance'])\n",
        "data['argument_label'] = pd.Categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Transform your output to numeric\n",
        "data[f'{CLASS_NAME}_stance'] = data['stance_label'].cat.codes\n",
        "data[f'{CLASS_NAME}_argument'] = data['argument_label'].cat.codes\n",
        "\n",
        "#------------------------------------------------------------------------------------#\n",
        "## Test\n",
        "# Select required columns\n",
        "data_test = data_test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "\n",
        "# Set your model output as categorical and save in new label col\n",
        "data_test['stance_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_stance'])\n",
        "data_test['argument_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Transform your output to numeric\n",
        "data_test[f'{CLASS_NAME}_stance'] = data_test['stance_label'].cat.codes\n",
        "data_test[f'{CLASS_NAME}_argument'] = data_test['argument_label'].cat.codes\n",
        "#wandb.init(project=\"Text_categorization\", name = \"baseline_run\", tags = [\"Ruberta\", \"RB\"])\n",
        "# Ready output data for the model\n",
        "test_y_stance = to_categorical(data_test[f'{CLASS_NAME}_stance'])\n",
        "test_y_argument = to_categorical(data_test[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "test_x = tokenizer(\n",
        "    text=data_test['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "# Build your model input\n",
        "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[1]\n",
        "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "pooled_output = dropout(bert_model, training=False)\n",
        "\n",
        "# Then build your model output\n",
        "stance = Dense(units=len(data.stance_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
        "argument = Dense(units=len(data.argument_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
        "outputs = {'stance': stance, 'argument': argument}\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hs9veuJ39GHN",
      "metadata": {
        "id": "hs9veuJ39GHN"
      },
      "source": [
        "### 3.5.2 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ge2SV7TG9GHN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:47:30.568837Z",
          "iopub.status.busy": "2023-04-18T19:47:30.567995Z",
          "iopub.status.idle": "2023-04-18T19:54:27.231648Z",
          "shell.execute_reply": "2023-04-18T19:54:27.228470Z",
          "shell.execute_reply.started": "2023-04-18T19:47:30.568797Z"
        },
        "id": "Ge2SV7TG9GHN",
        "outputId": "13ec7a9b-50c7-41ac-f9e4-62411f68093d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230419_080129-aqk0c2j9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/aqk0c2j9' target=\"_blank\">baseline_run_vaccines</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/aqk0c2j9' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/aqk0c2j9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "672/672 [==============================] - ETA: 0s - loss: 0.8639 - argument_loss: 0.3964 - stance_loss: 0.4674 - argument_accuracy: 0.8729 - stance_accuracy: 0.8394"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_080129-aqk0c2j9/files/model-best)... Done. 12.9s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 497s 639ms/step - loss: 0.8639 - argument_loss: 0.3964 - stance_loss: 0.4674 - argument_accuracy: 0.8729 - stance_accuracy: 0.8394 - val_loss: 0.0885 - val_argument_loss: 0.0322 - val_stance_loss: 0.0563 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 2/20\n",
            "\n",
            "672/672 [==============================] - ETA: 0s - loss: 0.5012 - argument_loss: 0.2189 - stance_loss: 0.2823 - argument_accuracy: 0.9295 - stance_accuracy: 0.8718"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_080129-aqk0c2j9/files/model-best)... Done. 12.9s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 411s 612ms/step - loss: 0.5012 - argument_loss: 0.2189 - stance_loss: 0.2823 - argument_accuracy: 0.9295 - stance_accuracy: 0.8718 - val_loss: 0.0812 - val_argument_loss: 0.0418 - val_stance_loss: 0.0394 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 3/20\n",
            "\n",
            "672/672 [==============================] - 342s 509ms/step - loss: 0.5515 - argument_loss: 0.2473 - stance_loss: 0.3043 - argument_accuracy: 0.9213 - stance_accuracy: 0.8708 - val_loss: 0.1275 - val_argument_loss: 0.0490 - val_stance_loss: 0.0785 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
            "\n",
            "Epoch 4/20\n",
            "\n",
            "672/672 [==============================] - 339s 505ms/step - loss: 1.5166 - argument_loss: 0.7262 - stance_loss: 0.7904 - argument_accuracy: 0.7696 - stance_accuracy: 0.7664 - val_loss: 0.9052 - val_argument_loss: 0.4384 - val_stance_loss: 0.4669 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 5/20\n",
            "\n",
            "672/672 [==============================] - 338s 503ms/step - loss: 1.5768 - argument_loss: 0.7539 - stance_loss: 0.8228 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 0.9852 - val_argument_loss: 0.4636 - val_stance_loss: 0.5216 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 6/20\n",
            "\n",
            "672/672 [==============================] - 339s 504ms/step - loss: 1.5618 - argument_loss: 0.7475 - stance_loss: 0.8143 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 1.0046 - val_argument_loss: 0.4800 - val_stance_loss: 0.5246 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 7/20\n",
            "\n",
            "672/672 [==============================] - 338s 502ms/step - loss: 1.5596 - argument_loss: 0.7466 - stance_loss: 0.8130 - argument_accuracy: 0.7579 - stance_accuracy: 0.7577 - val_loss: 0.9487 - val_argument_loss: 0.4411 - val_stance_loss: 0.5076 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 8/20\n",
            "\n",
            "672/672 [==============================] - 337s 502ms/step - loss: 1.5615 - argument_loss: 0.7469 - stance_loss: 0.8146 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 1.0505 - val_argument_loss: 0.4984 - val_stance_loss: 0.5521 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 9/20\n",
            "\n",
            "672/672 [==============================] - 338s 503ms/step - loss: 1.5616 - argument_loss: 0.7474 - stance_loss: 0.8141 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 0.9981 - val_argument_loss: 0.4720 - val_stance_loss: 0.5260 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 10/20\n",
            "\n",
            "672/672 [==============================] - 337s 502ms/step - loss: 1.5599 - argument_loss: 0.7465 - stance_loss: 0.8134 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 0.9459 - val_argument_loss: 0.4445 - val_stance_loss: 0.5014 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 11/20\n",
            "\n",
            "672/672 [==============================] - 337s 501ms/step - loss: 1.5613 - argument_loss: 0.7478 - stance_loss: 0.8135 - argument_accuracy: 0.7577 - stance_accuracy: 0.7579 - val_loss: 1.1941 - val_argument_loss: 0.5592 - val_stance_loss: 0.6348 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 12/20\n",
            "\n",
            "672/672 [==============================] - 337s 502ms/step - loss: 1.5588 - argument_loss: 0.7458 - stance_loss: 0.8129 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 0.9752 - val_argument_loss: 0.4618 - val_stance_loss: 0.5134 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 13/20\n",
            "\n",
            " 51/672 [=>............................] - ETA: 5:11 - loss: 1.6768 - argument_loss: 0.8013 - stance_loss: 0.8755 - argument_accuracy: 0.7255 - stance_accuracy: 0.7255"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1a279b085cfe>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m# x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = Adam(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "wandb.init(project=\"Text_categorization\", name = \"baseline_run_vaccines\", tags = [\"Ruberta\", \"RB\"])\n",
        "epochs = 20\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8]}, {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs, callbacks=[WandbCallback()])\n",
        "for epoch in range(epochs): \n",
        "    wandb.log({'loss': history.history['loss'][epoch],\n",
        "               'argument_loss': history.history['argument_loss'][epoch],\n",
        "               'stance_loss': history.history['stance_loss'][epoch],\n",
        "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
        "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
        "               'val_loss': history.history['stance_accuracy'][epoch],\n",
        "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
        "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
        "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
        "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F9swUYK5ypUI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9swUYK5ypUI",
        "outputId": "f4cce1be-78d5-45f9-f785-91c1d5a399b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230419_092630-z1wiapq3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/z1wiapq3' target=\"_blank\">baseline_run_vaccines_2_epochs</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/z1wiapq3' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/z1wiapq3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\n",
            "672/672 [==============================] - ETA: 0s - loss: 0.5840 - argument_loss: 0.2581 - stance_loss: 0.3259 - argument_accuracy: 0.9200 - stance_accuracy: 0.8684"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_092630-z1wiapq3/files/model-best)... Done. 12.6s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "672/672 [==============================] - 489s 638ms/step - loss: 0.5840 - argument_loss: 0.2581 - stance_loss: 0.3259 - argument_accuracy: 0.9200 - stance_accuracy: 0.8684 - val_loss: 0.2219 - val_argument_loss: 0.0349 - val_stance_loss: 0.1870 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
            "\n",
            "Epoch 2/2\n",
            "\n",
            "672/672 [==============================] - 341s 508ms/step - loss: 0.5058 - argument_loss: 0.2165 - stance_loss: 0.2893 - argument_accuracy: 0.9334 - stance_accuracy: 0.8773 - val_loss: 0.2485 - val_argument_loss: 0.0328 - val_stance_loss: 0.2157 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n"
          ]
        }
      ],
      "source": [
        "! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = Adam(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "wandb.init(project=\"Text_categorization\", name = \"baseline_run_vaccines_2_epochs\", tags = [\"Ruberta\", \"RB\"])\n",
        "epochs = 2\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8]}, {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs, callbacks=[WandbCallback()])\n",
        "for epoch in range(epochs): \n",
        "    wandb.log({'loss': history.history['loss'][epoch],\n",
        "               'argument_loss': history.history['argument_loss'][epoch],\n",
        "               'stance_loss': history.history['stance_loss'][epoch],\n",
        "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
        "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
        "               'val_loss': history.history['stance_accuracy'][epoch],\n",
        "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
        "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
        "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
        "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wC1NzXEj9GHN",
      "metadata": {
        "id": "wC1NzXEj9GHN"
      },
      "source": [
        "### 3.5.3 Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QlTecKRB9GHN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:54:27.236803Z",
          "iopub.status.busy": "2023-04-18T19:54:27.233964Z",
          "iopub.status.idle": "2023-04-18T19:55:09.915103Z",
          "shell.execute_reply": "2023-04-18T19:55:09.913684Z",
          "shell.execute_reply.started": "2023-04-18T19:54:27.236757Z"
        },
        "id": "QlTecKRB9GHN",
        "outputId": "0ef4f680-de30-4c7b-9982-26296fd7a56f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 24s 533ms/step\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       1.00      1.00      1.00      1009\n",
            "\n",
            "           1       0.00      0.00      0.00        89\n",
            "\n",
            "           2       0.51      0.98      0.67       173\n",
            "\n",
            "           3       0.00      0.00      0.00        73\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.88      1344\n",
            "\n",
            "   macro avg       0.38      0.50      0.42      1344\n",
            "\n",
            "weighted avg       0.81      0.88      0.84      1344\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "val_results = model.predict(x={'input_ids': test_x['input_ids']})\n",
        "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
        "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
        "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GUq0CRkN9GHN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:55:09.923746Z",
          "iopub.status.busy": "2023-04-18T19:55:09.919605Z",
          "iopub.status.idle": "2023-04-18T19:55:09.946909Z",
          "shell.execute_reply": "2023-04-18T19:55:09.943824Z",
          "shell.execute_reply.started": "2023-04-18T19:55:09.923695Z"
        },
        "id": "GUq0CRkN9GHN",
        "outputId": "2e4279e2-f2fd-4e2d-f765-c9fc78f0ce12",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       1.00      1.00      1.00      1009\n",
            "\n",
            "           1       0.00      0.00      0.00        59\n",
            "\n",
            "           2       0.72      0.98      0.83       244\n",
            "\n",
            "           3       0.00      0.00      0.00        32\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.93      1344\n",
            "\n",
            "   macro avg       0.43      0.50      0.46      1344\n",
            "\n",
            "weighted avg       0.88      0.93      0.90      1344\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F-ZaM_eZ9GHN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:55:09.956118Z",
          "iopub.status.busy": "2023-04-18T19:55:09.953170Z",
          "iopub.status.idle": "2023-04-18T19:55:53.894877Z",
          "shell.execute_reply": "2023-04-18T19:55:53.893454Z",
          "shell.execute_reply.started": "2023-04-18T19:55:09.956071Z"
        },
        "id": "F-ZaM_eZ9GHN",
        "outputId": "d01758c9-1be2-4a8d-a362-adfbb4e053fa",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 28s 571ms/step\n"
          ]
        }
      ],
      "source": [
        "test = pd.read_csv(\"/content/drive/MyDrive/HW_2/val_empty.tsv\", sep='\\t')\n",
        "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "for_pred = tokenizer(\n",
        "    text=test_d['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "test_results = model.predict(x={'input_ids': for_pred['input_ids']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SMVO6kxn9GHO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:55:53.897916Z",
          "iopub.status.busy": "2023-04-18T19:55:53.896925Z",
          "iopub.status.idle": "2023-04-18T19:55:53.919161Z",
          "shell.execute_reply": "2023-04-18T19:55:53.917885Z",
          "shell.execute_reply.started": "2023-04-18T19:55:53.897858Z"
        },
        "id": "SMVO6kxn9GHO",
        "outputId": "ce16e255-ced5-47d2-ec16-2fd3bb758da1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-d467d76760e1>:1: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
            "\n",
            "<ipython-input-11-d467d76760e1>:2: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
            "\n",
            "<ipython-input-11-d467d76760e1>:3: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_stance'] -= 1\n",
            "\n",
            "<ipython-input-11-d467d76760e1>:4: SettingWithCopyWarning: \n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  test_d[f'{CLASS_NAME}_argument'] -= 1\n"
          ]
        }
      ],
      "source": [
        "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
        "test_d[f'{CLASS_NAME}_argument'] -= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lOvFhLjw9GHO",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-18T19:55:53.924364Z",
          "iopub.status.busy": "2023-04-18T19:55:53.924035Z",
          "iopub.status.idle": "2023-04-18T19:55:53.956123Z",
          "shell.execute_reply": "2023-04-18T19:55:53.954938Z",
          "shell.execute_reply.started": "2023-04-18T19:55:53.924334Z"
        },
        "id": "lOvFhLjw9GHO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_NCrXCBvLtNM",
      "metadata": {
        "id": "_NCrXCBvLtNM"
      },
      "outputs": [],
      "source": [
        "CLASS_NAME = \"vaccines\"фы\n",
        "df3 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50TKcudhC3Bd",
      "metadata": {
        "id": "50TKcudhC3Bd"
      },
      "source": [
        "### 3.5.4 New ARCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2A_NDwWmC7gb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T19:08:20.179543Z",
          "iopub.status.busy": "2023-04-19T19:08:20.179133Z",
          "iopub.status.idle": "2023-04-19T19:08:22.874195Z",
          "shell.execute_reply": "2023-04-19T19:08:22.873350Z",
          "shell.execute_reply.started": "2023-04-19T19:08:20.179506Z"
        },
        "id": "2A_NDwWmC7gb",
        "outputId": "87e449ee-a444-454f-fca1-4655a4284ac2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"BERT_MultiLabel_MultiClass\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['attention_mask[0][0]',         \n",
            "                                thPoolingAndCrossAt               'input_ids[0][0]']              \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 256, 768)    591168      ['bert[1][0]',                   \n",
            " dAttention)                                                      'bert[1][0]']                   \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 196608)       0           ['multi_head_attention[0][0]']   \n",
            "                                                                                                  \n",
            " pooled_output (Dropout)        (None, 196608)       0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " argument (Dense)               (None, 4)            786436      ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            " stance (Dense)                 (None, 4)            786436      ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 180,017,480\n",
            "Trainable params: 180,017,480\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build your model\n",
        "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
        "attention_mask = Input(shape=(256,), name='attention_mask', dtype='int32')\n",
        "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[0]\n",
        "\n",
        "# Add multi-head attention layer\n",
        "attention_output = MultiHeadAttention(num_heads=3, key_dim=64)(bert_model, bert_model)\n",
        "\n",
        "# Flatten the output from multi-head attention layer\n",
        "flatten = Flatten()(attention_output)\n",
        "\n",
        "# Apply dropout layer\n",
        "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "pooled_output = dropout(flatten, training=False)\n",
        "\n",
        "# Then build your model output\n",
        "stance = Dense(units=len(data.stance_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
        "argument = Dense(units=len(data.argument_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
        "outputs = {'stance': stance, 'argument': argument}\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NvkNH_v1DAXj",
      "metadata": {
        "id": "NvkNH_v1DAXj"
      },
      "source": [
        "#### 3.5.5 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8M6FHChvC7jR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T19:09:03.284020Z",
          "iopub.status.busy": "2023-04-19T19:09:03.283411Z",
          "iopub.status.idle": "2023-04-19T20:20:02.186024Z",
          "shell.execute_reply": "2023-04-19T20:20:02.184821Z",
          "shell.execute_reply.started": "2023-04-19T19:09:03.283983Z"
        },
        "id": "8M6FHChvC7jR",
        "outputId": "e97909e4-63cc-45e7-ea0a-1e6792ee82e5",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "672/672 [==============================] - 281s 337ms/step - loss: 1.6283 - argument_loss: 0.2790 - stance_loss: 1.3493 - argument_accuracy: 0.9140 - stance_accuracy: 0.8535 - val_loss: 1.4829 - val_argument_loss: 0.2677 - val_stance_loss: 1.2152 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 2/20\n",
            "672/672 [==============================] - 210s 312ms/step - loss: 1.5175 - argument_loss: 0.1928 - stance_loss: 1.3246 - argument_accuracy: 0.9300 - stance_accuracy: 0.8703 - val_loss: 1.6284 - val_argument_loss: 0.3714 - val_stance_loss: 1.2570 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.6250\n",
            "Epoch 3/20\n",
            "672/672 [==============================] - 208s 309ms/step - loss: 1.4702 - argument_loss: 0.1642 - stance_loss: 1.3060 - argument_accuracy: 0.9315 - stance_accuracy: 0.8656 - val_loss: 1.4259 - val_argument_loss: 0.1078 - val_stance_loss: 1.3182 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.6250\n",
            "Epoch 4/20\n",
            "672/672 [==============================] - 207s 309ms/step - loss: 1.1275 - argument_loss: 0.1225 - stance_loss: 1.0050 - argument_accuracy: 0.9568 - stance_accuracy: 0.8671 - val_loss: 1.0664 - val_argument_loss: 0.3571 - val_stance_loss: 0.7093 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.3005 - argument_loss: 0.0789 - stance_loss: 0.2216 - argument_accuracy: 0.9725 - stance_accuracy: 0.8680 - val_loss: 0.7802 - val_argument_loss: 0.2286 - val_stance_loss: 0.5515 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.6250\n",
            "Epoch 6/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.2580 - argument_loss: 0.0526 - stance_loss: 0.2054 - argument_accuracy: 0.9844 - stance_accuracy: 0.8682 - val_loss: 0.7035 - val_argument_loss: 0.0078 - val_stance_loss: 0.6957 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.2346 - argument_loss: 0.0331 - stance_loss: 0.2015 - argument_accuracy: 0.9896 - stance_accuracy: 0.8706 - val_loss: 1.9559 - val_argument_loss: 1.4212 - val_stance_loss: 0.5347 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
            "Epoch 8/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.2102 - argument_loss: 0.0194 - stance_loss: 0.1908 - argument_accuracy: 0.9939 - stance_accuracy: 0.8712 - val_loss: 0.5231 - val_argument_loss: 0.0023 - val_stance_loss: 0.5208 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.6250\n",
            "Epoch 9/20\n",
            "672/672 [==============================] - 207s 307ms/step - loss: 0.2013 - argument_loss: 0.0100 - stance_loss: 0.1913 - argument_accuracy: 0.9976 - stance_accuracy: 0.8716 - val_loss: 0.6594 - val_argument_loss: 0.0031 - val_stance_loss: 0.6563 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.6250\n",
            "Epoch 10/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.1999 - argument_loss: 0.0131 - stance_loss: 0.1868 - argument_accuracy: 0.9970 - stance_accuracy: 0.8729 - val_loss: 0.8463 - val_argument_loss: 0.3210 - val_stance_loss: 0.5253 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.6250\n",
            "Epoch 11/20\n",
            "672/672 [==============================] - 207s 308ms/step - loss: 0.1750 - argument_loss: 0.0145 - stance_loss: 0.1605 - argument_accuracy: 0.9963 - stance_accuracy: 0.9181 - val_loss: 2.1712 - val_argument_loss: 1.6925 - val_stance_loss: 0.4787 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1508 - argument_loss: 0.0144 - stance_loss: 0.1363 - argument_accuracy: 0.9963 - stance_accuracy: 0.9224 - val_loss: 0.4332 - val_argument_loss: 0.0044 - val_stance_loss: 0.4288 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 13/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1415 - argument_loss: 0.0182 - stance_loss: 0.1233 - argument_accuracy: 0.9953 - stance_accuracy: 0.9269 - val_loss: 0.6681 - val_argument_loss: 0.3151 - val_stance_loss: 0.3530 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1212 - argument_loss: 0.0090 - stance_loss: 0.1123 - argument_accuracy: 0.9978 - stance_accuracy: 0.9270 - val_loss: 0.3930 - val_argument_loss: 1.4931e-04 - val_stance_loss: 0.3929 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1204 - argument_loss: 0.0111 - stance_loss: 0.1093 - argument_accuracy: 0.9981 - stance_accuracy: 0.9276 - val_loss: 0.4002 - val_argument_loss: 4.2766e-06 - val_stance_loss: 0.4002 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1182 - argument_loss: 0.0114 - stance_loss: 0.1067 - argument_accuracy: 0.9978 - stance_accuracy: 0.9296 - val_loss: 0.3768 - val_argument_loss: 0.0147 - val_stance_loss: 0.3620 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1161 - argument_loss: 0.0074 - stance_loss: 0.1087 - argument_accuracy: 0.9980 - stance_accuracy: 0.9287 - val_loss: 0.3752 - val_argument_loss: 0.0258 - val_stance_loss: 0.3494 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1171 - argument_loss: 0.0113 - stance_loss: 0.1058 - argument_accuracy: 0.9970 - stance_accuracy: 0.9300 - val_loss: 0.3565 - val_argument_loss: 0.0097 - val_stance_loss: 0.3468 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "672/672 [==============================] - 206s 307ms/step - loss: 0.1142 - argument_loss: 0.0116 - stance_loss: 0.1025 - argument_accuracy: 0.9968 - stance_accuracy: 0.9293 - val_loss: 0.3466 - val_argument_loss: 9.9837e-07 - val_stance_loss: 0.3466 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "672/672 [==============================] - 207s 307ms/step - loss: 0.1148 - argument_loss: 0.0105 - stance_loss: 0.1044 - argument_accuracy: 0.9968 - stance_accuracy: 0.9293 - val_loss: 0.3466 - val_argument_loss: 7.7335e-06 - val_stance_loss: 0.3466 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "#! wandb login --relogin Nikita4epuh\n",
        "# Set an optimizer\n",
        "optimizer = AdamW(\n",
        "    learning_rate=5e-06,\n",
        "    epsilon=1e-08,\n",
        "    weight_decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
        "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "#wandb.init(project=\"Text_categorization\", name = \"Bert_attention_vaccines_4epochs\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
        "epochs = 20\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': test_x['input_ids'][:8], 'attention_mask': test_x['attention_mask'][:8]}, \n",
        "                     {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
        "    batch_size=8,\n",
        "    epochs=epochs) #callbacks=[WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-SGHoqB_iL7I",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "389ac52824a94297b81cf2fb4c2ab5fd"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T20:31:45.915975Z",
          "iopub.status.busy": "2023-04-19T20:31:45.915584Z",
          "iopub.status.idle": "2023-04-19T20:32:39.412139Z",
          "shell.execute_reply": "2023-04-19T20:32:39.411043Z",
          "shell.execute_reply.started": "2023-04-19T20:31:45.915940Z"
        },
        "id": "-SGHoqB_iL7I",
        "outputId": "9dbd92b1-4e7c-41cc-a32e-09374c185763",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Usage: wandb login [OPTIONS] [KEY]...\n",
            "Try 'wandb login --help' for help.\n",
            "\n",
            "Error: No such option: --login Did you mean --relogin?\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ········································\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "389ac52824a94297b81cf2fb4c2ab5fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670499766663245, max=1.0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.14.2 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/kaggle/working/wandb/run-20230419_203157-f8nknbhb</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/f8nknbhb' target=\"_blank\">Bert_attention_vaccines_20epochs_Adam_5e-6</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/f8nknbhb' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/f8nknbhb</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "! wandb login --login Nikita4epuh\n",
        "wandb.init(project=\"Text_categorization\", name = \"Bert_attention_vaccines_20epochs_Adam_5e-6\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
        "\n",
        "for epoch in range(epochs): \n",
        "    wandb.log({'loss': history.history['loss'][epoch],\n",
        "               'argument_loss': history.history['argument_loss'][epoch],\n",
        "               'stance_loss': history.history['stance_loss'][epoch],\n",
        "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
        "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
        "               'val_loss': history.history['stance_accuracy'][epoch],\n",
        "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
        "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
        "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
        "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43wzoIa1DJma",
      "metadata": {
        "id": "43wzoIa1DJma"
      },
      "source": [
        "#### 3.5.6 Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G3vTEbboC7oo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3vTEbboC7oo",
        "outputId": "c56c45c5-c423-4d97-e812-457b8707dea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 28s 614ms/step\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.75      1.00      0.86      1010\n",
            "\n",
            "           1       0.00      0.00      0.00        78\n",
            "\n",
            "           2       0.00      0.00      0.00       174\n",
            "\n",
            "           3       0.00      0.00      0.00        82\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.75      1344\n",
            "\n",
            "   macro avg       0.19      0.25      0.21      1344\n",
            "\n",
            "weighted avg       0.56      0.75      0.64      1344\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       1.00      1.00      1.00      1010\n",
            "\n",
            "           1       0.00      0.00      0.00        50\n",
            "\n",
            "           2       0.74      1.00      0.85       248\n",
            "\n",
            "           3       0.00      0.00      0.00        36\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.93      1344\n",
            "\n",
            "   macro avg       0.43      0.50      0.46      1344\n",
            "\n",
            "weighted avg       0.89      0.93      0.91      1344\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "val_results = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
        "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
        "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
        "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0), classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "APpkcLSbDMmV",
      "metadata": {
        "id": "APpkcLSbDMmV"
      },
      "source": [
        "#### 3.5.7 Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rynEhE07iL7I",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-19T20:20:02.189026Z",
          "iopub.status.busy": "2023-04-19T20:20:02.188532Z",
          "iopub.status.idle": "2023-04-19T20:20:04.577178Z",
          "shell.execute_reply": "2023-04-19T20:20:04.575892Z",
          "shell.execute_reply.started": "2023-04-19T20:20:02.188986Z"
        },
        "id": "rynEhE07iL7I",
        "outputId": "5acf3c1c-d1cf-4cf6-bc52-0725e7cc8e57",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lUerv_gpQvo_e8Fl-flxEDtz77z_ZsLx\n",
            "To: /kaggle/working/val_empty.tsv\n",
            "100%|█████████████████████████████████████████| 316k/316k [00:00<00:00, 100MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1lUerv_gpQvo_e8Fl-flxEDtz77z_ZsLx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oXE0Lr2PC7rb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-19T20:21:24.820609Z",
          "iopub.status.busy": "2023-04-19T20:21:24.819491Z",
          "iopub.status.idle": "2023-04-19T20:21:48.645687Z",
          "shell.execute_reply": "2023-04-19T20:21:48.644526Z",
          "shell.execute_reply.started": "2023-04-19T20:21:24.820565Z"
        },
        "id": "oXE0Lr2PC7rb",
        "outputId": "8ea6523a-bdeb-411b-d7e7-aa3ef3646420",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 18s 322ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "CLASS_NAME = \"vaccines\"\n",
        "test = pd.read_csv(\"/kaggle/working/val_empty.tsv\", sep='\\t')\n",
        "test.head()\n",
        "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "for_pred = tokenizer(\n",
        "    text=test_d['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "test_results = model.predict(x={'input_ids': for_pred['input_ids'], 'attention_mask': for_pred['attention_mask']})\n",
        "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
        "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
        "test_d[f'{CLASS_NAME}_argument'] -= 1\n",
        "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/kaggle/working/val_predict_MHA_Adam_5e_6_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gnWg1Irw9GHO",
      "metadata": {
        "id": "gnWg1Irw9GHO"
      },
      "source": [
        "## 3.6 Concatinate all files with results for masks, vaccines, quarantine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p6kX2AxZ9GHO",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-18T19:55:53.958445Z",
          "iopub.status.busy": "2023-04-18T19:55:53.957707Z",
          "iopub.status.idle": "2023-04-18T19:55:54.002220Z",
          "shell.execute_reply": "2023-04-18T19:55:54.000932Z",
          "shell.execute_reply.started": "2023-04-18T19:55:53.958406Z"
        },
        "id": "p6kX2AxZ9GHO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "CLASS_NAME = \"quarantine\"\n",
        "df1 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_{CLASS_NAME}.tsv\", sep='\\t')\n",
        "CLASS_NAME = \"masks\"\n",
        "df2 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_{CLASS_NAME}.tsv\", sep='\\t')\n",
        "CLASS_NAME = \"vaccines\"\n",
        "df3 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_{CLASS_NAME}.tsv\", sep='\\t')\n",
        "\n",
        "\n",
        "result = pd.merge(df1, df2, on=\"text\")\n",
        "result = pd.merge(result, df3, on=\"text\")\n",
        "result.to_csv(\"/content/drive/MyDrive/HW_2/val_predict_concat_MHA.tsv\", sep='\\t', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qiqgj--k9GHO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-04-18T19:55:54.010538Z",
          "iopub.status.busy": "2023-04-18T19:55:54.007210Z",
          "iopub.status.idle": "2023-04-18T19:55:55.205261Z",
          "shell.execute_reply": "2023-04-18T19:55:55.203740Z",
          "shell.execute_reply.started": "2023-04-18T19:55:54.010489Z"
        },
        "id": "Qiqgj--k9GHO",
        "outputId": "84170e0d-338c-41e5-eb14-6a666fa6488d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "updating: content/drive/MyDrive/HW_2/val_predict_concat.tsv (deflated 73%)\n"
          ]
        }
      ],
      "source": [
        "!zip /content/drive/MyDrive/HW_2/val_predict_concat.zip /content/drive/MyDrive/HW_2/val_predict_concat.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IN3g1uCHN4nY",
      "metadata": {
        "id": "IN3g1uCHN4nY"
      },
      "outputs": [],
      "source": [
        "CLASS_NAME = \"quarantine\"\n",
        "df1 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_AdamW_lr_5e6_{CLASS_NAME}.tsv\", sep='\\t')\n",
        "CLASS_NAME = \"masks\"\n",
        "df2 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_{CLASS_NAME}.tsv\", sep='\\t')\n",
        "CLASS_NAME = \"vaccines\"\n",
        "df3 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_{CLASS_NAME}.tsv\", sep='\\t')\n",
        "\n",
        "\n",
        "result = pd.merge(df1, df2, on=\"text\")\n",
        "result = pd.merge(result, df3, on=\"text\")\n",
        "result.to_csv(\"/content/drive/MyDrive/HW_2/val_predict_concat_MHA_AdamW_lr_5e6.tsv\", sep='\\t', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PADlbfKm4i-t",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-19T20:26:54.687650Z",
          "iopub.status.busy": "2023-04-19T20:26:54.687219Z",
          "iopub.status.idle": "2023-04-19T20:26:56.851874Z",
          "shell.execute_reply": "2023-04-19T20:26:56.850597Z",
          "shell.execute_reply.started": "2023-04-19T20:26:54.687601Z"
        },
        "id": "PADlbfKm4i-t",
        "outputId": "69c022d8-e820-45b3-b777-db068609cad4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JFBva7VMJocCLVUPrsCyqLD7QOYbHh-F\n",
            "To: /kaggle/working/val_predict_MHA_masks.tsv\n",
            "100%|█████████████████████████████████████████| 306k/306k [00:00<00:00, 102MB/s]\n"
          ]
        }
      ],
      "source": [
        "! gdown 1JFBva7VMJocCLVUPrsCyqLD7QOYbHh-F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9OZUIW44iL7J",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-19T21:55:51.312496Z",
          "iopub.status.busy": "2023-04-19T21:55:51.311737Z",
          "iopub.status.idle": "2023-04-19T21:55:51.359733Z",
          "shell.execute_reply": "2023-04-19T21:55:51.358656Z",
          "shell.execute_reply.started": "2023-04-19T21:55:51.312451Z"
        },
        "id": "9OZUIW44iL7J",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(f\"/kaggle/working/val_predict_MHA_AdamW_lr_5e6_quarantine.tsv\", sep='\\t')\n",
        "df2 = pd.read_csv(f\"/kaggle/working/val_predict_MHA_Adam_5e_6_vaccines.tsv\", sep='\\t')\n",
        "df3 = pd.read_csv(f\"/kaggle/working/val_predict_MHA_AdamW_lr_5e6_masks.tsv\", sep='\\t')\n",
        "\n",
        "\n",
        "result = pd.merge(df1, df2, on=\"text\")\n",
        "result = pd.merge(result, df3, on=\"text\")\n",
        "result.to_csv(\"/kaggle/working/val_q_v_m.tsv\", sep='\\t', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rQSogYpDiL7J",
      "metadata": {
        "id": "rQSogYpDiL7J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1b3c19fa-f883-4675-9506-85c4f02f0af9",
        "VZa3_IxI9GHJ",
        "1TjrWgJs9GHL",
        "T5v7lBS49GHM",
        "peIWpSF59GHN"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0128ba3037d54f689efe4fc9abe25bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52458245c5984599bdfbbcb3563a38ee",
            "placeholder": "​",
            "style": "IPY_MODEL_b86ea15b73a747a69ba379bdd890dc1b",
            "value": " 112/112 [00:00&lt;00:00, 4.91kB/s]"
          }
        },
        "076fab6237eb4abfadd1f25330041b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1288e4dbb6fa42abb8786a14d6a58fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "168b4a4a02e74707a85c4a57f6f65deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f05103783e324ef5be9b6be4625934f8",
            "max": 1649718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6744639e9adb4beda7d1eaa91cd48e20",
            "value": 1649718
          }
        },
        "1859ea04a21349d8a4b7b657c896bf75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19373f266a3b45c29f5cf8b164e68809": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d6cfcf43f62450b8432462e839f776a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b7e428fa9554798b652e307c9a0d789",
            "placeholder": "​",
            "style": "IPY_MODEL_b214014bdc094792b33a1e6ac1bb283f",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "1e81219c44ff4cf19bdb083c4a372e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f74d62057f64197a68ef807fae1f0cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aae01d39da4a4d39b95ba98f138e9920",
            "placeholder": "​",
            "style": "IPY_MODEL_2909ae3e202545ca97f2d177a50ceaa9",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "235bd2cda15142dfa7a99f8fd8cd0a9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27fc82e66c7747ef966440dcbfcbade8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289ff43ec3604aa1a2430f53c39d9bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f3e3315e4349da8459d980058b9cf5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbeeb5a93bca48ebb320a13e0e9937d1",
            "value": 1
          }
        },
        "2909ae3e202545ca97f2d177a50ceaa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fe76d7b205a4c37b6a3d60e27bc0f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5842bd0413754232a206c565d66df1d0",
            "placeholder": "​",
            "style": "IPY_MODEL_c56ed62af4d943ec829f02f69cfb1a18",
            "value": " 711M/711M [00:14&lt;00:00, 38.5MB/s]"
          }
        },
        "39b3a03232074940a32d832ed72b9bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b7e428fa9554798b652e307c9a0d789": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42287c1ea97f4d959d4cb1d86c65ee3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fb2681bef4f4a7dbf203bfb812910ce",
            "placeholder": "​",
            "style": "IPY_MODEL_c6951df00866437380f997604f2d0e88",
            "value": " 1.65M/1.65M [00:00&lt;00:00, 7.38MB/s]"
          }
        },
        "44950988de7144ba9c075a5901fe6d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fb2681bef4f4a7dbf203bfb812910ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52458245c5984599bdfbbcb3563a38ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57fb930a50d546be9ad485886f58a54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71e436214e95485da4d300218b6339f9",
            "placeholder": "​",
            "style": "IPY_MODEL_076fab6237eb4abfadd1f25330041b9b",
            "value": "2042.839 MB of 2042.839 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "58365ddd22454f7e8148e5e417ae0a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d6cfcf43f62450b8432462e839f776a",
              "IPY_MODEL_65bec8e640c04dd3bfd525e9d85a228c",
              "IPY_MODEL_0128ba3037d54f689efe4fc9abe25bb5"
            ],
            "layout": "IPY_MODEL_c2c994d8d37d42aa9c707b3cd95fc315"
          }
        },
        "5842bd0413754232a206c565d66df1d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6042b5798fd444f6bc658ee9669211bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ae863966f849789ea5e1b93a18e47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65bec8e640c04dd3bfd525e9d85a228c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e81219c44ff4cf19bdb083c4a372e1f",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a2938dd5138476ebd05358c4855ef0f",
            "value": 112
          }
        },
        "664a0142c8734e0b8cfb07fd42e57aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57fb930a50d546be9ad485886f58a54f",
              "IPY_MODEL_289ff43ec3604aa1a2430f53c39d9bfb"
            ],
            "layout": "IPY_MODEL_27fc82e66c7747ef966440dcbfcbade8"
          }
        },
        "6744639e9adb4beda7d1eaa91cd48e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cd77a7ebbfe446389ea3461318d5a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d035931093f248369dbb26f17eb590bf",
              "IPY_MODEL_fd8d238024cb43019ad5552237000223",
              "IPY_MODEL_a55bc959b5464902be6584288ce7b8d1"
            ],
            "layout": "IPY_MODEL_235bd2cda15142dfa7a99f8fd8cd0a9b"
          }
        },
        "71e436214e95485da4d300218b6339f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7264c4efd2d142cb9da4997994d13090": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a2938dd5138476ebd05358c4855ef0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ee59eb8a0954366a92cfc8aec52d5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7facfea53845464981c9cb07b31137c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f66f51ecc2204b21928b34740b028474",
            "placeholder": "​",
            "style": "IPY_MODEL_39b3a03232074940a32d832ed72b9bf4",
            "value": " 24.0/24.0 [00:00&lt;00:00, 769B/s]"
          }
        },
        "8d9e9d90c9bd4548bff981b9c63a4259": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94da8c2174b6465a8b09099ca1c698c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95248307486c46b59e794349a399d238": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6851b1763c64aaaa53bed69b05f56be",
              "IPY_MODEL_f940b7a547524f728476c9f00db7898f",
              "IPY_MODEL_2fe76d7b205a4c37b6a3d60e27bc0f12"
            ],
            "layout": "IPY_MODEL_6042b5798fd444f6bc658ee9669211bf"
          }
        },
        "9fedcf90bd234b92b2a9ca884c16e082": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55bc959b5464902be6584288ce7b8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de5a58be128a4e23a3adcecacef41e2f",
            "placeholder": "​",
            "style": "IPY_MODEL_d2c7cac0850d4c76ae22dccdf1a594d8",
            "value": " 642/642 [00:00&lt;00:00, 22.0kB/s]"
          }
        },
        "a604b16f25c34d568e59294280330bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dafedb9a4229445384d73bca5be86700",
            "placeholder": "​",
            "style": "IPY_MODEL_64ae863966f849789ea5e1b93a18e47d",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "aae01d39da4a4d39b95ba98f138e9920": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b214014bdc094792b33a1e6ac1bb283f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b86ea15b73a747a69ba379bdd890dc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2c994d8d37d42aa9c707b3cd95fc315": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43d9796980542518e7fc98a22aa96af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c51a2be116e740a19a4aaac982c89717": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56ed62af4d943ec829f02f69cfb1a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6951df00866437380f997604f2d0e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d035931093f248369dbb26f17eb590bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d9e9d90c9bd4548bff981b9c63a4259",
            "placeholder": "​",
            "style": "IPY_MODEL_e0e368e7fa9e4c45b7babb003d17a99f",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "d2c7cac0850d4c76ae22dccdf1a594d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5aea24b949c430195ad3e4b6835deb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f74d62057f64197a68ef807fae1f0cf",
              "IPY_MODEL_e02e39a6969c42ba9c9096f4eb7aead1",
              "IPY_MODEL_7facfea53845464981c9cb07b31137c9"
            ],
            "layout": "IPY_MODEL_94da8c2174b6465a8b09099ca1c698c0"
          }
        },
        "dadd760b9d8142ae987b8868409353c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a604b16f25c34d568e59294280330bd8",
              "IPY_MODEL_168b4a4a02e74707a85c4a57f6f65deb",
              "IPY_MODEL_42287c1ea97f4d959d4cb1d86c65ee3f"
            ],
            "layout": "IPY_MODEL_9fedcf90bd234b92b2a9ca884c16e082"
          }
        },
        "dafedb9a4229445384d73bca5be86700": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbeeb5a93bca48ebb320a13e0e9937d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de5a58be128a4e23a3adcecacef41e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02e39a6969c42ba9c9096f4eb7aead1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7264c4efd2d142cb9da4997994d13090",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c43d9796980542518e7fc98a22aa96af",
            "value": 24
          }
        },
        "e0e368e7fa9e4c45b7babb003d17a99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f05103783e324ef5be9b6be4625934f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f3e3315e4349da8459d980058b9cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66f51ecc2204b21928b34740b028474": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6851b1763c64aaaa53bed69b05f56be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c51a2be116e740a19a4aaac982c89717",
            "placeholder": "​",
            "style": "IPY_MODEL_7ee59eb8a0954366a92cfc8aec52d5a9",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "f940b7a547524f728476c9f00db7898f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19373f266a3b45c29f5cf8b164e68809",
            "max": 711456784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1288e4dbb6fa42abb8786a14d6a58fcc",
            "value": 711456784
          }
        },
        "fd8d238024cb43019ad5552237000223": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1859ea04a21349d8a4b7b657c896bf75",
            "max": 642,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44950988de7144ba9c075a5901fe6d58",
            "value": 642
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
