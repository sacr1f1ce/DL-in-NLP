{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09d7a19-5848-43f4-9d91-f35d4e8614b0",
   "metadata": {
    "id": "b09d7a19-5848-43f4-9d91-f35d4e8614b0"
   },
   "source": [
    "# 1. Information about the submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37cb5bb-f3d0-4c11-a1dc-2490a208fcd3",
   "metadata": {
    "id": "e37cb5bb-f3d0-4c11-a1dc-2490a208fcd3"
   },
   "source": [
    "## 1.1 Name and number of the assignment "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e9d00b8-f3e5-4a44-bcc6-35cdd60767a9",
   "metadata": {
    "id": "4e9d00b8-f3e5-4a44-bcc6-35cdd60767a9"
   },
   "source": [
    "### Text categorization and argument mining task. HW2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba7f63-66ec-4691-a5d2-17f4679e298d",
   "metadata": {
    "id": "64ba7f63-66ec-4691-a5d2-17f4679e298d"
   },
   "source": [
    "## 1.2 Student name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc8a4e09-62cc-43fd-a7a7-3e9d55ec13b2",
   "metadata": {
    "id": "cc8a4e09-62cc-43fd-a7a7-3e9d55ec13b2"
   },
   "source": [
    "### Nuzhnov Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a46ab45-d215-41af-b910-63ff4a215a07",
   "metadata": {
    "id": "8a46ab45-d215-41af-b910-63ff4a215a07"
   },
   "source": [
    "## 1.3 Codalab user ID"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b15cd6b5-8e20-4287-b6ea-a7b0904b355a",
   "metadata": {
    "id": "b15cd6b5-8e20-4287-b6ea-a7b0904b355a"
   },
   "source": [
    "### Nuzhnov_Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70456c74-8e1f-4da0-bebe-fbceee169115",
   "metadata": {
    "id": "70456c74-8e1f-4da0-bebe-fbceee169115"
   },
   "source": [
    "## 1.4 Additional comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b810ac6-7739-4f7f-8bea-dbf1198570ea",
   "metadata": {
    "id": "6b810ac6-7739-4f7f-8bea-dbf1198570ea"
   },
   "source": [
    "***Enter here** any additional comments which you would like to communicate to a TA who is going to grade this work not related to the content of your submission.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af498ab-3c00-4d36-a962-c947862fede8",
   "metadata": {
    "id": "1af498ab-3c00-4d36-a962-c947862fede8"
   },
   "source": [
    "# 2. Technical Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c18a6-868b-4357-a308-7f6dff05c3d0",
   "metadata": {
    "id": "9b3c18a6-868b-4357-a308-7f6dff05c3d0"
   },
   "source": [
    "*Use Section 2 to describe results of your experiments as you would do writing a paper about your results. DO NOT insert code in this part. Only insert plots and tables summarizing results as needed. Use formulas if needed do described your methodology. The code is provided in Section 3.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f71b9-114a-4cb0-b531-5711970317bf",
   "metadata": {
    "id": "061f71b9-114a-4cb0-b531-5711970317bf"
   },
   "source": [
    "## 2.1 Methodology "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327f43e-ed30-4279-bba2-a97b2f8ef9e3",
   "metadata": {
    "id": "c327f43e-ed30-4279-bba2-a97b2f8ef9e3"
   },
   "source": [
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a recent paper published by researchers at Google AI Language. In practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix $Q$.   The keys and values are also packed together into matrices $K$ and $V$.  We compute the matrix of outputs as:                      \n",
    "                                                                 \n",
    "$$                                                                         \n",
    "   \\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V               \n",
    "$$   \n",
    "\n",
    "![alt text](https://lena-voita.github.io/resources/lectures/seq2seq/transformer/qkv_explained-min.png)\n",
    "Source: [Lena Voita's Lecture about Seq2Seq](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)\n",
    "\n",
    "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.                                            \n",
    "$$    \n",
    "\\mathrm{MultiHead}(Q, K, V) = \\mathrm{Concat}(\\mathrm{head_1}, ..., \\mathrm{head_h})W^O    \\\\                                           \n",
    "    \\text{where}~\\mathrm{head_i} = \\mathrm{Attention}(QW^Q_i, KW^K_i, VW^V_i)                                \n",
    "$$                                                                                                                 \n",
    "\n",
    "Where the projections are parameter matrices $W^Q_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^K_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^V_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}$ and $W^O \\in \\mathbb{R}^{hd_v \\times d_{\\text{model}}}$.                                                                                                                                                                                             In this work I tried employ $h=3$, $h=5$, $h=8$ parallel attention layers, or heads. For each of these I use $d_k=d_v=d_{\\text{model}}/h=64$. Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality. \n",
    "\n",
    "![alt text](https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png)\n",
    "Source: [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe27e49-10c7-4c12-adea-48b0a05a5681",
   "metadata": {
    "id": "afe27e49-10c7-4c12-adea-48b0a05a5681"
   },
   "source": [
    "## 2.2 Discussion of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1c84c-c261-46b5-a009-0f2bc4002752",
   "metadata": {
    "id": "b5b1c84c-c261-46b5-a009-0f2bc4002752"
   },
   "source": [
    "Discussing the results I would say that Baseline model (without multihead attention layer) gives a **0.3924 - F1_Stance_Detection** and **0.4517 - F1_Premise_Classification**. By adding MHA layer I was able to increased the score to **0.5713 - F1_Stance_Detection** and **0.6179 - F1_Premise_Classification**. Regarding to loss values we can see that in my case **val_argument_accuracy** was always higher than **val_stance_accuracy**, and loss was controversial. All graphs and losses can be found by the link to wandb below.\n",
    "\n",
    "https://wandb.ai/smolenkovaea00/Text_categorization?workspace=user-smolenkovaea00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194fecf1-e044-4210-a54b-aefbf4b4eebe",
   "metadata": {
    "id": "194fecf1-e044-4210-a54b-aefbf4b4eebe"
   },
   "source": [
    "# 3. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33ff9bd-62c6-4a63-8600-b1651420fee1",
   "metadata": {
    "id": "a33ff9bd-62c6-4a63-8600-b1651420fee1"
   },
   "source": [
    "*Enter here all code used to produce your results submitted to Codalab. Add some comments and subsections to navigate though your solution.*\n",
    "\n",
    "*In this part you are expected to develop yourself a solution of the task and provide a reproducible code:*\n",
    "- *Using Python 3;*\n",
    "- *Contains code for installation of all dependencies;*\n",
    "- *Contains code for downloading of all the datasets used*;\n",
    "- *Contains the code for reproducing your results (in other words, if a tester downloads your notebook she should be able to run cell-by-cell the code and obtain your experimental results as described in the methodology section)*.\n",
    "\n",
    "\n",
    "*As a result, you code will be graded according to these criteria:*\n",
    "- ***Readability**: your code should be well-structured preferably with indicated parts of your approach (Preprocessing, Model training, Evaluation, etc.).*\n",
    "- ***Reproducibility**: your code should be reproduced without any mistakes with “Run all” mode (obtaining experimental part).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff93e37-3a24-40ab-87db-16b537aad3f6",
   "metadata": {
    "id": "dff93e37-3a24-40ab-87db-16b537aad3f6"
   },
   "source": [
    "## 3.1 Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paNHf6yRz5jK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-20T10:01:05.242096Z",
     "iopub.status.busy": "2023-04-20T10:01:05.241616Z",
     "iopub.status.idle": "2023-04-20T10:01:36.229144Z",
     "shell.execute_reply": "2023-04-20T10:01:36.227941Z",
     "shell.execute_reply.started": "2023-04-20T10:01:05.242058Z"
    },
    "id": "paNHf6yRz5jK",
    "outputId": "a5d5f4d1-0efd-4bbd-f645-dab00243ed2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-4.7.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.14.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.18.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from wandb) (4.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.8.0)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.11.4)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.11.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install gdown\n",
    "! pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73daa932-114b-4e28-9141-13b57c729435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T10:01:36.232263Z",
     "iopub.status.busy": "2023-04-20T10:01:36.231838Z",
     "iopub.status.idle": "2023-04-20T10:01:47.062545Z",
     "shell.execute_reply": "2023-04-20T10:01:47.061333Z",
     "shell.execute_reply.started": "2023-04-20T10:01:36.232219Z"
    },
    "id": "73daa932-114b-4e28-9141-13b57c729435"
   },
   "outputs": [],
   "source": [
    "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Flatten, TimeDistributed\n",
    "from tensorflow.keras.optimizers.experimental import AdamW\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ifqn-NB_9GHI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246,
     "referenced_widgets": [
      "6cd77a7ebbfe446389ea3461318d5a3f",
      "d035931093f248369dbb26f17eb590bf",
      "fd8d238024cb43019ad5552237000223",
      "a55bc959b5464902be6584288ce7b8d1",
      "235bd2cda15142dfa7a99f8fd8cd0a9b",
      "8d9e9d90c9bd4548bff981b9c63a4259",
      "e0e368e7fa9e4c45b7babb003d17a99f",
      "1859ea04a21349d8a4b7b657c896bf75",
      "44950988de7144ba9c075a5901fe6d58",
      "de5a58be128a4e23a3adcecacef41e2f",
      "d2c7cac0850d4c76ae22dccdf1a594d8",
      "d5aea24b949c430195ad3e4b6835deb4",
      "1f74d62057f64197a68ef807fae1f0cf",
      "e02e39a6969c42ba9c9096f4eb7aead1",
      "7facfea53845464981c9cb07b31137c9",
      "94da8c2174b6465a8b09099ca1c698c0",
      "aae01d39da4a4d39b95ba98f138e9920",
      "2909ae3e202545ca97f2d177a50ceaa9",
      "7264c4efd2d142cb9da4997994d13090",
      "c43d9796980542518e7fc98a22aa96af",
      "f66f51ecc2204b21928b34740b028474",
      "39b3a03232074940a32d832ed72b9bf4",
      "dadd760b9d8142ae987b8868409353c4",
      "a604b16f25c34d568e59294280330bd8",
      "168b4a4a02e74707a85c4a57f6f65deb",
      "42287c1ea97f4d959d4cb1d86c65ee3f",
      "9fedcf90bd234b92b2a9ca884c16e082",
      "dafedb9a4229445384d73bca5be86700",
      "64ae863966f849789ea5e1b93a18e47d",
      "f05103783e324ef5be9b6be4625934f8",
      "6744639e9adb4beda7d1eaa91cd48e20",
      "4fb2681bef4f4a7dbf203bfb812910ce",
      "c6951df00866437380f997604f2d0e88",
      "58365ddd22454f7e8148e5e417ae0a63",
      "1d6cfcf43f62450b8432462e839f776a",
      "65bec8e640c04dd3bfd525e9d85a228c",
      "0128ba3037d54f689efe4fc9abe25bb5",
      "c2c994d8d37d42aa9c707b3cd95fc315",
      "3b7e428fa9554798b652e307c9a0d789",
      "b214014bdc094792b33a1e6ac1bb283f",
      "1e81219c44ff4cf19bdb083c4a372e1f",
      "7a2938dd5138476ebd05358c4855ef0f",
      "52458245c5984599bdfbbcb3563a38ee",
      "b86ea15b73a747a69ba379bdd890dc1b",
      "95248307486c46b59e794349a399d238",
      "f6851b1763c64aaaa53bed69b05f56be",
      "f940b7a547524f728476c9f00db7898f",
      "2fe76d7b205a4c37b6a3d60e27bc0f12",
      "6042b5798fd444f6bc658ee9669211bf",
      "c51a2be116e740a19a4aaac982c89717",
      "7ee59eb8a0954366a92cfc8aec52d5a9",
      "19373f266a3b45c29f5cf8b164e68809",
      "1288e4dbb6fa42abb8786a14d6a58fcc",
      "5842bd0413754232a206c565d66df1d0",
      "c56ed62af4d943ec829f02f69cfb1a18",
      "4278a2522b5b4828ae3dc3cf0a342464",
      "9c9c02b2c7164ecbaa46f5fc46cf442b",
      "d5356f37663149859ffc075a97bcd298",
      "7e1902d83138404a9a31ff4a090e8c84",
      "e51ca994a9fc42f49cb9dac440fa3582"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-04-20T10:01:47.064761Z",
     "iopub.status.busy": "2023-04-20T10:01:47.064375Z",
     "iopub.status.idle": "2023-04-20T10:02:00.868029Z",
     "shell.execute_reply": "2023-04-20T10:02:00.867013Z",
     "shell.execute_reply.started": "2023-04-20T10:01:47.064717Z"
    },
    "id": "Ifqn-NB_9GHI",
    "outputId": "681d1dec-fcb0-4981-fb07-f3da2240caa6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4278a2522b5b4828ae3dc3cf0a342464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9c02b2c7164ecbaa46f5fc46cf442b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5356f37663149859ffc075a97bcd298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1902d83138404a9a31ff4a090e8c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51ca994a9fc42f49cb9dac440fa3582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertModel.\n",
      "\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Name of the BERT model to use\n",
    "model_name = 'DeepPavlov/rubert-base-cased-sentence'\n",
    "\n",
    "# Load transformers config and set output_hidden_states to False\n",
    "config = BertConfig.from_pretrained(model_name)\n",
    "config.output_hidden_states = False\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config=config)\n",
    "\n",
    "# Load the Transformers BERT model\n",
    "transformer_model = TFBertModel.from_pretrained(model_name, config=config, from_pt=True)\n",
    "\n",
    "# Load the MainLayer\n",
    "bert = transformer_model.layers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c19fa-f883-4675-9506-85c4f02f0af9",
   "metadata": {
    "id": "1b3c19fa-f883-4675-9506-85c4f02f0af9"
   },
   "source": [
    "## 3.2 Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f366b0f-7d0b-44e0-bb82-0d82c3ea1bb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-20T10:02:00.873091Z",
     "iopub.status.busy": "2023-04-20T10:02:00.870660Z",
     "iopub.status.idle": "2023-04-20T10:02:03.522832Z",
     "shell.execute_reply": "2023-04-20T10:02:03.521377Z",
     "shell.execute_reply.started": "2023-04-20T10:02:00.873058Z"
    },
    "id": "8f366b0f-7d0b-44e0-bb82-0d82c3ea1bb1",
    "outputId": "cfd9f867-64e3-4032-c0ef-135025330da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=19LzgUlM3417TlG6bmo-eSY5vRAKw2ukR\n",
      "To: /kaggle/working/train_all.tsv\n",
      "100%|███████████████████████████████████████| 1.54M/1.54M [00:00<00:00, 133MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 19LzgUlM3417TlG6bmo-eSY5vRAKw2ukR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t9RX0IdD9GHI",
   "metadata": {
    "id": "t9RX0IdD9GHI"
   },
   "source": [
    "## 3.3 Quarantine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cKrIw_Ve9GHI",
   "metadata": {
    "id": "cKrIw_Ve9GHI"
   },
   "source": [
    "### 3.3.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa2274-477a-46e6-95ff-ec98e633ab35",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-20T12:50:36.749519Z",
     "iopub.status.idle": "2023-04-20T12:50:36.750469Z",
     "shell.execute_reply": "2023-04-20T12:50:36.750176Z",
     "shell.execute_reply.started": "2023-04-20T12:50:36.750139Z"
    },
    "id": "f4aa2274-477a-46e6-95ff-ec98e633ab35"
   },
   "outputs": [],
   "source": [
    "CLASS_NAME = \"quarantine\"\n",
    "# Import data from csv\n",
    "whole_data = pd.read_csv('/kaggle/working/train_all.tsv', sep='\\t')\n",
    "\n",
    "# Train_test_split\n",
    "test_size = 0.4\n",
    "data, data_test = train_test_split(whole_data, test_size=test_size, random_state = seed_value)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "## Train\n",
    "# Select required columns\n",
    "data = data[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "\n",
    "# Set your model output as categorical and save in new label col\n",
    "data['stance_label'] = pd.Categorical(data[f'{CLASS_NAME}_stance'])\n",
    "data['argument_label'] = pd.Categorical(data[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Transform your output to numeric\n",
    "data[f'{CLASS_NAME}_stance'] = data['stance_label'].cat.codes\n",
    "data[f'{CLASS_NAME}_argument'] = data['argument_label'].cat.codes\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "## Test\n",
    "# Select required columns\n",
    "data_test = data_test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "\n",
    "# Set your model output as categorical and save in new label col\n",
    "data_test['stance_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_stance'])\n",
    "data_test['argument_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Transform your output to numeric\n",
    "data_test[f'{CLASS_NAME}_stance'] = data_test['stance_label'].cat.codes\n",
    "data_test[f'{CLASS_NAME}_argument'] = data_test['argument_label'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hm3BY632zyn1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-20T12:50:36.752321Z",
     "iopub.status.idle": "2023-04-20T12:50:36.753250Z",
     "shell.execute_reply": "2023-04-20T12:50:36.753014Z",
     "shell.execute_reply.started": "2023-04-20T12:50:36.752983Z"
    },
    "id": "hm3BY632zyn1"
   },
   "outputs": [],
   "source": [
    "#wandb.init(project=\"Text_categorization\", name = \"baseline_run\", tags = [\"Ruberta\", \"RB\"])\n",
    "# Ready output data for the model\n",
    "test_y_stance = to_categorical(data_test[f'{CLASS_NAME}_stance'])\n",
    "test_y_argument = to_categorical(data_test[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "test_x = tokenizer(\n",
    "    text=data_test['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6mfHDU3GWdy6",
   "metadata": {
    "id": "6mfHDU3GWdy6"
   },
   "source": [
    "### 3.3.2 Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8DuMYSSnzyrU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T18:27:56.180203Z",
     "iopub.status.busy": "2023-04-18T18:27:56.179785Z",
     "iopub.status.idle": "2023-04-18T18:28:01.686653Z",
     "shell.execute_reply": "2023-04-18T18:28:01.685782Z",
     "shell.execute_reply.started": "2023-04-18T18:27:56.180168Z"
    },
    "id": "8DuMYSSnzyrU",
    "outputId": "489231c6-6e29-4d0d-c330-2ee6d27c153d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiLabel_MultiClass\"\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "\n",
      "==================================================================================================\n",
      "\n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "\n",
      "                                                                                                  \n",
      "\n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['input_ids[0][0]']              \n",
      "\n",
      "                                thPoolingAndCrossAt                                               \n",
      "\n",
      "                                tentions(last_hidde                                               \n",
      "\n",
      "                                n_state=(None, 256,                                               \n",
      "\n",
      "                                 768),                                                            \n",
      "\n",
      "                                 pooler_output=(Non                                               \n",
      "\n",
      "                                e, 768),                                                          \n",
      "\n",
      "                                 past_key_values=No                                               \n",
      "\n",
      "                                ne, hidden_states=N                                               \n",
      "\n",
      "                                one, attentions=Non                                               \n",
      "\n",
      "                                e, cross_attentions                                               \n",
      "\n",
      "                                =None)                                                            \n",
      "\n",
      "                                                                                                  \n",
      "\n",
      " pooled_output (Dropout)        (None, 768)          0           ['bert[1][1]']                   \n",
      "\n",
      "                                                                                                  \n",
      "\n",
      " argument (Dense)               (None, 4)            3076        ['pooled_output[0][0]']          \n",
      "\n",
      "                                                                                                  \n",
      "\n",
      " stance (Dense)                 (None, 4)            3076        ['pooled_output[0][0]']          \n",
      "\n",
      "                                                                                                  \n",
      "\n",
      "==================================================================================================\n",
      "\n",
      "Total params: 177,859,592\n",
      "\n",
      "Trainable params: 177,859,592\n",
      "\n",
      "Non-trainable params: 0\n",
      "\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build your model input\n",
    "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "inputs = {'input_ids': input_ids}\n",
    "\n",
    "# Load the Transformers BERT model as a layer in a Keras model\n",
    "bert_model = bert(inputs)[1]\n",
    "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "pooled_output = dropout(bert_model, training=False)\n",
    "\n",
    "# Then build your model output\n",
    "stance = Dense(units=len(data.stance_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
    "argument = Dense(units=len(data.argument_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
    "outputs = {'stance': stance, 'argument': argument}\n",
    "\n",
    "# And combine it all in a model object\n",
    "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
    "\n",
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KLOaX_HE9GHJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 940
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T18:28:20.212474Z",
     "iopub.status.busy": "2023-04-18T18:28:20.212054Z",
     "iopub.status.idle": "2023-04-18T18:31:58.735610Z",
     "shell.execute_reply": "2023-04-18T18:31:58.732299Z",
     "shell.execute_reply.started": "2023-04-18T18:28:20.212440Z"
    },
    "id": "KLOaX_HE9GHJ",
    "outputId": "02d03914-a17f-4fa8-d774-78dcad833cac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20230418_200519-egdadxhc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/egdadxhc' target=\"_blank\">baseline_run_quarantine</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/egdadxhc' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/egdadxhc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "672/672 [==============================] - ETA: 0s - loss: 1.7180 - argument_loss: 0.8148 - stance_loss: 0.9032 - argument_accuracy: 0.6868 - stance_accuracy: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230418_200519-egdadxhc/files/model-best)... Done. 13.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 558s 674ms/step - loss: 1.7180 - argument_loss: 0.8148 - stance_loss: 0.9032 - argument_accuracy: 0.6868 - stance_accuracy: 0.6875 - val_loss: 1.5449 - val_argument_loss: 0.7069 - val_stance_loss: 0.8380 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 2/20\n",
      "\n",
      "672/672 [==============================] - ETA: 0s - loss: 1.4550 - argument_loss: 0.6857 - stance_loss: 0.7692 - argument_accuracy: 0.7499 - stance_accuracy: 0.7340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230418_200519-egdadxhc/files/model-best)... Done. 12.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 426s 633ms/step - loss: 1.4550 - argument_loss: 0.6857 - stance_loss: 0.7692 - argument_accuracy: 0.7499 - stance_accuracy: 0.7340 - val_loss: 0.3162 - val_argument_loss: 0.0847 - val_stance_loss: 0.2316 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
      "\n",
      "Epoch 3/20\n",
      "\n",
      "672/672 [==============================] - 358s 533ms/step - loss: 1.2980 - argument_loss: 0.6068 - stance_loss: 0.6912 - argument_accuracy: 0.7828 - stance_accuracy: 0.7621 - val_loss: 1.5579 - val_argument_loss: 0.7391 - val_stance_loss: 0.8189 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 4/20\n",
      "\n",
      "672/672 [==============================] - 354s 527ms/step - loss: 1.7145 - argument_loss: 0.8130 - stance_loss: 0.9014 - argument_accuracy: 0.6868 - stance_accuracy: 0.6873 - val_loss: 1.5648 - val_argument_loss: 0.7260 - val_stance_loss: 0.8388 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 5/20\n",
      "\n",
      "672/672 [==============================] - 354s 527ms/step - loss: 1.7060 - argument_loss: 0.8098 - stance_loss: 0.8962 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5385 - val_argument_loss: 0.7278 - val_stance_loss: 0.8107 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 6/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.7019 - argument_loss: 0.8063 - stance_loss: 0.8955 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.6548 - val_argument_loss: 0.7624 - val_stance_loss: 0.8924 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 7/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.7025 - argument_loss: 0.8068 - stance_loss: 0.8957 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5914 - val_argument_loss: 0.7330 - val_stance_loss: 0.8583 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 8/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.6990 - argument_loss: 0.8054 - stance_loss: 0.8935 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5595 - val_argument_loss: 0.7375 - val_stance_loss: 0.8220 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 9/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.7003 - argument_loss: 0.8052 - stance_loss: 0.8951 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5721 - val_argument_loss: 0.7408 - val_stance_loss: 0.8313 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 10/20\n",
      "\n",
      "672/672 [==============================] - 352s 524ms/step - loss: 1.7001 - argument_loss: 0.8053 - stance_loss: 0.8948 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5324 - val_argument_loss: 0.7128 - val_stance_loss: 0.8196 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 11/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.6962 - argument_loss: 0.8033 - stance_loss: 0.8928 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5026 - val_argument_loss: 0.6976 - val_stance_loss: 0.8050 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 12/20\n",
      "\n",
      "672/672 [==============================] - 352s 524ms/step - loss: 1.6963 - argument_loss: 0.8041 - stance_loss: 0.8922 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5513 - val_argument_loss: 0.7291 - val_stance_loss: 0.8222 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 13/20\n",
      "\n",
      "672/672 [==============================] - 352s 525ms/step - loss: 1.6952 - argument_loss: 0.8044 - stance_loss: 0.8909 - argument_accuracy: 0.6875 - stance_accuracy: 0.6875 - val_loss: 1.5729 - val_argument_loss: 0.7364 - val_stance_loss: 0.8365 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 14/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.6946 - argument_loss: 0.8028 - stance_loss: 0.8918 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5836 - val_argument_loss: 0.7360 - val_stance_loss: 0.8476 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 15/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.6950 - argument_loss: 0.8029 - stance_loss: 0.8921 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5834 - val_argument_loss: 0.7289 - val_stance_loss: 0.8545 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 16/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.6960 - argument_loss: 0.8029 - stance_loss: 0.8931 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5522 - val_argument_loss: 0.7266 - val_stance_loss: 0.8257 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 17/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.6929 - argument_loss: 0.8021 - stance_loss: 0.8908 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5787 - val_argument_loss: 0.7435 - val_stance_loss: 0.8352 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 18/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.6929 - argument_loss: 0.8020 - stance_loss: 0.8909 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5994 - val_argument_loss: 0.7499 - val_stance_loss: 0.8495 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 19/20\n",
      "\n",
      "672/672 [==============================] - 353s 526ms/step - loss: 1.6935 - argument_loss: 0.8020 - stance_loss: 0.8916 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5741 - val_argument_loss: 0.7464 - val_stance_loss: 0.8277 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 20/20\n",
      "\n",
      "672/672 [==============================] - 353s 525ms/step - loss: 1.6906 - argument_loss: 0.8010 - stance_loss: 0.8895 - argument_accuracy: 0.6877 - stance_accuracy: 0.6877 - val_loss: 1.5661 - val_argument_loss: 0.7293 - val_stance_loss: 0.8368 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "! wandb login --relogin Nikita4epuh\n",
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-05,\n",
    "    epsilon=1e-08,\n",
    "    weight_decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
    "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)\n",
    "\n",
    "# Ready output data for the model\n",
    "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
    "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "x = tokenizer(\n",
    "    text=data['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "wandb.init(project=\"Text_categorization\", name = \"baseline_run_quarantine\", tags = [\"Ruberta\", \"RB\"])\n",
    "epochs = 20\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    x={'input_ids': x['input_ids']},\n",
    "    y={'stance': y_stance, 'argument': y_argument},\n",
    "    validation_data=({'input_ids': test_x['input_ids'][:8]}, {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
    "    batch_size=8,\n",
    "    epochs=epochs, callbacks=[WandbCallback()])\n",
    "for epoch in range(epochs): \n",
    "    wandb.log({'loss': history.history['loss'][epoch],\n",
    "               'argument_loss': history.history['argument_loss'][epoch],\n",
    "               'stance_loss': history.history['stance_loss'][epoch],\n",
    "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
    "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
    "               'val_loss': history.history['stance_accuracy'][epoch],\n",
    "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
    "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
    "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
    "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VZa3_IxI9GHJ",
   "metadata": {
    "id": "VZa3_IxI9GHJ"
   },
   "source": [
    "### 3.3.3 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TnSf8ppm5NLO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:10:45.961256Z",
     "iopub.status.busy": "2023-04-18T19:10:45.960545Z",
     "iopub.status.idle": "2023-04-18T19:11:12.697586Z",
     "shell.execute_reply": "2023-04-18T19:11:12.695780Z",
     "shell.execute_reply.started": "2023-04-18T19:10:45.961200Z"
    },
    "id": "TnSf8ppm5NLO",
    "outputId": "cddb5707-2869-4d20-ef63-17424f097f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 23s 526ms/step\n"
     ]
    }
   ],
   "source": [
    "val_results = model.predict(x={'input_ids': test_x['input_ids']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ygAMFDn99GHK",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T19:11:12.701147Z",
     "iopub.status.busy": "2023-04-18T19:11:12.700194Z",
     "iopub.status.idle": "2023-04-18T19:11:12.712696Z",
     "shell.execute_reply": "2023-04-18T19:11:12.710990Z",
     "shell.execute_reply.started": "2023-04-18T19:11:12.701107Z"
    },
    "id": "ygAMFDn99GHK"
   },
   "outputs": [],
   "source": [
    "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
    "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aMBWw0LD5NRD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:11:12.719848Z",
     "iopub.status.busy": "2023-04-18T19:11:12.715071Z",
     "iopub.status.idle": "2023-04-18T19:11:12.742831Z",
     "shell.execute_reply": "2023-04-18T19:11:12.741041Z",
     "shell.execute_reply.started": "2023-04-18T19:11:12.719804Z"
    },
    "id": "aMBWw0LD5NRD",
    "outputId": "242f4ecb-31f1-45cd-c9f3-7ef1bc6464dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       0.99      1.00      0.99       910\n",
      "\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "           2       0.62      0.98      0.76       267\n",
      "\n",
      "           3       0.00      0.00      0.00       134\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.87      1344\n",
      "\n",
      "   macro avg       0.40      0.49      0.44      1344\n",
      "\n",
      "weighted avg       0.79      0.87      0.82      1344\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PPWoe9y15NUC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:11:12.752486Z",
     "iopub.status.busy": "2023-04-18T19:11:12.749716Z",
     "iopub.status.idle": "2023-04-18T19:11:12.775830Z",
     "shell.execute_reply": "2023-04-18T19:11:12.774884Z",
     "shell.execute_reply.started": "2023-04-18T19:11:12.752438Z"
    },
    "id": "PPWoe9y15NUC",
    "outputId": "1436092d-8735-4c0a-c85e-9a3b3983fb2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       0.99      1.00      0.99       910\n",
      "\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "           2       0.85      0.97      0.91       375\n",
      "\n",
      "           3       0.00      0.00      0.00        41\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.94      1344\n",
      "\n",
      "   macro avg       0.46      0.49      0.47      1344\n",
      "\n",
      "weighted avg       0.91      0.94      0.92      1344\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ro1qIXGaUT1W",
   "metadata": {
    "id": "ro1qIXGaUT1W"
   },
   "source": [
    "### 3.3.4 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hN97GUdu9GHK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:30:58.676596Z",
     "iopub.status.busy": "2023-04-18T19:30:58.676186Z",
     "iopub.status.idle": "2023-04-18T19:30:58.710106Z",
     "shell.execute_reply": "2023-04-18T19:30:58.708762Z",
     "shell.execute_reply.started": "2023-04-18T19:30:58.676557Z"
    },
    "id": "hN97GUdu9GHK",
    "outputId": "2466028a-ff96-4434-ff30-39ce4006f7c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b5785579-5813-4a52-b355-ea0e76fd8582\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>masks_stance</th>\n",
       "      <th>masks_argument</th>\n",
       "      <th>quarantine_stance</th>\n",
       "      <th>quarantine_argument</th>\n",
       "      <th>vaccines_stance</th>\n",
       "      <th>vaccines_argument</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17041</td>\n",
       "      <td>&gt; 26 марта его поместили на принудительный кар...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17057</td>\n",
       "      <td>И шевкунов вещает из телевизора про необходимо...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17058</td>\n",
       "      <td>Это результат его  же лобировал до последнего ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17071</td>\n",
       "      <td>При этом нормально обеспечены (к слову о якобы...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17079</td>\n",
       "      <td>для опасного врага нужен официальный карантин ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5785579-5813-4a52-b355-ea0e76fd8582')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b5785579-5813-4a52-b355-ea0e76fd8582 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b5785579-5813-4a52-b355-ea0e76fd8582');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   text_id                                               text  masks_stance  \\\n",
       "0    17041  > 26 марта его поместили на принудительный кар...           NaN   \n",
       "1    17057  И шевкунов вещает из телевизора про необходимо...           NaN   \n",
       "2    17058  Это результат его  же лобировал до последнего ...           NaN   \n",
       "3    17071  При этом нормально обеспечены (к слову о якобы...           NaN   \n",
       "4    17079  для опасного врага нужен официальный карантин ...           NaN   \n",
       "\n",
       "   masks_argument  quarantine_stance  quarantine_argument  vaccines_stance  \\\n",
       "0             NaN                NaN                  NaN              NaN   \n",
       "1             NaN                NaN                  NaN              NaN   \n",
       "2             NaN                NaN                  NaN              NaN   \n",
       "3             NaN                NaN                  NaN              NaN   \n",
       "4             NaN                NaN                  NaN              NaN   \n",
       "\n",
       "   vaccines_argument  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"/content/drive/MyDrive/HW_2/val_empty.tsv\", sep='\\t')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3wo6ErB29GHK",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T19:30:58.712407Z",
     "iopub.status.busy": "2023-04-18T19:30:58.711416Z",
     "iopub.status.idle": "2023-04-18T19:30:58.719558Z",
     "shell.execute_reply": "2023-04-18T19:30:58.718134Z",
     "shell.execute_reply.started": "2023-04-18T19:30:58.712369Z"
    },
    "id": "3wo6ErB29GHK"
   },
   "outputs": [],
   "source": [
    "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7-f6bLrd9GHK",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T19:25:38.520306Z",
     "iopub.status.busy": "2023-04-18T19:25:38.519915Z",
     "iopub.status.idle": "2023-04-18T19:25:38.706951Z",
     "shell.execute_reply": "2023-04-18T19:25:38.705661Z",
     "shell.execute_reply.started": "2023-04-18T19:25:38.520260Z"
    },
    "id": "7-f6bLrd9GHK"
   },
   "outputs": [],
   "source": [
    "for_pred = tokenizer(\n",
    "    text=test_d['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "luOpNbda9GHK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:28:01.274416Z",
     "iopub.status.busy": "2023-04-18T19:28:01.274022Z",
     "iopub.status.idle": "2023-04-18T19:28:33.862666Z",
     "shell.execute_reply": "2023-04-18T19:28:33.859414Z",
     "shell.execute_reply.started": "2023-04-18T19:28:01.274380Z"
    },
    "id": "luOpNbda9GHK",
    "outputId": "a67aa777-77a3-4193-cd13-52828b38f32e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 29s 553ms/step\n"
     ]
    }
   ],
   "source": [
    "test_results = model.predict(x={'input_ids': for_pred['input_ids']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MEvGRgeU9GHK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:31:04.832531Z",
     "iopub.status.busy": "2023-04-18T19:31:04.831958Z",
     "iopub.status.idle": "2023-04-18T19:31:04.845182Z",
     "shell.execute_reply": "2023-04-18T19:31:04.843039Z",
     "shell.execute_reply.started": "2023-04-18T19:31:04.832493Z"
    },
    "id": "MEvGRgeU9GHK",
    "outputId": "7c811b4d-c05f-42a7-c2cc-5360b9eae75e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stance': array([[-4.089829  , -0.33473855,  2.5395935 ,  1.3415891 ],\n",
       "        [-4.0897512 , -0.3347472 ,  2.5395615 ,  1.3415637 ],\n",
       "        [-4.0894866 , -0.33475885,  2.5394356 ,  1.3414531 ],\n",
       "        ...,\n",
       "        [ 5.198219  , -1.4057834 , -1.263636  , -1.1913619 ],\n",
       "        [ 5.200686  , -1.4059892 , -1.2654437 , -1.1920764 ],\n",
       "        [ 5.1925864 , -1.4060783 , -1.2590035 , -1.1900823 ]],\n",
       "       dtype=float32),\n",
       " 'argument': array([[-4.1424227 , -0.21485949,  2.9515023 ,  0.39686468],\n",
       "        [-4.1423306 , -0.21488512,  2.9514856 ,  0.3968405 ],\n",
       "        [-4.1420374 , -0.21497214,  2.9513922 ,  0.39675808],\n",
       "        ...,\n",
       "        [ 5.410088  , -1.8092142 , -0.41383114, -1.7783811 ],\n",
       "        [ 5.4125404 , -1.8092424 , -0.41525313, -1.7785566 ],\n",
       "        [ 5.40485   , -1.8096377 , -0.41075704, -1.7784284 ]],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xlku2NIG9GHL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:31:08.248136Z",
     "iopub.status.busy": "2023-04-18T19:31:08.247555Z",
     "iopub.status.idle": "2023-04-18T19:31:08.259731Z",
     "shell.execute_reply": "2023-04-18T19:31:08.258014Z",
     "shell.execute_reply.started": "2023-04-18T19:31:08.248098Z"
    },
    "id": "xlku2NIG9GHL",
    "outputId": "4a065ab6-1254-4fbb-8597-47a6a9f8091b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-1f1aa18992cb>:1: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
      "\n",
      "<ipython-input-27-1f1aa18992cb>:2: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n"
     ]
    }
   ],
   "source": [
    "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QnGgkiy55NXe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:31:18.790659Z",
     "iopub.status.busy": "2023-04-18T19:31:18.790269Z",
     "iopub.status.idle": "2023-04-18T19:31:18.803007Z",
     "shell.execute_reply": "2023-04-18T19:31:18.801536Z",
     "shell.execute_reply.started": "2023-04-18T19:31:18.790619Z"
    },
    "id": "QnGgkiy55NXe",
    "outputId": "6d9e8c98-c776-4147-c433-d76201c12596"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-c079fcfdc6d7>:1: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_stance'] -= 1\n",
      "\n",
      "<ipython-input-28-c079fcfdc6d7>:2: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_argument'] -= 1\n"
     ]
    }
   ],
   "source": [
    "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
    "test_d[f'{CLASS_NAME}_argument'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SzVczctF9GHL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:31:24.908800Z",
     "iopub.status.busy": "2023-04-18T19:31:24.908174Z",
     "iopub.status.idle": "2023-04-18T19:31:24.925512Z",
     "shell.execute_reply": "2023-04-18T19:31:24.923776Z",
     "shell.execute_reply.started": "2023-04-18T19:31:24.908750Z"
    },
    "id": "SzVczctF9GHL",
    "outputId": "258ecc55-8589-4489-f7ff-80d251092b63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7a04ae44-216c-4c44-a5fe-7391971319c2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>quarantine_stance</th>\n",
       "      <th>quarantine_argument</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt; 26 марта его поместили на принудительный кар...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>И шевкунов вещает из телевизора про необходимо...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Это результат его  же лобировал до последнего ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>При этом нормально обеспечены (к слову о якобы...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>для опасного врага нужен официальный карантин ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a04ae44-216c-4c44-a5fe-7391971319c2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7a04ae44-216c-4c44-a5fe-7391971319c2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7a04ae44-216c-4c44-a5fe-7391971319c2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text  quarantine_stance  \\\n",
       "0  > 26 марта его поместили на принудительный кар...                  1   \n",
       "1  И шевкунов вещает из телевизора про необходимо...                  1   \n",
       "2  Это результат его  же лобировал до последнего ...                  1   \n",
       "3  При этом нормально обеспечены (к слову о якобы...                  1   \n",
       "4  для опасного врага нужен официальный карантин ...                  1   \n",
       "\n",
       "   quarantine_argument  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RyzvpKmz4nJu",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T19:32:12.595149Z",
     "iopub.status.busy": "2023-04-18T19:32:12.594698Z",
     "iopub.status.idle": "2023-04-18T19:32:12.619944Z",
     "shell.execute_reply": "2023-04-18T19:32:12.618922Z",
     "shell.execute_reply.started": "2023-04-18T19:32:12.595109Z"
    },
    "id": "RyzvpKmz4nJu"
   },
   "outputs": [],
   "source": [
    "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Giwutp1z5nLB",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T19:32:22.662965Z",
     "iopub.status.busy": "2023-04-18T19:32:22.662395Z",
     "iopub.status.idle": "2023-04-18T19:32:22.680932Z",
     "shell.execute_reply": "2023-04-18T19:32:22.679788Z",
     "shell.execute_reply.started": "2023-04-18T19:32:22.662929Z"
    },
    "id": "Giwutp1z5nLB"
   },
   "outputs": [],
   "source": [
    "CLASS_NAME = \"quarantine\"\n",
    "df1 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q9TvyZMBWrjy",
   "metadata": {
    "id": "Q9TvyZMBWrjy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "i_6Zh1PNUX4C",
   "metadata": {
    "id": "i_6Zh1PNUX4C"
   },
   "source": [
    "### 3.3.5 new acrhitecture MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jWweocUlVxdN",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-20T12:50:36.754739Z",
     "iopub.status.idle": "2023-04-20T12:50:36.755720Z",
     "shell.execute_reply": "2023-04-20T12:50:36.755439Z",
     "shell.execute_reply.started": "2023-04-20T12:50:36.755406Z"
    },
    "id": "jWweocUlVxdN"
   },
   "outputs": [],
   "source": [
    "# Build your model\n",
    "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "attention_mask = Input(shape=(256,), name='attention_mask', dtype='int32')\n",
    "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "# Load the Transformers BERT model as a layer in a Keras model\n",
    "bert_model = bert(inputs)[0]\n",
    "\n",
    "# Add multi-head attention layer\n",
    "attention_output = MultiHeadAttention(num_heads=4, key_dim=64)(bert_model, bert_model)\n",
    "\n",
    "# Flatten the output from multi-head attention layer\n",
    "flatten = Flatten()(attention_output)\n",
    "\n",
    "# Apply dropout layer\n",
    "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "pooled_output = dropout(flatten, training=False)\n",
    "\n",
    "# Then build your model output\n",
    "stance = Dense(units=len(data.stance_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
    "argument = Dense(units=len(data.argument_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
    "outputs = {'stance': stance, 'argument': argument}\n",
    "\n",
    "# And combine it all in a model object\n",
    "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
    "\n",
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_b9BwoFqghah",
   "metadata": {
    "id": "_b9BwoFqghah"
   },
   "source": [
    "#### 3.3.5.0 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1w1dRryIUavy",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-20T12:50:36.757290Z",
     "iopub.status.idle": "2023-04-20T12:50:36.758176Z",
     "shell.execute_reply": "2023-04-20T12:50:36.757894Z",
     "shell.execute_reply.started": "2023-04-20T12:50:36.757839Z"
    },
    "id": "1w1dRryIUavy"
   },
   "outputs": [],
   "source": [
    "! wandb login --relogin Mark4epih\n",
    "# Set an optimizer\n",
    "optimizer = AdamW(\n",
    "    learning_rate=5e-06,\n",
    "    epsilon=1e-08,\n",
    "    weight_decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
    "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)\n",
    "\n",
    "# Ready output data for the model\n",
    "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
    "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "x = tokenizer(\n",
    "    text=data['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "wandb.init(project=\"Text_categorization\", name = \"Bert_attention_quarantine_ts_0.4_AdamW_5e6_heads_4_20epochs\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
    "epochs = 3\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    y={'stance': y_stance, 'argument': y_argument},\n",
    "    validation_data=({'input_ids': test_x['input_ids'][:8], 'attention_mask': test_x['attention_mask'][:8]}, \n",
    "                     {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
    "    batch_size=8,\n",
    "    epochs=epochs, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4BgYHG6mfdwF",
   "metadata": {
    "id": "4BgYHG6mfdwF"
   },
   "source": [
    "### 3.3.5.1 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SSYugGwgUa1Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSYugGwgUa1Q",
    "outputId": "691ddbce-eecb-427f-ff2f-9e4a8cbe492b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 14s 552ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       1.00      0.98      0.99       468\n",
      "\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "           2       0.59      0.99      0.74       126\n",
      "\n",
      "           3       0.00      0.00      0.00        59\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.87       672\n",
      "\n",
      "   macro avg       0.40      0.49      0.43       672\n",
      "\n",
      "weighted avg       0.80      0.87      0.83       672\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       1.00      0.98      0.99       468\n",
      "\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "           2       0.79      0.99      0.88       170\n",
      "\n",
      "           3       0.00      0.00      0.00        19\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.93       672\n",
      "\n",
      "   macro avg       0.45      0.49      0.47       672\n",
      "\n",
      "weighted avg       0.90      0.93      0.91       672\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_results = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
    "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
    "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
    "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0), classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OvcFdsIO33A2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvcFdsIO33A2",
    "outputId": "f79d9e98-e9c7-49f8-cd68-cf1a2b2c51ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 38s 571ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       0.97      0.99      0.98      1359\n",
      "\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "           2       0.70      0.74      0.72       408\n",
      "\n",
      "           3       0.41      0.41      0.41       202\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.86      2016\n",
      "\n",
      "   macro avg       0.52      0.53      0.53      2016\n",
      "\n",
      "weighted avg       0.84      0.86      0.85      2016\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       0.98      0.98      0.98      1359\n",
      "\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "           2       0.82      0.95      0.88       543\n",
      "\n",
      "           3       0.59      0.14      0.23        71\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.93      2016\n",
      "\n",
      "   macro avg       0.60      0.52      0.52      2016\n",
      "\n",
      "weighted avg       0.90      0.93      0.91      2016\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_results = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
    "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
    "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
    "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0), classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ILpu24fyCV",
   "metadata": {
    "id": "a6ILpu24fyCV"
   },
   "source": [
    "#### 3.3.5.2 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ofKoV8ZiUa6s",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-20T12:50:36.759697Z",
     "iopub.status.idle": "2023-04-20T12:50:36.760565Z",
     "shell.execute_reply": "2023-04-20T12:50:36.760324Z",
     "shell.execute_reply.started": "2023-04-20T12:50:36.760295Z"
    },
    "id": "ofKoV8ZiUa6s"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/kaggle/working/val_empty.tsv\", sep='\\t')\n",
    "test.head()\n",
    "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "for_pred = tokenizer(\n",
    "    text=test_d['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "test_results = model.predict(x={'input_ids': for_pred['input_ids'], 'attention_mask': for_pred['attention_mask']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4hU-oMDsUa9D",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-20T12:50:36.762105Z",
     "iopub.status.idle": "2023-04-20T12:50:36.762970Z",
     "shell.execute_reply": "2023-04-20T12:50:36.762700Z",
     "shell.execute_reply.started": "2023-04-20T12:50:36.762670Z"
    },
    "id": "4hU-oMDsUa9D"
   },
   "outputs": [],
   "source": [
    "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
    "test_d[f'{CLASS_NAME}_argument'] -= 1\n",
    "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/kaggle/working/val_predict_MHA_AdamW_lr_5e6_ts_0.4_num_4_20epochs{CLASS_NAME}.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dL1YyFDHUa_g",
   "metadata": {
    "id": "dL1YyFDHUa_g"
   },
   "outputs": [],
   "source": [
    "CLASS_NAME = \"quarantine\"\n",
    "df1 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_AdamW_lr_5e6_{CLASS_NAME}.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dl1vax0e9GHL",
   "metadata": {
    "id": "Dl1vax0e9GHL"
   },
   "source": [
    "## 3.4 Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1TjrWgJs9GHL",
   "metadata": {
    "id": "1TjrWgJs9GHL"
   },
   "source": [
    "### 3.4.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M0pPhzWh9GHL",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T11:35:01.958799Z",
     "iopub.status.busy": "2023-04-20T11:35:01.957720Z",
     "iopub.status.idle": "2023-04-20T11:35:02.027407Z",
     "shell.execute_reply": "2023-04-20T11:35:02.026313Z",
     "shell.execute_reply.started": "2023-04-20T11:35:01.958756Z"
    },
    "id": "M0pPhzWh9GHL"
   },
   "outputs": [],
   "source": [
    "CLASS_NAME = \"masks\"\n",
    "# Import data from csv\n",
    "whole_data = pd.read_csv('/kaggle/working/train_all.tsv', sep='\\t')\n",
    "\n",
    "# Train_test_split\n",
    "test_size = 0.4\n",
    "data, data_test = train_test_split(whole_data, test_size=test_size, random_state = seed_value)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "## Train\n",
    "# Select required columns\n",
    "data = data[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "\n",
    "# Set your model output as categorical and save in new label col\n",
    "data['stance_label'] = pd.Categorical(data[f'{CLASS_NAME}_stance'])\n",
    "data['argument_label'] = pd.Categorical(data[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Transform your output to numeric\n",
    "data[f'{CLASS_NAME}_stance'] = data['stance_label'].cat.codes\n",
    "data[f'{CLASS_NAME}_argument'] = data['argument_label'].cat.codes\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "## Test\n",
    "# Select required columns\n",
    "data_test = data_test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "\n",
    "# Set your model output as categorical and save in new label col\n",
    "data_test['stance_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_stance'])\n",
    "data_test['argument_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Transform your output to numeric\n",
    "data_test[f'{CLASS_NAME}_stance'] = data_test['stance_label'].cat.codes\n",
    "data_test[f'{CLASS_NAME}_argument'] = data_test['argument_label'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jFHr7V939GHL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-19T20:44:14.553005Z",
     "iopub.status.busy": "2023-04-19T20:44:14.552239Z",
     "iopub.status.idle": "2023-04-19T20:44:16.630681Z",
     "shell.execute_reply": "2023-04-19T20:44:16.629780Z",
     "shell.execute_reply.started": "2023-04-19T20:44:14.552965Z"
    },
    "id": "jFHr7V939GHL",
    "outputId": "c72dca70-17c1-4e10-b3b0-9941a2018503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiLabel_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['input_ids[0][0]']              \n",
      "                                thPoolingAndCrossAt                                               \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " pooled_output (Dropout)        (None, 768)          0           ['bert[3][1]']                   \n",
      "                                                                                                  \n",
      " argument (Dense)               (None, 4)            3076        ['pooled_output[0][0]']          \n",
      "                                                                                                  \n",
      " stance (Dense)                 (None, 4)            3076        ['pooled_output[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 177,859,592\n",
      "Trainable params: 177,859,592\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#wandb.init(project=\"Text_categorization\", name = \"baseline_run\", tags = [\"Ruberta\", \"RB\"])\n",
    "# Ready output data for the model\n",
    "test_y_stance = to_categorical(data_test[f'{CLASS_NAME}_stance'])\n",
    "test_y_argument = to_categorical(data_test[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "test_x = tokenizer(\n",
    "    text=data_test['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "# Build your model input\n",
    "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "inputs = {'input_ids': input_ids}\n",
    "\n",
    "# Load the Transformers BERT model as a layer in a Keras model\n",
    "bert_model = bert(inputs)[1]\n",
    "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "pooled_output = dropout(bert_model, training=False)\n",
    "\n",
    "# Then build your model output\n",
    "stance = Dense(units=len(data.stance_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
    "argument = Dense(units=len(data.argument_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
    "outputs = {'stance': stance, 'argument': argument}\n",
    "\n",
    "# And combine it all in a model object\n",
    "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
    "\n",
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "osmGpcNL9GHL",
   "metadata": {
    "id": "osmGpcNL9GHL"
   },
   "source": [
    "### 3.4.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0L-HQOGs9GHM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 852
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:35:54.986398Z",
     "iopub.status.busy": "2023-04-18T19:35:54.985999Z",
     "iopub.status.idle": "2023-04-18T19:42:53.392049Z",
     "shell.execute_reply": "2023-04-18T19:42:53.387855Z",
     "shell.execute_reply.started": "2023-04-18T19:35:54.986364Z"
    },
    "id": "0L-HQOGs9GHM",
    "outputId": "fbfc7401-af1a-44b6-ed7b-9d26b49ee3e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.sdk.internal.internal_api:500 response executing GraphQL.\n",
      "\n",
      "ERROR:wandb.sdk.internal.internal_api:{\"error\":\"driver: bad connection\"}\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20230419_070439-ofpqwwmf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/ofpqwwmf' target=\"_blank\">baseline_run_masks</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/ofpqwwmf' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/ofpqwwmf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "672/672 [==============================] - ETA: 0s - loss: 1.7642 - argument_loss: 0.8188 - stance_loss: 0.9454 - argument_accuracy: 0.6588 - stance_accuracy: 0.6213"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_070439-ofpqwwmf/files/model-best)... Done. 12.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 483s 633ms/step - loss: 1.7642 - argument_loss: 0.8188 - stance_loss: 0.9454 - argument_accuracy: 0.6588 - stance_accuracy: 0.6213 - val_loss: 1.7240 - val_argument_loss: 0.7653 - val_stance_loss: 0.9586 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 2/20\n",
      "\n",
      "672/672 [==============================] - 346s 514ms/step - loss: 1.1378 - argument_loss: 0.5051 - stance_loss: 0.6327 - argument_accuracy: 0.8558 - stance_accuracy: 0.7713 - val_loss: 1.9198 - val_argument_loss: 0.8926 - val_stance_loss: 1.0272 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 3/20\n",
      "\n",
      "672/672 [==============================] - ETA: 0s - loss: 1.1441 - argument_loss: 0.5083 - stance_loss: 0.6358 - argument_accuracy: 0.8558 - stance_accuracy: 0.7713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_070439-ofpqwwmf/files/model-best)... Done. 12.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 409s 609ms/step - loss: 1.1441 - argument_loss: 0.5083 - stance_loss: 0.6358 - argument_accuracy: 0.8558 - stance_accuracy: 0.7713 - val_loss: 1.6039 - val_argument_loss: 0.7321 - val_stance_loss: 0.8718 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 4/20\n",
      "\n",
      "672/672 [==============================] - 342s 509ms/step - loss: 1.1474 - argument_loss: 0.5106 - stance_loss: 0.6369 - argument_accuracy: 0.8559 - stance_accuracy: 0.7714 - val_loss: 1.6246 - val_argument_loss: 0.7632 - val_stance_loss: 0.8614 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 5/20\n",
      "\n",
      "672/672 [==============================] - 339s 505ms/step - loss: 1.1438 - argument_loss: 0.5080 - stance_loss: 0.6357 - argument_accuracy: 0.8554 - stance_accuracy: 0.7711 - val_loss: 1.7899 - val_argument_loss: 0.8472 - val_stance_loss: 0.9426 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.6250\n",
      "\n",
      "Epoch 6/20\n",
      "\n",
      "252/672 [==========>...................] - ETA: 3:31 - loss: 1.1472 - argument_loss: 0.5117 - stance_loss: 0.6355 - argument_accuracy: 0.8552 - stance_accuracy: 0.7728"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4eb7758fc33b>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m# x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "! wandb login --relogin VasyaBog\n",
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-05,\n",
    "    epsilon=1e-08,\n",
    "    weight_decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
    "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)\n",
    "\n",
    "# Ready output data for the model\n",
    "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
    "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "x = tokenizer(\n",
    "    text=data['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "wandb.init(project=\"Text_categorization\", name = \"baseline_run_masks\", tags = [\"Ruberta\", \"RB\"])\n",
    "epochs = 20\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    x={'input_ids': x['input_ids']},\n",
    "    y={'stance': y_stance, 'argument': y_argument},\n",
    "    validation_data=({'input_ids': test_x['input_ids'][:8]}, {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
    "    batch_size=8,\n",
    "    epochs=epochs, callbacks=[WandbCallback()])\n",
    "for epoch in range(epochs): \n",
    "    wandb.log({'loss': history.history['loss'][epoch],\n",
    "               'argument_loss': history.history['argument_loss'][epoch],\n",
    "               'stance_loss': history.history['stance_loss'][epoch],\n",
    "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
    "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
    "               'val_loss': history.history['stance_accuracy'][epoch],\n",
    "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
    "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
    "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
    "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T5v7lBS49GHM",
   "metadata": {
    "id": "T5v7lBS49GHM"
   },
   "source": [
    "### 3.4.3 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22N4D3Tb9GHM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:42:59.713265Z",
     "iopub.status.busy": "2023-04-18T19:42:59.712870Z",
     "iopub.status.idle": "2023-04-18T19:43:42.467165Z",
     "shell.execute_reply": "2023-04-18T19:43:42.465888Z",
     "shell.execute_reply.started": "2023-04-18T19:42:59.713213Z"
    },
    "id": "22N4D3Tb9GHM",
    "outputId": "566ea559-a2ca-4ce0-c0c3-39c35b9c04bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 20s 531ms/step\n"
     ]
    }
   ],
   "source": [
    "val_results = model.predict(x={'input_ids': test_x['input_ids']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A2Gn5EDk9GHM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:43:42.470776Z",
     "iopub.status.busy": "2023-04-18T19:43:42.469211Z",
     "iopub.status.idle": "2023-04-18T19:43:42.498225Z",
     "shell.execute_reply": "2023-04-18T19:43:42.496748Z",
     "shell.execute_reply.started": "2023-04-18T19:43:42.470733Z"
    },
    "id": "A2Gn5EDk9GHM",
    "outputId": "1092a943-6da0-47d4-a208-4a1235ae64e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       0.99      0.99      0.99       534\n",
      "\n",
      "           1       0.00      0.00      0.00        89\n",
      "\n",
      "           2       0.60      1.00      0.75       287\n",
      "\n",
      "           3       0.00      0.00      0.00        98\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.81      1008\n",
      "\n",
      "   macro avg       0.40      0.50      0.43      1008\n",
      "\n",
      "weighted avg       0.70      0.81      0.74      1008\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
    "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
    "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_eQGxfiO9GHM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:43:42.499924Z",
     "iopub.status.busy": "2023-04-18T19:43:42.499561Z",
     "iopub.status.idle": "2023-04-18T19:43:42.523366Z",
     "shell.execute_reply": "2023-04-18T19:43:42.521942Z",
     "shell.execute_reply.started": "2023-04-18T19:43:42.499885Z"
    },
    "id": "_eQGxfiO9GHM",
    "outputId": "0ff5907b-a647-4123-b72d-32ad40a7b74f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       0.99      0.99      0.99       534\n",
      "\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "           2       0.78      0.99      0.87       373\n",
      "\n",
      "           3       0.00      0.00      0.00        45\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.89      1008\n",
      "\n",
      "   macro avg       0.44      0.49      0.47      1008\n",
      "\n",
      "weighted avg       0.81      0.89      0.85      1008\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9F8-w-Hv9GHM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:43:56.268140Z",
     "iopub.status.busy": "2023-04-18T19:43:56.267325Z",
     "iopub.status.idle": "2023-04-18T19:43:56.322440Z",
     "shell.execute_reply": "2023-04-18T19:43:56.321400Z",
     "shell.execute_reply.started": "2023-04-18T19:43:56.268091Z"
    },
    "id": "9F8-w-Hv9GHM",
    "outputId": "8243955e-4723-4c55-cabc-413798b68429"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-02857577-469a-4372-bedb-c3e4a85abd6a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>masks_stance</th>\n",
       "      <th>masks_argument</th>\n",
       "      <th>quarantine_stance</th>\n",
       "      <th>quarantine_argument</th>\n",
       "      <th>vaccines_stance</th>\n",
       "      <th>vaccines_argument</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17041</td>\n",
       "      <td>&gt; 26 марта его поместили на принудительный кар...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17057</td>\n",
       "      <td>И шевкунов вещает из телевизора про необходимо...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17058</td>\n",
       "      <td>Это результат его  же лобировал до последнего ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17071</td>\n",
       "      <td>При этом нормально обеспечены (к слову о якобы...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17079</td>\n",
       "      <td>для опасного врага нужен официальный карантин ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02857577-469a-4372-bedb-c3e4a85abd6a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-02857577-469a-4372-bedb-c3e4a85abd6a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-02857577-469a-4372-bedb-c3e4a85abd6a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   text_id                                               text  masks_stance  \\\n",
       "0    17041  > 26 марта его поместили на принудительный кар...           NaN   \n",
       "1    17057  И шевкунов вещает из телевизора про необходимо...           NaN   \n",
       "2    17058  Это результат его  же лобировал до последнего ...           NaN   \n",
       "3    17071  При этом нормально обеспечены (к слову о якобы...           NaN   \n",
       "4    17079  для опасного врага нужен официальный карантин ...           NaN   \n",
       "\n",
       "   masks_argument  quarantine_stance  quarantine_argument  vaccines_stance  \\\n",
       "0             NaN                NaN                  NaN              NaN   \n",
       "1             NaN                NaN                  NaN              NaN   \n",
       "2             NaN                NaN                  NaN              NaN   \n",
       "3             NaN                NaN                  NaN              NaN   \n",
       "4             NaN                NaN                  NaN              NaN   \n",
       "\n",
       "   vaccines_argument  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"/content/drive/MyDrive/HW_2/val_empty.tsv\", sep='\\t')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nx6W9cz-9GHM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:44:00.180907Z",
     "iopub.status.busy": "2023-04-18T19:44:00.180531Z",
     "iopub.status.idle": "2023-04-18T19:44:31.587662Z",
     "shell.execute_reply": "2023-04-18T19:44:31.584483Z",
     "shell.execute_reply.started": "2023-04-18T19:44:00.180873Z"
    },
    "id": "Nx6W9cz-9GHM",
    "outputId": "746a63d8-056e-4256-b18e-05195a2aac4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 25s 549ms/step\n"
     ]
    }
   ],
   "source": [
    "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "for_pred = tokenizer(\n",
    "    text=test_d['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "test_results = model.predict(x={'input_ids': for_pred['input_ids']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bb-f3vmN9GHM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:44:31.590565Z",
     "iopub.status.busy": "2023-04-18T19:44:31.589905Z",
     "iopub.status.idle": "2023-04-18T19:44:31.601988Z",
     "shell.execute_reply": "2023-04-18T19:44:31.600881Z",
     "shell.execute_reply.started": "2023-04-18T19:44:31.590524Z"
    },
    "id": "Bb-f3vmN9GHM",
    "outputId": "dbbc52cc-7acf-4346-cd3b-3c563fcd7f9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-d467d76760e1>:1: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
      "\n",
      "<ipython-input-13-d467d76760e1>:2: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
      "\n",
      "<ipython-input-13-d467d76760e1>:3: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_stance'] -= 1\n",
      "\n",
      "<ipython-input-13-d467d76760e1>:4: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_argument'] -= 1\n"
     ]
    }
   ],
   "source": [
    "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
    "test_d[f'{CLASS_NAME}_argument'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DjrQC-6G9GHM",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T19:45:35.172502Z",
     "iopub.status.busy": "2023-04-18T19:45:35.171920Z",
     "iopub.status.idle": "2023-04-18T19:45:35.211525Z",
     "shell.execute_reply": "2023-04-18T19:45:35.208768Z",
     "shell.execute_reply.started": "2023-04-18T19:45:35.172456Z"
    },
    "id": "DjrQC-6G9GHM"
   },
   "outputs": [],
   "source": [
    "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t', index=None)\n",
    "df2 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r3FkHFVFAqh6",
   "metadata": {
    "id": "r3FkHFVFAqh6"
   },
   "source": [
    "### 3.4.4 New Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vyau-xOdAyv6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-20T11:36:54.545299Z",
     "iopub.status.busy": "2023-04-20T11:36:54.544770Z",
     "iopub.status.idle": "2023-04-20T11:36:57.293020Z",
     "shell.execute_reply": "2023-04-20T11:36:57.291930Z",
     "shell.execute_reply.started": "2023-04-20T11:36:54.545253Z"
    },
    "id": "vyau-xOdAyv6",
    "outputId": "55fbd5a5-0063-4ee1-93bc-93ee37d479ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiLabel_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['attention_mask[0][0]',         \n",
      "                                thPoolingAndCrossAt               'input_ids[0][0]']              \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 256, 768)    787968      ['bert[3][0]',                   \n",
      " eadAttention)                                                    'bert[3][0]']                   \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 196608)       0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " pooled_output (Dropout)        (None, 196608)       0           ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " argument (Dense)               (None, 4)            786436      ['pooled_output[0][0]']          \n",
      "                                                                                                  \n",
      " stance (Dense)                 (None, 4)            786436      ['pooled_output[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,214,280\n",
      "Trainable params: 180,214,280\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build your model\n",
    "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "attention_mask = Input(shape=(256,), name='attention_mask', dtype='int32')\n",
    "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "# Load the Transformers BERT model as a layer in a Keras model\n",
    "bert_model = bert(inputs)[0]\n",
    "\n",
    "# Add multi-head attention layer\n",
    "attention_output = MultiHeadAttention(num_heads=4, key_dim=64)(bert_model, bert_model)\n",
    "\n",
    "# Flatten the output from multi-head attention layer\n",
    "flatten = Flatten()(attention_output)\n",
    "\n",
    "# Apply dropout layer\n",
    "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "pooled_output = dropout(flatten, training=False)\n",
    "\n",
    "# Then build your model output\n",
    "stance = Dense(units=len(data.stance_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
    "argument = Dense(units=len(data.argument_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
    "outputs = {'stance': stance, 'argument': argument}\n",
    "\n",
    "# And combine it all in a model object\n",
    "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
    "\n",
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CbTC672ZA76b",
   "metadata": {
    "id": "CbTC672ZA76b"
   },
   "source": [
    "### 3.4.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s7vDnlPEAyy5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "execution": {
     "iopub.execute_input": "2023-04-20T11:37:17.762002Z",
     "iopub.status.busy": "2023-04-20T11:37:17.760987Z",
     "iopub.status.idle": "2023-04-20T12:50:28.988375Z",
     "shell.execute_reply": "2023-04-20T12:50:28.986028Z",
     "shell.execute_reply.started": "2023-04-20T11:37:17.761936Z"
    },
    "id": "s7vDnlPEAyy5",
    "outputId": "2a2646c3-432c-4ad5-dab7-15bcb867c290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:db3lt4ro) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>argument_accuracy</td><td>▁██</td></tr><tr><td>argument_loss</td><td>█▁▁</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▁▁</td></tr><tr><td>stance_accuracy</td><td>▁▇█</td></tr><tr><td>stance_loss</td><td>█▁▁</td></tr><tr><td>val_argument_accuracy</td><td>▁▁▁</td></tr><tr><td>val_argument_loss</td><td>█▂▁</td></tr><tr><td>val_loss</td><td>█▁▁</td></tr><tr><td>val_stance_accuracy</td><td>▁██</td></tr><tr><td>val_stance_loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>argument_accuracy</td><td>0.99975</td></tr><tr><td>argument_loss</td><td>0.00081</td></tr><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.02229</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>0.00193</td></tr><tr><td>stance_accuracy</td><td>0.99975</td></tr><tr><td>stance_loss</td><td>0.00112</td></tr><tr><td>val_argument_accuracy</td><td>1.0</td></tr><tr><td>val_argument_loss</td><td>0.0</td></tr><tr><td>val_loss</td><td>0.02229</td></tr><tr><td>val_stance_accuracy</td><td>1.0</td></tr><tr><td>val_stance_loss</td><td>0.02228</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Bert_attention_quarantine_ts_0.4_AdamW_5e6_heads_5_3epochs</strong> at: <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/db3lt4ro' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/db3lt4ro</a><br/>Synced 6 W&B file(s), 1 media file(s), 15 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230420_111201-db3lt4ro/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:db3lt4ro). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230420_113722-b17zbcum</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/b17zbcum' target=\"_blank\">Bert_attention_masks_20epochs_AdamW_lr_5e6_masks_num_4</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/b17zbcum' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/b17zbcum</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "672/672 [==============================] - ETA: 0s - loss: 0.9278 - argument_loss: 0.3746 - stance_loss: 0.5531 - argument_accuracy: 0.8783 - stance_accuracy: 0.7798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/wandb/run-20230420_113722-b17zbcum/files/model-best)... Done. 13.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 332s 413ms/step - loss: 0.9278 - argument_loss: 0.3746 - stance_loss: 0.5531 - argument_accuracy: 0.8783 - stance_accuracy: 0.7798 - val_loss: 6.4571 - val_argument_loss: 3.3633 - val_stance_loss: 3.0938 - val_argument_accuracy: 0.3750 - val_stance_accuracy: 0.6250\n",
      "Epoch 2/20\n",
      "672/672 [==============================] - 213s 317ms/step - loss: 0.7414 - argument_loss: 0.2717 - stance_loss: 0.4697 - argument_accuracy: 0.9038 - stance_accuracy: 0.7945 - val_loss: 6.5955 - val_argument_loss: 3.4809 - val_stance_loss: 3.1146 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.3750\n",
      "Epoch 3/20\n",
      "672/672 [==============================] - 209s 310ms/step - loss: 0.6589 - argument_loss: 0.2344 - stance_loss: 0.4245 - argument_accuracy: 0.9176 - stance_accuracy: 0.8282 - val_loss: 8.5854 - val_argument_loss: 4.3471 - val_stance_loss: 4.2382 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 4/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.5030 - argument_loss: 0.1638 - stance_loss: 0.3392 - argument_accuracy: 0.9444 - stance_accuracy: 0.8636 - val_loss: 11.6275 - val_argument_loss: 6.1599 - val_stance_loss: 5.4675 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 5/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.3477 - argument_loss: 0.1146 - stance_loss: 0.2330 - argument_accuracy: 0.9613 - stance_accuracy: 0.9122 - val_loss: 12.9125 - val_argument_loss: 6.5514 - val_stance_loss: 6.3611 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 6/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.2581 - argument_loss: 0.0850 - stance_loss: 0.1732 - argument_accuracy: 0.9745 - stance_accuracy: 0.9390 - val_loss: 13.8705 - val_argument_loss: 7.1208 - val_stance_loss: 6.7497 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 7/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.1892 - argument_loss: 0.0664 - stance_loss: 0.1227 - argument_accuracy: 0.9782 - stance_accuracy: 0.9568 - val_loss: 15.9495 - val_argument_loss: 7.7363 - val_stance_loss: 8.2132 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 8/20\n",
      "672/672 [==============================] - 208s 309ms/step - loss: 0.1418 - argument_loss: 0.0531 - stance_loss: 0.0887 - argument_accuracy: 0.9849 - stance_accuracy: 0.9760 - val_loss: 16.9324 - val_argument_loss: 8.2166 - val_stance_loss: 8.7158 - val_argument_accuracy: 0.1250 - val_stance_accuracy: 0.2500\n",
      "Epoch 9/20\n",
      "672/672 [==============================] - 208s 310ms/step - loss: 0.1042 - argument_loss: 0.0406 - stance_loss: 0.0636 - argument_accuracy: 0.9877 - stance_accuracy: 0.9812 - val_loss: 17.3849 - val_argument_loss: 7.8694 - val_stance_loss: 9.5155 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 10/20\n",
      "672/672 [==============================] - 208s 310ms/step - loss: 0.0816 - argument_loss: 0.0280 - stance_loss: 0.0536 - argument_accuracy: 0.9916 - stance_accuracy: 0.9838 - val_loss: 19.8979 - val_argument_loss: 8.8842 - val_stance_loss: 11.0137 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 11/20\n",
      "672/672 [==============================] - 208s 310ms/step - loss: 0.0654 - argument_loss: 0.0271 - stance_loss: 0.0383 - argument_accuracy: 0.9913 - stance_accuracy: 0.9875 - val_loss: 19.8003 - val_argument_loss: 9.4369 - val_stance_loss: 10.3634 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 12/20\n",
      "672/672 [==============================] - 208s 309ms/step - loss: 0.0448 - argument_loss: 0.0177 - stance_loss: 0.0271 - argument_accuracy: 0.9950 - stance_accuracy: 0.9922 - val_loss: 21.2813 - val_argument_loss: 10.0167 - val_stance_loss: 11.2647 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 13/20\n",
      "672/672 [==============================] - 207s 307ms/step - loss: 0.0547 - argument_loss: 0.0195 - stance_loss: 0.0352 - argument_accuracy: 0.9942 - stance_accuracy: 0.9907 - val_loss: 23.4692 - val_argument_loss: 10.6034 - val_stance_loss: 12.8658 - val_argument_accuracy: 0.1250 - val_stance_accuracy: 0.1250\n",
      "Epoch 14/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.0349 - argument_loss: 0.0140 - stance_loss: 0.0209 - argument_accuracy: 0.9953 - stance_accuracy: 0.9946 - val_loss: 22.7142 - val_argument_loss: 10.4101 - val_stance_loss: 12.3041 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 15/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.0365 - argument_loss: 0.0132 - stance_loss: 0.0232 - argument_accuracy: 0.9966 - stance_accuracy: 0.9944 - val_loss: 23.5873 - val_argument_loss: 11.1307 - val_stance_loss: 12.4565 - val_argument_accuracy: 0.1250 - val_stance_accuracy: 0.2500\n",
      "Epoch 16/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.0425 - argument_loss: 0.0202 - stance_loss: 0.0224 - argument_accuracy: 0.9946 - stance_accuracy: 0.9950 - val_loss: 23.4703 - val_argument_loss: 10.6592 - val_stance_loss: 12.8111 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 17/20\n",
      "672/672 [==============================] - 207s 307ms/step - loss: 0.0386 - argument_loss: 0.0140 - stance_loss: 0.0246 - argument_accuracy: 0.9966 - stance_accuracy: 0.9942 - val_loss: 24.0104 - val_argument_loss: 11.2510 - val_stance_loss: 12.7595 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 18/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.0293 - argument_loss: 0.0102 - stance_loss: 0.0191 - argument_accuracy: 0.9976 - stance_accuracy: 0.9937 - val_loss: 24.4945 - val_argument_loss: 11.6171 - val_stance_loss: 12.8774 - val_argument_accuracy: 0.1250 - val_stance_accuracy: 0.1250\n",
      "Epoch 19/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.0310 - argument_loss: 0.0176 - stance_loss: 0.0133 - argument_accuracy: 0.9963 - stance_accuracy: 0.9974 - val_loss: 25.8764 - val_argument_loss: 11.9716 - val_stance_loss: 13.9048 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n",
      "Epoch 20/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.0211 - argument_loss: 0.0086 - stance_loss: 0.0125 - argument_accuracy: 0.9980 - stance_accuracy: 0.9968 - val_loss: 24.5025 - val_argument_loss: 12.0273 - val_stance_loss: 12.4752 - val_argument_accuracy: 0.2500 - val_stance_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "! wandb login --relogin NikitaLoh\n",
    "# Set an optimizer\n",
    "optimizer = AdamW(\n",
    "    learning_rate=5e-06,\n",
    "    epsilon=1e-08,\n",
    "    weight_decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
    "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)\n",
    "\n",
    "# Ready output data for the model\n",
    "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
    "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "x = tokenizer(\n",
    "    text=data['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "wandb.init(project=\"Text_categorization\", name = \"Bert_attention_masks_20epochs_AdamW_lr_5e6_masks_num_4\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
    "epochs = 20\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    y={'stance': y_stance, 'argument': y_argument},\n",
    "    validation_data=({'input_ids': test_x['input_ids'][:8], 'attention_mask': test_x['attention_mask'][:8]}, \n",
    "                     {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
    "    batch_size=8,\n",
    "    epochs=epochs, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FBwH1L09A_FM",
   "metadata": {
    "id": "FBwH1L09A_FM"
   },
   "source": [
    "#### 3.4.5.1 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cOI_mXfHAy4J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cOI_mXfHAy4J",
    "outputId": "c6d79fc6-56f5-4ee4-b1be-4c0b7b3fa154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 25s 653ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       1.00      1.00      1.00       534\n",
      "\n",
      "           1       0.41      0.21      0.28        89\n",
      "\n",
      "           2       0.75      0.75      0.75       287\n",
      "\n",
      "           3       0.28      0.41      0.33        98\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.80      1008\n",
      "\n",
      "   macro avg       0.61      0.59      0.59      1008\n",
      "\n",
      "weighted avg       0.81      0.80      0.80      1008\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       1.00      1.00      1.00       534\n",
      "\n",
      "           1       0.33      0.54      0.41        56\n",
      "\n",
      "           2       0.90      0.92      0.91       373\n",
      "\n",
      "           3       0.00      0.00      0.00        45\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.90      1008\n",
      "\n",
      "   macro avg       0.55      0.61      0.58      1008\n",
      "\n",
      "weighted avg       0.88      0.90      0.89      1008\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_results = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
    "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
    "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
    "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0), classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rTMsoe3aBBD4",
   "metadata": {
    "id": "rTMsoe3aBBD4"
   },
   "source": [
    "#### 3.4.5.2 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8KdNpUAy9A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-20T12:50:38.886199Z",
     "iopub.status.busy": "2023-04-20T12:50:38.885091Z",
     "iopub.status.idle": "2023-04-20T12:50:53.692752Z",
     "shell.execute_reply": "2023-04-20T12:50:53.684672Z",
     "shell.execute_reply.started": "2023-04-20T12:50:38.886152Z"
    },
    "id": "7d8KdNpUAy9A",
    "outputId": "267886c5-1ed7-4b74-f720-9736a1257140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 15s 322ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAME = \"masks\"\n",
    "test = pd.read_csv(\"/kaggle/working/val_empty.tsv\", sep='\\t')\n",
    "test.head()\n",
    "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "for_pred = tokenizer(\n",
    "    text=test_d['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "test_results = model.predict(x={'input_ids': for_pred['input_ids'], 'attention_mask': for_pred['attention_mask']})\n",
    "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
    "test_d[f'{CLASS_NAME}_argument'] -= 1\n",
    "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/kaggle/working/val_predict_MHA_AdamW_lr_5e6_ts_0.4_num_4_20epochs_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YVR6SY-yAy_7",
   "metadata": {
    "id": "YVR6SY-yAy_7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "iciqRheS9GHN",
   "metadata": {
    "id": "iciqRheS9GHN"
   },
   "source": [
    "## 3.5 vaccines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peIWpSF59GHN",
   "metadata": {
    "id": "peIWpSF59GHN"
   },
   "source": [
    "### 3.5.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LZGYLGXF9GHN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-19T19:07:50.471846Z",
     "iopub.status.busy": "2023-04-19T19:07:50.470588Z",
     "iopub.status.idle": "2023-04-19T19:07:56.590530Z",
     "shell.execute_reply": "2023-04-19T19:07:56.589288Z",
     "shell.execute_reply.started": "2023-04-19T19:07:50.471792Z"
    },
    "id": "LZGYLGXF9GHN",
    "outputId": "4395a95a-6ced-4243-c5ed-df0d3ea69b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiLabel_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['input_ids[0][0]']              \n",
      "                                thPoolingAndCrossAt                                               \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " pooled_output (Dropout)        (None, 768)          0           ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " argument (Dense)               (None, 4)            3076        ['pooled_output[0][0]']          \n",
      "                                                                                                  \n",
      " stance (Dense)                 (None, 4)            3076        ['pooled_output[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 177,859,592\n",
      "Trainable params: 177,859,592\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAME = \"vaccines\"\n",
    "# Import data from csv\n",
    "whole_data = pd.read_csv('/kaggle/working/train_all.tsv', sep='\\t')\n",
    "\n",
    "# Train_test_split\n",
    "test_size = 0.2\n",
    "data, data_test = train_test_split(whole_data, test_size=test_size)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "## Train\n",
    "# Select required columns\n",
    "data = data[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "\n",
    "# Set your model output as categorical and save in new label col\n",
    "data['stance_label'] = pd.Categorical(data[f'{CLASS_NAME}_stance'])\n",
    "data['argument_label'] = pd.Categorical(data[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Transform your output to numeric\n",
    "data[f'{CLASS_NAME}_stance'] = data['stance_label'].cat.codes\n",
    "data[f'{CLASS_NAME}_argument'] = data['argument_label'].cat.codes\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "## Test\n",
    "# Select required columns\n",
    "data_test = data_test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "\n",
    "# Set your model output as categorical and save in new label col\n",
    "data_test['stance_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_stance'])\n",
    "data_test['argument_label'] = pd.Categorical(data_test[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Transform your output to numeric\n",
    "data_test[f'{CLASS_NAME}_stance'] = data_test['stance_label'].cat.codes\n",
    "data_test[f'{CLASS_NAME}_argument'] = data_test['argument_label'].cat.codes\n",
    "#wandb.init(project=\"Text_categorization\", name = \"baseline_run\", tags = [\"Ruberta\", \"RB\"])\n",
    "# Ready output data for the model\n",
    "test_y_stance = to_categorical(data_test[f'{CLASS_NAME}_stance'])\n",
    "test_y_argument = to_categorical(data_test[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "test_x = tokenizer(\n",
    "    text=data_test['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "# Build your model input\n",
    "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "inputs = {'input_ids': input_ids}\n",
    "\n",
    "# Load the Transformers BERT model as a layer in a Keras model\n",
    "bert_model = bert(inputs)[1]\n",
    "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "pooled_output = dropout(bert_model, training=False)\n",
    "\n",
    "# Then build your model output\n",
    "stance = Dense(units=len(data.stance_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
    "argument = Dense(units=len(data.argument_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
    "outputs = {'stance': stance, 'argument': argument}\n",
    "\n",
    "# And combine it all in a model object\n",
    "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
    "\n",
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hs9veuJ39GHN",
   "metadata": {
    "id": "hs9veuJ39GHN"
   },
   "source": [
    "### 3.5.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ge2SV7TG9GHN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:47:30.568837Z",
     "iopub.status.busy": "2023-04-18T19:47:30.567995Z",
     "iopub.status.idle": "2023-04-18T19:54:27.231648Z",
     "shell.execute_reply": "2023-04-18T19:54:27.228470Z",
     "shell.execute_reply.started": "2023-04-18T19:47:30.568797Z"
    },
    "id": "Ge2SV7TG9GHN",
    "outputId": "13ec7a9b-50c7-41ac-f9e4-62411f68093d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20230419_080129-aqk0c2j9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/aqk0c2j9' target=\"_blank\">baseline_run_vaccines</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/aqk0c2j9' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/aqk0c2j9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "672/672 [==============================] - ETA: 0s - loss: 0.8639 - argument_loss: 0.3964 - stance_loss: 0.4674 - argument_accuracy: 0.8729 - stance_accuracy: 0.8394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_080129-aqk0c2j9/files/model-best)... Done. 12.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 497s 639ms/step - loss: 0.8639 - argument_loss: 0.3964 - stance_loss: 0.4674 - argument_accuracy: 0.8729 - stance_accuracy: 0.8394 - val_loss: 0.0885 - val_argument_loss: 0.0322 - val_stance_loss: 0.0563 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
      "\n",
      "Epoch 2/20\n",
      "\n",
      "672/672 [==============================] - ETA: 0s - loss: 0.5012 - argument_loss: 0.2189 - stance_loss: 0.2823 - argument_accuracy: 0.9295 - stance_accuracy: 0.8718"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_080129-aqk0c2j9/files/model-best)... Done. 12.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 411s 612ms/step - loss: 0.5012 - argument_loss: 0.2189 - stance_loss: 0.2823 - argument_accuracy: 0.9295 - stance_accuracy: 0.8718 - val_loss: 0.0812 - val_argument_loss: 0.0418 - val_stance_loss: 0.0394 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
      "\n",
      "Epoch 3/20\n",
      "\n",
      "672/672 [==============================] - 342s 509ms/step - loss: 0.5515 - argument_loss: 0.2473 - stance_loss: 0.3043 - argument_accuracy: 0.9213 - stance_accuracy: 0.8708 - val_loss: 0.1275 - val_argument_loss: 0.0490 - val_stance_loss: 0.0785 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 1.0000\n",
      "\n",
      "Epoch 4/20\n",
      "\n",
      "672/672 [==============================] - 339s 505ms/step - loss: 1.5166 - argument_loss: 0.7262 - stance_loss: 0.7904 - argument_accuracy: 0.7696 - stance_accuracy: 0.7664 - val_loss: 0.9052 - val_argument_loss: 0.4384 - val_stance_loss: 0.4669 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
      "\n",
      "Epoch 5/20\n",
      "\n",
      "672/672 [==============================] - 338s 503ms/step - loss: 1.5768 - argument_loss: 0.7539 - stance_loss: 0.8228 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 0.9852 - val_argument_loss: 0.4636 - val_stance_loss: 0.5216 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
      "\n",
      "Epoch 6/20\n",
      "\n",
      "672/672 [==============================] - 339s 504ms/step - loss: 1.5618 - argument_loss: 0.7475 - stance_loss: 0.8143 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 1.0046 - val_argument_loss: 0.4800 - val_stance_loss: 0.5246 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
      "\n",
      "Epoch 7/20\n",
      "\n",
      "672/672 [==============================] - 338s 502ms/step - loss: 1.5596 - argument_loss: 0.7466 - stance_loss: 0.8130 - argument_accuracy: 0.7579 - stance_accuracy: 0.7577 - val_loss: 0.9487 - val_argument_loss: 0.4411 - val_stance_loss: 0.5076 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
      "\n",
      "Epoch 8/20\n",
      "\n",
      "672/672 [==============================] - 337s 502ms/step - loss: 1.5615 - argument_loss: 0.7469 - stance_loss: 0.8146 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 1.0505 - val_argument_loss: 0.4984 - val_stance_loss: 0.5521 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
      "\n",
      "Epoch 9/20\n",
      "\n",
      "672/672 [==============================] - 338s 503ms/step - loss: 1.5616 - argument_loss: 0.7474 - stance_loss: 0.8141 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 0.9981 - val_argument_loss: 0.4720 - val_stance_loss: 0.5260 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
      "\n",
      "Epoch 10/20\n",
      "\n",
      "672/672 [==============================] - 337s 502ms/step - loss: 1.5599 - argument_loss: 0.7465 - stance_loss: 0.8134 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 0.9459 - val_argument_loss: 0.4445 - val_stance_loss: 0.5014 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
      "\n",
      "Epoch 11/20\n",
      "\n",
      "672/672 [==============================] - 337s 501ms/step - loss: 1.5613 - argument_loss: 0.7478 - stance_loss: 0.8135 - argument_accuracy: 0.7577 - stance_accuracy: 0.7579 - val_loss: 1.1941 - val_argument_loss: 0.5592 - val_stance_loss: 0.6348 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
      "\n",
      "Epoch 12/20\n",
      "\n",
      "672/672 [==============================] - 337s 502ms/step - loss: 1.5588 - argument_loss: 0.7458 - stance_loss: 0.8129 - argument_accuracy: 0.7577 - stance_accuracy: 0.7577 - val_loss: 0.9752 - val_argument_loss: 0.4618 - val_stance_loss: 0.5134 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.8750\n",
      "\n",
      "Epoch 13/20\n",
      "\n",
      " 51/672 [=>............................] - ETA: 5:11 - loss: 1.6768 - argument_loss: 0.8013 - stance_loss: 0.8755 - argument_accuracy: 0.7255 - stance_accuracy: 0.7255"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1a279b085cfe>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m# x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "! wandb login --relogin Markkrasav4ik\n",
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-05,\n",
    "    epsilon=1e-08,\n",
    "    weight_decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
    "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)\n",
    "\n",
    "# Ready output data for the model\n",
    "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
    "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "x = tokenizer(\n",
    "    text=data['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "wandb.init(project=\"Text_categorization\", name = \"baseline_run_vaccines\", tags = [\"Ruberta\", \"RB\"])\n",
    "epochs = 20\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    x={'input_ids': x['input_ids']},\n",
    "    y={'stance': y_stance, 'argument': y_argument},\n",
    "    validation_data=({'input_ids': test_x['input_ids'][:8]}, {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
    "    batch_size=8,\n",
    "    epochs=epochs, callbacks=[WandbCallback()])\n",
    "for epoch in range(epochs): \n",
    "    wandb.log({'loss': history.history['loss'][epoch],\n",
    "               'argument_loss': history.history['argument_loss'][epoch],\n",
    "               'stance_loss': history.history['stance_loss'][epoch],\n",
    "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
    "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
    "               'val_loss': history.history['stance_accuracy'][epoch],\n",
    "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
    "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
    "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
    "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F9swUYK5ypUI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9swUYK5ypUI",
    "outputId": "f4cce1be-78d5-45f9-f785-91c1d5a399b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmolenkovaea00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20230419_092630-z1wiapq3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/z1wiapq3' target=\"_blank\">baseline_run_vaccines_2_epochs</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/z1wiapq3' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/z1wiapq3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "672/672 [==============================] - ETA: 0s - loss: 0.5840 - argument_loss: 0.2581 - stance_loss: 0.3259 - argument_accuracy: 0.9200 - stance_accuracy: 0.8684"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230419_092630-z1wiapq3/files/model-best)... Done. 12.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 489s 638ms/step - loss: 0.5840 - argument_loss: 0.2581 - stance_loss: 0.3259 - argument_accuracy: 0.9200 - stance_accuracy: 0.8684 - val_loss: 0.2219 - val_argument_loss: 0.0349 - val_stance_loss: 0.1870 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n",
      "\n",
      "Epoch 2/2\n",
      "\n",
      "672/672 [==============================] - 341s 508ms/step - loss: 0.5058 - argument_loss: 0.2165 - stance_loss: 0.2893 - argument_accuracy: 0.9334 - stance_accuracy: 0.8773 - val_loss: 0.2485 - val_argument_loss: 0.0328 - val_stance_loss: 0.2157 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "! wandb login --relogin VasyaBog\n",
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-05,\n",
    "    epsilon=1e-08,\n",
    "    weight_decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
    "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)\n",
    "\n",
    "# Ready output data for the model\n",
    "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
    "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "x = tokenizer(\n",
    "    text=data['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "wandb.init(project=\"Text_categorization\", name = \"baseline_run_vaccines_2_epochs\", tags = [\"Ruberta\", \"RB\"])\n",
    "epochs = 2\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    x={'input_ids': x['input_ids']},\n",
    "    y={'stance': y_stance, 'argument': y_argument},\n",
    "    validation_data=({'input_ids': test_x['input_ids'][:8]}, {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
    "    batch_size=8,\n",
    "    epochs=epochs, callbacks=[WandbCallback()])\n",
    "for epoch in range(epochs): \n",
    "    wandb.log({'loss': history.history['loss'][epoch],\n",
    "               'argument_loss': history.history['argument_loss'][epoch],\n",
    "               'stance_loss': history.history['stance_loss'][epoch],\n",
    "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
    "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
    "               'val_loss': history.history['stance_accuracy'][epoch],\n",
    "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
    "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
    "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
    "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wC1NzXEj9GHN",
   "metadata": {
    "id": "wC1NzXEj9GHN"
   },
   "source": [
    "### 3.5.3 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QlTecKRB9GHN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:54:27.236803Z",
     "iopub.status.busy": "2023-04-18T19:54:27.233964Z",
     "iopub.status.idle": "2023-04-18T19:55:09.915103Z",
     "shell.execute_reply": "2023-04-18T19:55:09.913684Z",
     "shell.execute_reply.started": "2023-04-18T19:54:27.236757Z"
    },
    "id": "QlTecKRB9GHN",
    "outputId": "0ef4f680-de30-4c7b-9982-26296fd7a56f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 24s 533ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       1.00      1.00      1.00      1009\n",
      "\n",
      "           1       0.00      0.00      0.00        89\n",
      "\n",
      "           2       0.51      0.98      0.67       173\n",
      "\n",
      "           3       0.00      0.00      0.00        73\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.88      1344\n",
      "\n",
      "   macro avg       0.38      0.50      0.42      1344\n",
      "\n",
      "weighted avg       0.81      0.88      0.84      1344\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_results = model.predict(x={'input_ids': test_x['input_ids']})\n",
    "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
    "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
    "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GUq0CRkN9GHN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:55:09.923746Z",
     "iopub.status.busy": "2023-04-18T19:55:09.919605Z",
     "iopub.status.idle": "2023-04-18T19:55:09.946909Z",
     "shell.execute_reply": "2023-04-18T19:55:09.943824Z",
     "shell.execute_reply.started": "2023-04-18T19:55:09.923695Z"
    },
    "id": "GUq0CRkN9GHN",
    "outputId": "2e4279e2-f2fd-4e2d-f765-c9fc78f0ce12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       1.00      1.00      1.00      1009\n",
      "\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "           2       0.72      0.98      0.83       244\n",
      "\n",
      "           3       0.00      0.00      0.00        32\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.93      1344\n",
      "\n",
      "   macro avg       0.43      0.50      0.46      1344\n",
      "\n",
      "weighted avg       0.88      0.93      0.90      1344\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F-ZaM_eZ9GHN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:55:09.956118Z",
     "iopub.status.busy": "2023-04-18T19:55:09.953170Z",
     "iopub.status.idle": "2023-04-18T19:55:53.894877Z",
     "shell.execute_reply": "2023-04-18T19:55:53.893454Z",
     "shell.execute_reply.started": "2023-04-18T19:55:09.956071Z"
    },
    "id": "F-ZaM_eZ9GHN",
    "outputId": "d01758c9-1be2-4a8d-a362-adfbb4e053fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 28s 571ms/step\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"/content/drive/MyDrive/HW_2/val_empty.tsv\", sep='\\t')\n",
    "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "for_pred = tokenizer(\n",
    "    text=test_d['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "test_results = model.predict(x={'input_ids': for_pred['input_ids']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SMVO6kxn9GHO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:55:53.897916Z",
     "iopub.status.busy": "2023-04-18T19:55:53.896925Z",
     "iopub.status.idle": "2023-04-18T19:55:53.919161Z",
     "shell.execute_reply": "2023-04-18T19:55:53.917885Z",
     "shell.execute_reply.started": "2023-04-18T19:55:53.897858Z"
    },
    "id": "SMVO6kxn9GHO",
    "outputId": "ce16e255-ced5-47d2-ec16-2fd3bb758da1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-d467d76760e1>:1: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
      "\n",
      "<ipython-input-11-d467d76760e1>:2: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
      "\n",
      "<ipython-input-11-d467d76760e1>:3: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_stance'] -= 1\n",
      "\n",
      "<ipython-input-11-d467d76760e1>:4: SettingWithCopyWarning: \n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  test_d[f'{CLASS_NAME}_argument'] -= 1\n"
     ]
    }
   ],
   "source": [
    "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
    "test_d[f'{CLASS_NAME}_argument'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lOvFhLjw9GHO",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T19:55:53.924364Z",
     "iopub.status.busy": "2023-04-18T19:55:53.924035Z",
     "iopub.status.idle": "2023-04-18T19:55:53.956123Z",
     "shell.execute_reply": "2023-04-18T19:55:53.954938Z",
     "shell.execute_reply.started": "2023-04-18T19:55:53.924334Z"
    },
    "id": "lOvFhLjw9GHO"
   },
   "outputs": [],
   "source": [
    "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_NCrXCBvLtNM",
   "metadata": {
    "id": "_NCrXCBvLtNM"
   },
   "outputs": [],
   "source": [
    "CLASS_NAME = \"vaccines\"фы\n",
    "df3 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_{CLASS_NAME}.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50TKcudhC3Bd",
   "metadata": {
    "id": "50TKcudhC3Bd"
   },
   "source": [
    "### 3.5.4 New ARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2A_NDwWmC7gb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-19T19:08:20.179543Z",
     "iopub.status.busy": "2023-04-19T19:08:20.179133Z",
     "iopub.status.idle": "2023-04-19T19:08:22.874195Z",
     "shell.execute_reply": "2023-04-19T19:08:22.873350Z",
     "shell.execute_reply.started": "2023-04-19T19:08:20.179506Z"
    },
    "id": "2A_NDwWmC7gb",
    "outputId": "87e449ee-a444-454f-fca1-4655a4284ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiLabel_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['attention_mask[0][0]',         \n",
      "                                thPoolingAndCrossAt               'input_ids[0][0]']              \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 256, 768)    591168      ['bert[1][0]',                   \n",
      " dAttention)                                                      'bert[1][0]']                   \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 196608)       0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " pooled_output (Dropout)        (None, 196608)       0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " argument (Dense)               (None, 4)            786436      ['pooled_output[0][0]']          \n",
      "                                                                                                  \n",
      " stance (Dense)                 (None, 4)            786436      ['pooled_output[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,017,480\n",
      "Trainable params: 180,017,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build your model\n",
    "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "attention_mask = Input(shape=(256,), name='attention_mask', dtype='int32')\n",
    "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "# Load the Transformers BERT model as a layer in a Keras model\n",
    "bert_model = bert(inputs)[0]\n",
    "\n",
    "# Add multi-head attention layer\n",
    "attention_output = MultiHeadAttention(num_heads=3, key_dim=64)(bert_model, bert_model)\n",
    "\n",
    "# Flatten the output from multi-head attention layer\n",
    "flatten = Flatten()(attention_output)\n",
    "\n",
    "# Apply dropout layer\n",
    "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "pooled_output = dropout(flatten, training=False)\n",
    "\n",
    "# Then build your model output\n",
    "stance = Dense(units=len(data.stance_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
    "argument = Dense(units=len(data.argument_label.value_counts()), activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
    "outputs = {'stance': stance, 'argument': argument}\n",
    "\n",
    "# And combine it all in a model object\n",
    "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
    "\n",
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NvkNH_v1DAXj",
   "metadata": {
    "id": "NvkNH_v1DAXj"
   },
   "source": [
    "#### 3.5.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8M6FHChvC7jR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "execution": {
     "iopub.execute_input": "2023-04-19T19:09:03.284020Z",
     "iopub.status.busy": "2023-04-19T19:09:03.283411Z",
     "iopub.status.idle": "2023-04-19T20:20:02.186024Z",
     "shell.execute_reply": "2023-04-19T20:20:02.184821Z",
     "shell.execute_reply.started": "2023-04-19T19:09:03.283983Z"
    },
    "id": "8M6FHChvC7jR",
    "outputId": "e97909e4-63cc-45e7-ea0a-1e6792ee82e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "672/672 [==============================] - 281s 337ms/step - loss: 1.6283 - argument_loss: 0.2790 - stance_loss: 1.3493 - argument_accuracy: 0.9140 - stance_accuracy: 0.8535 - val_loss: 1.4829 - val_argument_loss: 0.2677 - val_stance_loss: 1.2152 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "672/672 [==============================] - 210s 312ms/step - loss: 1.5175 - argument_loss: 0.1928 - stance_loss: 1.3246 - argument_accuracy: 0.9300 - stance_accuracy: 0.8703 - val_loss: 1.6284 - val_argument_loss: 0.3714 - val_stance_loss: 1.2570 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.6250\n",
      "Epoch 3/20\n",
      "672/672 [==============================] - 208s 309ms/step - loss: 1.4702 - argument_loss: 0.1642 - stance_loss: 1.3060 - argument_accuracy: 0.9315 - stance_accuracy: 0.8656 - val_loss: 1.4259 - val_argument_loss: 0.1078 - val_stance_loss: 1.3182 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.6250\n",
      "Epoch 4/20\n",
      "672/672 [==============================] - 207s 309ms/step - loss: 1.1275 - argument_loss: 0.1225 - stance_loss: 1.0050 - argument_accuracy: 0.9568 - stance_accuracy: 0.8671 - val_loss: 1.0664 - val_argument_loss: 0.3571 - val_stance_loss: 0.7093 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.3005 - argument_loss: 0.0789 - stance_loss: 0.2216 - argument_accuracy: 0.9725 - stance_accuracy: 0.8680 - val_loss: 0.7802 - val_argument_loss: 0.2286 - val_stance_loss: 0.5515 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.6250\n",
      "Epoch 6/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.2580 - argument_loss: 0.0526 - stance_loss: 0.2054 - argument_accuracy: 0.9844 - stance_accuracy: 0.8682 - val_loss: 0.7035 - val_argument_loss: 0.0078 - val_stance_loss: 0.6957 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.2346 - argument_loss: 0.0331 - stance_loss: 0.2015 - argument_accuracy: 0.9896 - stance_accuracy: 0.8706 - val_loss: 1.9559 - val_argument_loss: 1.4212 - val_stance_loss: 0.5347 - val_argument_accuracy: 0.6250 - val_stance_accuracy: 0.6250\n",
      "Epoch 8/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.2102 - argument_loss: 0.0194 - stance_loss: 0.1908 - argument_accuracy: 0.9939 - stance_accuracy: 0.8712 - val_loss: 0.5231 - val_argument_loss: 0.0023 - val_stance_loss: 0.5208 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.6250\n",
      "Epoch 9/20\n",
      "672/672 [==============================] - 207s 307ms/step - loss: 0.2013 - argument_loss: 0.0100 - stance_loss: 0.1913 - argument_accuracy: 0.9976 - stance_accuracy: 0.8716 - val_loss: 0.6594 - val_argument_loss: 0.0031 - val_stance_loss: 0.6563 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.6250\n",
      "Epoch 10/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.1999 - argument_loss: 0.0131 - stance_loss: 0.1868 - argument_accuracy: 0.9970 - stance_accuracy: 0.8729 - val_loss: 0.8463 - val_argument_loss: 0.3210 - val_stance_loss: 0.5253 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.6250\n",
      "Epoch 11/20\n",
      "672/672 [==============================] - 207s 308ms/step - loss: 0.1750 - argument_loss: 0.0145 - stance_loss: 0.1605 - argument_accuracy: 0.9963 - stance_accuracy: 0.9181 - val_loss: 2.1712 - val_argument_loss: 1.6925 - val_stance_loss: 0.4787 - val_argument_accuracy: 0.7500 - val_stance_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.1508 - argument_loss: 0.0144 - stance_loss: 0.1363 - argument_accuracy: 0.9963 - stance_accuracy: 0.9224 - val_loss: 0.4332 - val_argument_loss: 0.0044 - val_stance_loss: 0.4288 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.1415 - argument_loss: 0.0182 - stance_loss: 0.1233 - argument_accuracy: 0.9953 - stance_accuracy: 0.9269 - val_loss: 0.6681 - val_argument_loss: 0.3151 - val_stance_loss: 0.3530 - val_argument_accuracy: 0.8750 - val_stance_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.1212 - argument_loss: 0.0090 - stance_loss: 0.1123 - argument_accuracy: 0.9978 - stance_accuracy: 0.9270 - val_loss: 0.3930 - val_argument_loss: 1.4931e-04 - val_stance_loss: 0.3929 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.1204 - argument_loss: 0.0111 - stance_loss: 0.1093 - argument_accuracy: 0.9981 - stance_accuracy: 0.9276 - val_loss: 0.4002 - val_argument_loss: 4.2766e-06 - val_stance_loss: 0.4002 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.1182 - argument_loss: 0.0114 - stance_loss: 0.1067 - argument_accuracy: 0.9978 - stance_accuracy: 0.9296 - val_loss: 0.3768 - val_argument_loss: 0.0147 - val_stance_loss: 0.3620 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.1161 - argument_loss: 0.0074 - stance_loss: 0.1087 - argument_accuracy: 0.9980 - stance_accuracy: 0.9287 - val_loss: 0.3752 - val_argument_loss: 0.0258 - val_stance_loss: 0.3494 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.1171 - argument_loss: 0.0113 - stance_loss: 0.1058 - argument_accuracy: 0.9970 - stance_accuracy: 0.9300 - val_loss: 0.3565 - val_argument_loss: 0.0097 - val_stance_loss: 0.3468 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "672/672 [==============================] - 206s 307ms/step - loss: 0.1142 - argument_loss: 0.0116 - stance_loss: 0.1025 - argument_accuracy: 0.9968 - stance_accuracy: 0.9293 - val_loss: 0.3466 - val_argument_loss: 9.9837e-07 - val_stance_loss: 0.3466 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "672/672 [==============================] - 207s 307ms/step - loss: 0.1148 - argument_loss: 0.0105 - stance_loss: 0.1044 - argument_accuracy: 0.9968 - stance_accuracy: 0.9293 - val_loss: 0.3466 - val_argument_loss: 7.7335e-06 - val_stance_loss: 0.3466 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "#! wandb login --relogin Nikita4epuh\n",
    "# Set an optimizer\n",
    "optimizer = AdamW(\n",
    "    learning_rate=5e-06,\n",
    "    epsilon=1e-08,\n",
    "    weight_decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
    "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)\n",
    "\n",
    "# Ready output data for the model\n",
    "y_stance = to_categorical(data[f'{CLASS_NAME}_stance'])\n",
    "y_argument = to_categorical(data[f'{CLASS_NAME}_argument'])\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "x = tokenizer(\n",
    "    text=data['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "#wandb.init(project=\"Text_categorization\", name = \"Bert_attention_vaccines_4epochs\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
    "epochs = 20\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    y={'stance': y_stance, 'argument': y_argument},\n",
    "    validation_data=({'input_ids': test_x['input_ids'][:8], 'attention_mask': test_x['attention_mask'][:8]}, \n",
    "                     {'stance': test_y_stance[:8], 'argument': test_y_argument[:8]}),\n",
    "    batch_size=8,\n",
    "    epochs=epochs) #callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v0bjIFV9J_k5",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "389ac52824a94297b81cf2fb4c2ab5fd"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-04-19T20:31:45.915975Z",
     "iopub.status.busy": "2023-04-19T20:31:45.915584Z",
     "iopub.status.idle": "2023-04-19T20:32:39.412139Z",
     "shell.execute_reply": "2023-04-19T20:32:39.411043Z",
     "shell.execute_reply.started": "2023-04-19T20:31:45.915940Z"
    },
    "id": "v0bjIFV9J_k5",
    "outputId": "57ad27f3-0605-416f-e8d2-701633eba84e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Usage: wandb login [OPTIONS] [KEY]...\n",
      "Try 'wandb login --help' for help.\n",
      "\n",
      "Error: No such option: --login Did you mean --relogin?\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389ac52824a94297b81cf2fb4c2ab5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670499766663245, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230419_203157-f8nknbhb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/f8nknbhb' target=\"_blank\">Bert_attention_vaccines_20epochs_Adam_5e-6</a></strong> to <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smolenkovaea00/Text_categorization' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smolenkovaea00/Text_categorization/runs/f8nknbhb' target=\"_blank\">https://wandb.ai/smolenkovaea00/Text_categorization/runs/f8nknbhb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "! wandb login --login Nikitathebest\n",
    "wandb.init(project=\"Text_categorization\", name = \"Bert_attention_vaccines_20epochs_Adam_5e-6\", tags = [\"Ruberta_with_MHA\", \"RB\"])\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    wandb.log({'loss': history.history['loss'][epoch],\n",
    "               'argument_loss': history.history['argument_loss'][epoch],\n",
    "               'stance_loss': history.history['stance_loss'][epoch],\n",
    "               'argument_accuracy': history.history['argument_accuracy'][epoch],\n",
    "               'stance_accuracy': history.history['stance_accuracy'][epoch],\n",
    "               'val_loss': history.history['stance_accuracy'][epoch],\n",
    "               'val_argument_loss': history.history['val_argument_loss'][epoch],\n",
    "               'val_stance_loss': history.history['val_stance_loss'][epoch],\n",
    "               'val_argument_accuracy': history.history['val_argument_accuracy'][epoch],\n",
    "               'val_stance_accuracy': history.history['val_stance_accuracy'][epoch]}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43wzoIa1DJma",
   "metadata": {
    "id": "43wzoIa1DJma"
   },
   "source": [
    "#### 3.5.6 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G3vTEbboC7oo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3vTEbboC7oo",
    "outputId": "c56c45c5-c423-4d97-e812-457b8707dea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 28s 614ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       0.75      1.00      0.86      1010\n",
      "\n",
      "           1       0.00      0.00      0.00        78\n",
      "\n",
      "           2       0.00      0.00      0.00       174\n",
      "\n",
      "           3       0.00      0.00      0.00        82\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.75      1344\n",
      "\n",
      "   macro avg       0.19      0.25      0.21      1344\n",
      "\n",
      "weighted avg       0.56      0.75      0.64      1344\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "\n",
      "\n",
      "           0       1.00      1.00      1.00      1010\n",
      "\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "           2       0.74      1.00      0.85       248\n",
      "\n",
      "           3       0.00      0.00      0.00        36\n",
      "\n",
      "\n",
      "\n",
      "    accuracy                           0.93      1344\n",
      "\n",
      "   macro avg       0.43      0.50      0.46      1344\n",
      "\n",
      "weighted avg       0.89      0.93      0.91      1344\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_results = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
    "data_test[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
    "data_test[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
    "print(classification_report(data_test[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0), classification_report(data_test[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "APpkcLSbDMmV",
   "metadata": {
    "id": "APpkcLSbDMmV"
   },
   "source": [
    "#### 3.5.7 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dyirz8lPJ_k5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T11:06:11.638096Z",
     "iopub.status.busy": "2023-04-20T11:06:11.637017Z",
     "iopub.status.idle": "2023-04-20T11:06:14.048316Z",
     "shell.execute_reply": "2023-04-20T11:06:14.046794Z",
     "shell.execute_reply.started": "2023-04-20T11:06:11.638044Z"
    },
    "id": "Dyirz8lPJ_k5",
    "outputId": "2b456e7e-0e34-4649-d65a-3db4a47b6c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1lUerv_gpQvo_e8Fl-flxEDtz77z_ZsLx\n",
      "To: /kaggle/working/val_empty.tsv\n",
      "100%|█████████████████████████████████████████| 316k/316k [00:00<00:00, 102MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1lUerv_gpQvo_e8Fl-flxEDtz77z_ZsLx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oXE0Lr2PC7rb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-19T20:21:24.820609Z",
     "iopub.status.busy": "2023-04-19T20:21:24.819491Z",
     "iopub.status.idle": "2023-04-19T20:21:48.645687Z",
     "shell.execute_reply": "2023-04-19T20:21:48.644526Z",
     "shell.execute_reply.started": "2023-04-19T20:21:24.820565Z"
    },
    "id": "oXE0Lr2PC7rb",
    "outputId": "8ea6523a-bdeb-411b-d7e7-aa3ef3646420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 322ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAME = \"vaccines\"\n",
    "test = pd.read_csv(\"/kaggle/working/val_empty.tsv\", sep='\\t')\n",
    "test.head()\n",
    "test_d = test[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
    "for_pred = tokenizer(\n",
    "    text=test_d['text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "test_results = model.predict(x={'input_ids': for_pred['input_ids'], 'attention_mask': for_pred['attention_mask']})\n",
    "test_d[f'{CLASS_NAME}_stance'] = test_results['stance'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_argument'] = test_results['argument'].argmax(axis=-1)\n",
    "test_d[f'{CLASS_NAME}_stance'] -= 1\n",
    "test_d[f'{CLASS_NAME}_argument'] -= 1\n",
    "test_d[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']].to_csv(f\"/kaggle/working/val_predict_MHA_Adam_5e_6_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gnWg1Irw9GHO",
   "metadata": {
    "id": "gnWg1Irw9GHO"
   },
   "source": [
    "## 3.6 Concatinate all files with results for masks, vaccines, quarantine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p6kX2AxZ9GHO",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T19:55:53.958445Z",
     "iopub.status.busy": "2023-04-18T19:55:53.957707Z",
     "iopub.status.idle": "2023-04-18T19:55:54.002220Z",
     "shell.execute_reply": "2023-04-18T19:55:54.000932Z",
     "shell.execute_reply.started": "2023-04-18T19:55:53.958406Z"
    },
    "id": "p6kX2AxZ9GHO"
   },
   "outputs": [],
   "source": [
    "CLASS_NAME = \"quarantine\"\n",
    "df1 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_{CLASS_NAME}.tsv\", sep='\\t')\n",
    "CLASS_NAME = \"masks\"\n",
    "df2 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_{CLASS_NAME}.tsv\", sep='\\t')\n",
    "CLASS_NAME = \"vaccines\"\n",
    "df3 = pd.read_csv(f\"/content/drive/MyDrive/HW_2/val_predict_MHA_{CLASS_NAME}.tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "result = pd.merge(df1, df2, on=\"text\")\n",
    "result = pd.merge(result, df3, on=\"text\")\n",
    "result.to_csv(\"/content/drive/MyDrive/HW_2/val_predict_concat_MHA.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qiqgj--k9GHO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-18T19:55:54.010538Z",
     "iopub.status.busy": "2023-04-18T19:55:54.007210Z",
     "iopub.status.idle": "2023-04-18T19:55:55.205261Z",
     "shell.execute_reply": "2023-04-18T19:55:55.203740Z",
     "shell.execute_reply.started": "2023-04-18T19:55:54.010489Z"
    },
    "id": "Qiqgj--k9GHO",
    "outputId": "84170e0d-338c-41e5-eb14-6a666fa6488d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: content/drive/MyDrive/HW_2/val_predict_concat.tsv (deflated 73%)\n"
     ]
    }
   ],
   "source": [
    "!zip /content/drive/MyDrive/HW_2/val_predict_concat.zip /content/drive/MyDrive/HW_2/val_predict_concat.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XqVEV2W8NMC5",
   "metadata": {
    "id": "XqVEV2W8NMC5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1b3c19fa-f883-4675-9506-85c4f02f0af9",
    "cKrIw_Ve9GHI",
    "6mfHDU3GWdy6",
    "VZa3_IxI9GHJ",
    "Dl1vax0e9GHL",
    "1TjrWgJs9GHL",
    "osmGpcNL9GHL",
    "T5v7lBS49GHM",
    "r3FkHFVFAqh6",
    "CbTC672ZA76b",
    "iciqRheS9GHN",
    "peIWpSF59GHN",
    "hs9veuJ39GHN"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0128ba3037d54f689efe4fc9abe25bb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52458245c5984599bdfbbcb3563a38ee",
      "placeholder": "​",
      "style": "IPY_MODEL_b86ea15b73a747a69ba379bdd890dc1b",
      "value": " 112/112 [00:00&lt;00:00, 4.91kB/s]"
     }
    },
    "1288e4dbb6fa42abb8786a14d6a58fcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "168b4a4a02e74707a85c4a57f6f65deb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f05103783e324ef5be9b6be4625934f8",
      "max": 1649718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6744639e9adb4beda7d1eaa91cd48e20",
      "value": 1649718
     }
    },
    "1859ea04a21349d8a4b7b657c896bf75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19373f266a3b45c29f5cf8b164e68809": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d6cfcf43f62450b8432462e839f776a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b7e428fa9554798b652e307c9a0d789",
      "placeholder": "​",
      "style": "IPY_MODEL_b214014bdc094792b33a1e6ac1bb283f",
      "value": "Downloading (…)cial_tokens_map.json: 100%"
     }
    },
    "1e81219c44ff4cf19bdb083c4a372e1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f74d62057f64197a68ef807fae1f0cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aae01d39da4a4d39b95ba98f138e9920",
      "placeholder": "​",
      "style": "IPY_MODEL_2909ae3e202545ca97f2d177a50ceaa9",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "235bd2cda15142dfa7a99f8fd8cd0a9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2909ae3e202545ca97f2d177a50ceaa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fe76d7b205a4c37b6a3d60e27bc0f12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5842bd0413754232a206c565d66df1d0",
      "placeholder": "​",
      "style": "IPY_MODEL_c56ed62af4d943ec829f02f69cfb1a18",
      "value": " 711M/711M [00:14&lt;00:00, 38.5MB/s]"
     }
    },
    "39b3a03232074940a32d832ed72b9bf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b7e428fa9554798b652e307c9a0d789": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42287c1ea97f4d959d4cb1d86c65ee3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fb2681bef4f4a7dbf203bfb812910ce",
      "placeholder": "​",
      "style": "IPY_MODEL_c6951df00866437380f997604f2d0e88",
      "value": " 1.65M/1.65M [00:00&lt;00:00, 7.38MB/s]"
     }
    },
    "44950988de7144ba9c075a5901fe6d58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4fb2681bef4f4a7dbf203bfb812910ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52458245c5984599bdfbbcb3563a38ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58365ddd22454f7e8148e5e417ae0a63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d6cfcf43f62450b8432462e839f776a",
       "IPY_MODEL_65bec8e640c04dd3bfd525e9d85a228c",
       "IPY_MODEL_0128ba3037d54f689efe4fc9abe25bb5"
      ],
      "layout": "IPY_MODEL_c2c994d8d37d42aa9c707b3cd95fc315"
     }
    },
    "5842bd0413754232a206c565d66df1d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6042b5798fd444f6bc658ee9669211bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64ae863966f849789ea5e1b93a18e47d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65bec8e640c04dd3bfd525e9d85a228c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e81219c44ff4cf19bdb083c4a372e1f",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a2938dd5138476ebd05358c4855ef0f",
      "value": 112
     }
    },
    "6744639e9adb4beda7d1eaa91cd48e20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6cd77a7ebbfe446389ea3461318d5a3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d035931093f248369dbb26f17eb590bf",
       "IPY_MODEL_fd8d238024cb43019ad5552237000223",
       "IPY_MODEL_a55bc959b5464902be6584288ce7b8d1"
      ],
      "layout": "IPY_MODEL_235bd2cda15142dfa7a99f8fd8cd0a9b"
     }
    },
    "7264c4efd2d142cb9da4997994d13090": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a2938dd5138476ebd05358c4855ef0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ee59eb8a0954366a92cfc8aec52d5a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7facfea53845464981c9cb07b31137c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f66f51ecc2204b21928b34740b028474",
      "placeholder": "​",
      "style": "IPY_MODEL_39b3a03232074940a32d832ed72b9bf4",
      "value": " 24.0/24.0 [00:00&lt;00:00, 769B/s]"
     }
    },
    "8d9e9d90c9bd4548bff981b9c63a4259": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94da8c2174b6465a8b09099ca1c698c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95248307486c46b59e794349a399d238": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6851b1763c64aaaa53bed69b05f56be",
       "IPY_MODEL_f940b7a547524f728476c9f00db7898f",
       "IPY_MODEL_2fe76d7b205a4c37b6a3d60e27bc0f12"
      ],
      "layout": "IPY_MODEL_6042b5798fd444f6bc658ee9669211bf"
     }
    },
    "9fedcf90bd234b92b2a9ca884c16e082": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a55bc959b5464902be6584288ce7b8d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de5a58be128a4e23a3adcecacef41e2f",
      "placeholder": "​",
      "style": "IPY_MODEL_d2c7cac0850d4c76ae22dccdf1a594d8",
      "value": " 642/642 [00:00&lt;00:00, 22.0kB/s]"
     }
    },
    "a604b16f25c34d568e59294280330bd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dafedb9a4229445384d73bca5be86700",
      "placeholder": "​",
      "style": "IPY_MODEL_64ae863966f849789ea5e1b93a18e47d",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "aae01d39da4a4d39b95ba98f138e9920": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b214014bdc094792b33a1e6ac1bb283f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b86ea15b73a747a69ba379bdd890dc1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2c994d8d37d42aa9c707b3cd95fc315": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c43d9796980542518e7fc98a22aa96af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c51a2be116e740a19a4aaac982c89717": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c56ed62af4d943ec829f02f69cfb1a18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6951df00866437380f997604f2d0e88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d035931093f248369dbb26f17eb590bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d9e9d90c9bd4548bff981b9c63a4259",
      "placeholder": "​",
      "style": "IPY_MODEL_e0e368e7fa9e4c45b7babb003d17a99f",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "d2c7cac0850d4c76ae22dccdf1a594d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5aea24b949c430195ad3e4b6835deb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f74d62057f64197a68ef807fae1f0cf",
       "IPY_MODEL_e02e39a6969c42ba9c9096f4eb7aead1",
       "IPY_MODEL_7facfea53845464981c9cb07b31137c9"
      ],
      "layout": "IPY_MODEL_94da8c2174b6465a8b09099ca1c698c0"
     }
    },
    "dadd760b9d8142ae987b8868409353c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a604b16f25c34d568e59294280330bd8",
       "IPY_MODEL_168b4a4a02e74707a85c4a57f6f65deb",
       "IPY_MODEL_42287c1ea97f4d959d4cb1d86c65ee3f"
      ],
      "layout": "IPY_MODEL_9fedcf90bd234b92b2a9ca884c16e082"
     }
    },
    "dafedb9a4229445384d73bca5be86700": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de5a58be128a4e23a3adcecacef41e2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e02e39a6969c42ba9c9096f4eb7aead1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7264c4efd2d142cb9da4997994d13090",
      "max": 24,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c43d9796980542518e7fc98a22aa96af",
      "value": 24
     }
    },
    "e0e368e7fa9e4c45b7babb003d17a99f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f05103783e324ef5be9b6be4625934f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f66f51ecc2204b21928b34740b028474": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6851b1763c64aaaa53bed69b05f56be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c51a2be116e740a19a4aaac982c89717",
      "placeholder": "​",
      "style": "IPY_MODEL_7ee59eb8a0954366a92cfc8aec52d5a9",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "f940b7a547524f728476c9f00db7898f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19373f266a3b45c29f5cf8b164e68809",
      "max": 711456784,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1288e4dbb6fa42abb8786a14d6a58fcc",
      "value": 711456784
     }
    },
    "fd8d238024cb43019ad5552237000223": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1859ea04a21349d8a4b7b657c896bf75",
      "max": 642,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_44950988de7144ba9c075a5901fe6d58",
      "value": 642
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
